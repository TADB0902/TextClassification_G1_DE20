{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-14 04:25:33.368778: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Vietnamese Text Normalizer version 1.9.5\n",
      "\tBùi Tấn Quang - langmaninternet@gmail.com\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import numpy as np\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import json\n",
    "import pandas as pd\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import load_model\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import *\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional, Dropout, GRU, BatchNormalization\n",
    "import optuna\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from  VietnameseTextNormalizer.ReleasePython3 import VietnameseTextNormalizer\n",
    "import py_vncorenlp\n",
    "import re\n",
    "from optuna.integration import TFKerasPruningCallback\n",
    "from optuna.trial import TrialState\n",
    "from optuna.visualization import plot_intermediate_values\n",
    "from optuna.visualization import plot_optimization_history\n",
    "from optuna.visualization import plot_contour\n",
    "from optuna.visualization import plot_param_importances\n",
    "import optuna.visualization as ov\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-13 11:39:14 INFO  WordSegmenter:24 - Loading Word Segmentation model\n",
      "2023-12-13 11:39:14 INFO  PosTagger:23 - Loading POS Tagging model\n",
      "2023-12-13 11:39:17 INFO  NerRecognizer:34 - Loading NER model\n",
      "2023-12-13 11:39:29 INFO  DependencyParser:32 - Loading Dependency Parsing model\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "annotate = py_vncorenlp.VnCoreNLP(annotators=[\"wseg\", \"pos\", \"ner\", \"parse\"], save_dir='./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIGINAL_DATA =\"./original_data/\"\n",
    "PREPROCESSED_DATA = \"./preprocessed_data/preprocessed_data.json\"\n",
    "MODEL_FOLDER = \"./models\"\n",
    "WORD2VEC_MODEL = \"word2vec_model_100dim_10min.save\"\n",
    "DOC2VEC_MODEL = \"doc2vec_model_100dim_10min.save\"\n",
    "STOPWORD = \"./vietnamese-stopwords-dash.txt\"\n",
    "with open(STOPWORD, 'r', encoding='utf-8') as stop_word_file:\n",
    "    stop_words = stop_word_file.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging, os\n",
    "logging.disable(logging.WARNING)\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sep = os.sep\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text= VietnameseTextNormalizer.Normalize(text)\n",
    "    text = re.sub(r'http\\S+', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\b(www\\.[^\\s]+|(?!https?://)[^\\s]+\\.[a-z]{2,})\\b', '', text)\n",
    "    # Remove phone numbers\n",
    "    text = re.sub(r'\\b\\d{10,}\\b', '', text)\n",
    "\n",
    "    # Remove emails\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    annotations = annotate.annotate_text(text)\n",
    "    all_tokens = []\n",
    "    for sentence_index, sentence_annotations in annotations.items():\n",
    "        all_tokens.extend(sentence_annotations)\n",
    "    word_list  = [\n",
    "        token['wordForm'] for token in all_tokens\n",
    "        if isinstance(token, dict) and 'wordForm' in token and isinstance(token['wordForm'], str)\n",
    "        and 'posTag' in token and isinstance(token['posTag'], str) and token['posTag'] in ['N', 'V', 'A']\n",
    "        and 'nerLabel' in token and token['nerLabel'] not in ['B-PER']\n",
    "    ]\n",
    "    clean_words = [word.strip(',').strip().lower() for word in word_list  if word not in stop_words]\n",
    "    clean_words = [re.sub(r'([^\\s\\w]|)+', '', sentence) for sentence in clean_words if sentence!='']\n",
    "    return clean_words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   Processed_Content  Category\n",
      "0  [lễ, chủ_tịch, tỉnh, trao, khen, chủ_tịch, tỉn...  Giao duc\n",
      "1  [đề_xuất, giáo_dục, kỳ_vọng, đột_phá, dư_luận,...  Giao duc\n",
      "2  [gần, cư_dân, mạng, truyền, đoạn, clip, ghi, h...  Giao duc\n",
      "3  [căn_bệnh, thành_tích, địa_phương, biến, thi, ...  Giao duc\n",
      "4  [phân_biệt, dạy, tác_phẩm, chương_trình, ban, ...  Giao duc\n"
     ]
    }
   ],
   "source": [
    "# Đường dẫn đến file JSON\n",
    "json_file_path = PREPROCESSED_DATA\n",
    "\n",
    "# Load dữ liệu từ file JSON vào DataFrame\n",
    "df = pd.read_json(json_file_path, encoding='utf-8', lines=True)\n",
    "\n",
    "# Hiển thị DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df['Category'].tolist()\n",
    "# news là 1 list mà mỗi phần tử là 1 bài báo (1 list các từ đã được phân tách)\n",
    "news = df['Processed_Content'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lễ', 'chủ_tịch', 'tỉnh', 'trao', 'khen', 'chủ_tịch', 'tỉnh', 'khen', 'bí_thư', 'tỉnh_uỷ', 'ghi_nhận', 'nỗ_lực', 'cố_gắng', 'học_tập', 'hoạt_động', 'xã_hội', 'đại_diện', 'lãnh_đạo', 'tỉnh', 'trao', 'thư', 'khen', 'khen', 'lãnh_đạo', 'tỉnh_uỷ', 'tỉnh', 'em', 'học_sinh', 'lớp', 'chuyên', 'trường', 'chuyên', 'sở_hữu', 'bảng_vàng', 'thành_tích', 'liên_tục', 'học_sinh', 'giỏi', 'giải', 'học_sinh', 'giỏi', 'quốc_gia', 'môn', 'tiếng', 'huy_chương', 'tiếng', 'quốc_gia', 'huy_chương', 'năng', 'tiếng', 'anh', 'quốc_gia', 'sáng_lập', 'tổ_chức', 'hoạt_động', 'xã_hội', 'dự_án', 'cung_cấp', 'áo_ấm', 'trẻ_em', 'vùng_cao', 'dự_án', 'phát_triển', 'túi', 'giấy', 'bảo_vệ', 'môi_trường', 'thành_tích', 'nổi_bật', 'vinh_dự', 'gương_mặt', 'trẻ', 'đại_diện', 'tham_dự', 'chương_trình', 'thủ_lĩnh', 'thanh_niên', 'ngoại_giao', 'trường', 'đại_học', 'tổ_chức', 'đại_diện', 'tham_dự', 'đối_thoại', 'giáo_dục', 'đặc_biệt', 'xuất_sắc', 'ứng_viên', 'thí_sinh', 'thế_giới', 'học_bổng', 'toàn_phần', 'trường', 'đại_học', 'quốc', 'tin', 'ảnh']\n",
      "97\n",
      "Giao duc\n",
      "114322\n",
      "114322\n"
     ]
    }
   ],
   "source": [
    "print(news[0])\n",
    "print(len(news[0]))\n",
    "print(labels[0])\n",
    "print(len(news))\n",
    "print(len(labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_length'] = df['Processed_Content'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   Processed_Content  Category  text_length\n",
      "0  [lễ, chủ_tịch, tỉnh, trao, khen, chủ_tịch, tỉn...  Giao duc           97\n",
      "1  [đề_xuất, giáo_dục, kỳ_vọng, đột_phá, dư_luận,...  Giao duc          267\n",
      "2  [gần, cư_dân, mạng, truyền, đoạn, clip, ghi, h...  Giao duc          172\n",
      "3  [căn_bệnh, thành_tích, địa_phương, biến, thi, ...  Giao duc          370\n",
      "4  [phân_biệt, dạy, tác_phẩm, chương_trình, ban, ...  Giao duc          325\n",
      "5  [trường, năm_học, nộp, tiền, quản_lý, phép, dạ...  Giao duc          204\n",
      "6  [công_nghệ, may, hút, thí_sinh, nữ, tranh, tuy...  Giao duc          225\n",
      "7  [ảnh, minh_hoạ, phương_án, tổ_chức, quy_trình,...  Giao duc          213\n",
      "8  [học_sinh, bậc, mầm_non, tiểu_học, nghỉ, học, ...  Giao duc          142\n",
      "9  [thi, kỳ, thi, ghi_nhận, phóng_viên, báo_điện_...  Giao duc          412\n"
     ]
    }
   ],
   "source": [
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "392\n",
      "162.2473102290023\n"
     ]
    }
   ],
   "source": [
    "# Tính độ dài của mỗi chuỗi trong sequences\n",
    "lengths = [len(sentence) for sentence in df['Processed_Content']]\n",
    "\n",
    "# Xác định giá trị max_length dựa trên phân phối của độ dài chuỗi\n",
    "max_length = int(np.percentile(lengths, 95))\n",
    "print(max_length)\n",
    "\n",
    "# Tính trung bình của max_length\n",
    "average_max_length = np.mean(lengths)\n",
    "print(average_max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert label to one-hot-encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.get_dummies(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def txtTokenizer(texts):\n",
    "    # Khởi tạo Tokenizer với số từ tối đa là 26313\n",
    "    tokenizer = Tokenizer(num_words=26313)\n",
    "    \n",
    "    # Huấn luyện Tokenizer trên danh sách văn bản\n",
    "    tokenizer.fit_on_texts(texts)\n",
    "\n",
    "    # Lấy từ điển từ (word index) từ Tokenizer\n",
    "    word_index = tokenizer.word_index\n",
    "\n",
    "    return tokenizer, word_index\n",
    "\n",
    "\n",
    "tokenizer, word_index = txtTokenizer(news)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of 'cầu_thủ': 68\n",
      "The word 'cầu_thủ' appears 6869 times in the data.\n"
     ]
    }
   ],
   "source": [
    "# In ra word_index của một từ cụ thể\n",
    "word_to_lookup = \"cầu_thủ\"\n",
    "\n",
    "if word_to_lookup in word_index:\n",
    "    print(f\"Index of '{word_to_lookup}': {word_index[word_to_lookup]}\")\n",
    "else:\n",
    "    print(f\"'{word_to_lookup}' not found in vocabulary.\")\n",
    "\n",
    "count_of_word = 0\n",
    "\n",
    "# Lặp qua dữ liệu để đếm số lần xuất hiện của từ\n",
    "for sentence in news:\n",
    "    if word_to_lookup in sentence:\n",
    "        count_of_word += 1\n",
    "\n",
    "print(f\"The word '{word_to_lookup}' appears {count_of_word} times in the data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "đi: 1\n",
      "trường: 2\n",
      "thi: 3\n",
      "học: 4\n",
      "trẻ: 5\n",
      "tiền: 6\n",
      "đầu: 7\n",
      "đội: 8\n",
      "công_ty: 9\n",
      "tổ_chức: 10\n"
     ]
    }
   ],
   "source": [
    "# Print the first 10 items from word_index\n",
    "for index, (word, value) in enumerate(word_index.items()):\n",
    "    print(f\"{word}: {value}\")\n",
    "    \n",
    "    # Print only the first 10 items\n",
    "    if index == 9:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence and padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chuyển đổi văn bản thành chuỗi các chỉ số tương ứng sử dụng tokenizer\n",
    "news_token = tokenizer.texts_to_sequences(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['đề_xuất', 'giáo_dục', 'kỳ_vọng', 'đột_phá', 'dư_luận', 'theo', 'hàng_loạt', 'rút', 'ngắn', 'học', 'đào_tạo', 'hình_thức', 'tín_chỉ', 'học', 'trực_tuyến', 'công_nhận', 'tốt_nghiệp', 'tự_biên', 'soạn', 'nâng', 'chế_độ', 'lương', 'giáo_viên', 'văn_phòng', 'đề_xuất', 'giúp', 'học_sinh', 'hoàn_cảnh', 'tiếp_cận', 'giáo_dục', 'đại_học', 'đề_xuất', 'dư_luận', 'hình_thức', 'giáo_dục', 'đào_tạo', 'dạng', 'tín_chỉ', 'áp_dụng', 'đề_xuất', 'học_sinh', 'học', 'tín_chỉ', 'ảnh', 'tin', 'theo', 'lãnh_đạo', 'thành_phố', 'áp_dụng', 'tín_chỉ', 'liên_thông', 'bậc', 'đại_học', 'sau_đại_học', 'giúp', 'học_sinh', 'làm_quen', 'phương_thức', 'học', 'tín_chỉ', 'hiện_đại', 'tiết_kiệm', 'học', 'học', 'giỏi', 'đề_án', 'hướng', 'tiếp_cận', 'kiến_thức', 'phổ_thông', 'học', 'đại_học', 'học_sinh', 'đại_học', 'chờ', 'quy_định', 'thế_giới', 'quy_định', 'áp_dụng', 'thành_công', 'đề_án', 'thành_phố', 'dự_tính', 'năm_học', 'môn', 'bắt_buộc', 'môn', 'hoàn_thành', 'chủ_tịch', 'hội_đồng', 'chuyên_môn', 'trường', 'giảng_viên', 'học', 'tín_chỉ', 'giải_quyết', 'quy_định', 'học_sinh', 'giỏi', 'đi', 'chậm', 'chờ', 'học_sinh', 'yếu', 'người', 'yếu', 'níu', 'chân', 'giỏi', 'việc', 'học', 'tín_chỉ', 'giải_quyết', 'bài_toán', 'môn_học', 'chương_trình', 'giáo_dục_phổ_thông', 'được', 'giúp', 'rút', 'ngắn', 'đào_tạo', 'uyển_chuyển', 'linh_hoạt', 'lớp_học', 'cách', 'học', 'học_sinh', 'thi', 'chứng_chỉ', 'trường', 'quốc_tế', 'thầy_giáo', 'tỏ', 'lo_lắng', 'đề_xuất', 'theo', 'thầy', 'bậc', 'đăng_ký', 'lựa_chọn', 'tín_chỉ', 'học_sinh', 'dễ_dàng', 'tuổi', 'tự_chủ', 'tự_giác', 'sắp_xếp', 'lộ_trình', 'học_tập', 'phụ_thuộc', 'cha_mẹ', 'học_sinh', 'quá_tải', 'học_tập', 'thời_gian', 'học_tập', 'linh_hoạt', 'đi', 'chiều', 'cha_mẹ', 'đón_đưa', 'thầy', 'học', 'tín_chỉ', 'tổ_chức', 'quan_hệ', 'thành_viên', 'lớp', 'giáo_viên', 'chủ_nhiệm', 'liệu', 'lứa', 'cần', 'kỹ_lưỡng', 'vụ', 'vụ', 'giáo_dục', 'đại_học', 'đề_xuất', 'học', 'tín_chỉ', 'khả_thi', 'đề_xuất', 'rút', 'ngắn', 'năm_học', 'cấu_trúc', 'chương_trình', 'là_hơi', 'nước', 'hệ_thống', 'giáo_dục', 'đề_xuất', 'khuôn_khổ', 'hệ_thống', 'giáo_dục', 'quốc_gia', 'nêu', 'quan_điểm', 'theo', 'nguyên', 'vụ', 'vụ', 'giáo_dục', 'đại_học', 'học', 'tín_chỉ', 'học_sinh', 'học', 'chậm', 'cớ_sao', 'năm_học', 'khác_biệt', 'đi', 'chệch', 'hướng', 'thành_phố', 'năng_động', 'hệ_thống', 'đào_tạo', 'tín_chỉ', 'phương_thức', 'đơn_giản', 'nghiên_cứu', 'chu_đáo', 'trường', 'đại_học', 'triển_khai', 'đào_tạo', 'tín_chỉ', 'số_ít', 'trường', 'kiểu', 'nửa_vời', 'nghiên_cứu', 'kỹ', 'hình_thức', 'lợi_bất_cập_hại', 'giáo_dục', 'bê', 'nguyên', 'mẫu', 'đào_tạo', 'nước_ngoài', 'áp_dụng', 'máy_móc', 'thất_bại', 'nhấn_mạnh', 'tổ_chức', 'học', 'tín_chỉ', 'thành_công', 'giám_sát', 'nghiên_cứu', 'thấu_đáo', 'chuyên_gia', 'tư_vấn', 'hình_thức', 'đào_tạo', 'lưu_tâm', 'quốc_gia', 'phát_triển', 'tỉnh_thành', 'nhân', 'rộng', 'mô_hình']\n",
      "[757, 40, 1924, 1986, 680, 20, 768, 438, 546, 4, 84, 444, 5339, 4, 1125, 1068, 464, 20500, 3600, 215, 577, 597, 92, 607, 757, 19, 14, 779, 867, 40, 35, 757, 680, 444, 40, 84, 508, 5339, 269, 757, 14, 4, 5339, 25, 3211, 20, 202, 49, 269, 5339, 5038, 584, 35, 5119, 19, 14, 2293, 1460, 4, 5339, 616, 987, 4, 4, 465, 1543, 209, 867, 369, 1190, 4, 35, 14, 35, 428, 69, 26, 69, 269, 121, 1543, 49, 3516, 516, 128, 1470, 128, 484, 132, 489, 633, 2, 1095, 4, 5339, 212, 69, 14, 465, 1, 646, 428, 14, 808, 158, 808, 7645, 138, 465, 228, 4, 5339, 212, 2957, 1234, 16, 2284, 674, 19, 438, 546, 84, 7646, 2339, 1383, 752, 4, 14, 3, 1820, 2, 117, 2096, 501, 667, 757, 20, 278, 584, 178, 293, 5339, 14, 442, 4728, 1694, 6105, 1534, 2134, 336, 1273, 487, 14, 2569, 336, 884, 336, 2339, 1, 116, 487, 17723, 278, 4, 5339, 10, 189, 207, 52, 92, 1504, 727, 1574, 1473, 2846, 28, 28, 40, 35, 757, 4, 5339, 2915, 757, 438, 546, 516, 1752, 16, 9199, 2038, 96, 40, 757, 2418, 96, 40, 70, 672, 582, 20, 1028, 28, 28, 40, 35, 4, 5339, 14, 4, 646, 19391, 516, 1246, 1, 4125, 209, 49, 2163, 96, 84, 5339, 1460, 418, 48, 3064, 2, 35, 296, 84, 5339, 3370, 2, 301, 11409, 48, 949, 444, 15563, 40, 5782, 1028, 504, 84, 135, 269, 2277, 657, 776, 10, 4, 5339, 121, 742, 48, 6898, 163, 644, 444, 84, 7724, 70, 23, 3266, 1071, 388, 748]\n",
      "267\n",
      "267\n"
     ]
    }
   ],
   "source": [
    "print(news[1])\n",
    "print(news_token[1])\n",
    "print(len(news[1]))\n",
    "print(len(news_token[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Độ dài tối đa của mỗi chuỗi chỉ số\n",
    "maxlen = 200\n",
    "\n",
    "# Padding chuỗi chỉ số để có chiều dài tối đa là maxlen\n",
    "news_pad = pad_sequences(news_token, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  867   369  1190     4    35    14    35   428    69    26    69   269\n",
      "   121  1543    49  3516   516   128  1470   128   484   132   489   633\n",
      "     2  1095     4  5339   212    69    14   465     1   646   428    14\n",
      "   808   158   808  7645   138   465   228     4  5339   212  2957  1234\n",
      "    16  2284   674    19   438   546    84  7646  2339  1383   752     4\n",
      "    14     3  1820     2   117  2096   501   667   757    20   278   584\n",
      "   178   293  5339    14   442  4728  1694  6105  1534  2134   336  1273\n",
      "   487    14  2569   336   884   336  2339     1   116   487 17723   278\n",
      "     4  5339    10   189   207    52    92  1504   727  1574  1473  2846\n",
      "    28    28    40    35   757     4  5339  2915   757   438   546   516\n",
      "  1752    16  9199  2038    96    40   757  2418    96    40    70   672\n",
      "   582    20  1028    28    28    40    35     4  5339    14     4   646\n",
      " 19391   516  1246     1  4125   209    49  2163    96    84  5339  1460\n",
      "   418    48  3064     2    35   296    84  5339  3370     2   301 11409\n",
      "    48   949   444 15563    40  5782  1028   504    84   135   269  2277\n",
      "   657   776    10     4  5339   121   742    48  6898   163   644   444\n",
      "    84  7724    70    23  3266  1071   388   748]\n"
     ]
    }
   ],
   "source": [
    "print(news_pad[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sử dụng train_test_split để chia dữ liệu thành train, test, val\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(news_pad, y, test_size=0.4, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lưu dữ liệu vào file data.pkl\n",
    "data = {\n",
    "    'X_train': X_train,\n",
    "    'y_train': y_train,\n",
    "    'X_test': X_test,\n",
    "    'y_test': y_test,\n",
    "    'X_val': X_val,\n",
    "    'y_val': y_val,\n",
    "    'word_index': word_index,\n",
    "    'tokenizer': tokenizer,\n",
    "}\n",
    "\n",
    "with open('data.pkl', 'wb') as file:\n",
    "    pickle.dump(data, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If already splitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.pkl', 'rb') as f:\n",
    "    loaded_data = pickle.load(f)\n",
    "X_train,y_train, X_test, y_test,X_val, y_val, word_index,tokenizer = loaded_data.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kích thước tập train: (68593, 200) (68593, 12)\n",
      "Kích thước tập test: (22864, 200) (22864, 12)\n",
      "Kích thước tập validation: (22865, 200) (22865, 12)\n"
     ]
    }
   ],
   "source": [
    "# In ra kích thước của từng tập\n",
    "print(\"Kích thước tập train:\", X_train.shape, y_train.shape)\n",
    "print(\"Kích thước tập test:\", X_test.shape, y_test.shape)\n",
    "print(\"Kích thước tập validation:\", X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng mẫu trên từng nhãn trong tập train:\n",
      "Chinh tri Xa hoi: 6463 mẫu\n",
      "Cong nghe: 5140 mẫu\n",
      "Doi song: 6106 mẫu\n",
      "Giai tri: 5364 mẫu\n",
      "Giao duc: 5542 mẫu\n",
      "Khoa hoc: 6031 mẫu\n",
      "Kinh doanh: 5665 mẫu\n",
      "Phap luat: 5816 mẫu\n",
      "Suc khoe: 5325 mẫu\n",
      "The gioi: 5765 mẫu\n",
      "The thao: 5889 mẫu\n",
      "Van hoa: 5487 mẫu\n",
      "\n",
      "Số lượng mẫu trên từng nhãn trong tập test:\n",
      "Chinh tri Xa hoi: 2152 mẫu\n",
      "Cong nghe: 1737 mẫu\n",
      "Doi song: 2038 mẫu\n",
      "Giai tri: 1825 mẫu\n",
      "Giao duc: 1837 mẫu\n",
      "Khoa hoc: 1959 mẫu\n",
      "Kinh doanh: 1819 mẫu\n",
      "Phap luat: 1918 mẫu\n",
      "Suc khoe: 1694 mẫu\n",
      "The gioi: 1877 mẫu\n",
      "The thao: 2062 mẫu\n",
      "Van hoa: 1946 mẫu\n",
      "\n",
      "Số lượng mẫu trên từng nhãn trong tập validation:\n",
      "Chinh tri Xa hoi: 2171 mẫu\n",
      "Cong nghe: 1610 mẫu\n",
      "Doi song: 2051 mẫu\n",
      "Giai tri: 1834 mẫu\n",
      "Giao duc: 1842 mẫu\n",
      "Khoa hoc: 1926 mẫu\n",
      "Kinh doanh: 1844 mẫu\n",
      "Phap luat: 1922 mẫu\n",
      "Suc khoe: 1782 mẫu\n",
      "The gioi: 1972 mẫu\n",
      "The thao: 2014 mẫu\n",
      "Van hoa: 1897 mẫu\n"
     ]
    }
   ],
   "source": [
    "counts_train = np.sum(y_train, axis=0)\n",
    "print(\"Số lượng mẫu trên từng nhãn trong tập train:\")\n",
    "for label, count in zip(y_train.columns, counts_train):\n",
    "    print(f\"{label}: {count} mẫu\")\n",
    "\n",
    "counts_test = np.sum(y_test, axis=0)\n",
    "print(\"\\nSố lượng mẫu trên từng nhãn trong tập test:\")\n",
    "for label, count in zip(y_test.columns, counts_test):\n",
    "    print(f\"{label}: {count} mẫu\")\n",
    "\n",
    "counts_val = np.sum(y_val, axis=0)\n",
    "print(\"\\nSố lượng mẫu trên từng nhãn trong tập validation:\")\n",
    "for label, count in zip(y_val.columns, counts_val):\n",
    "    print(f\"{label}: {count} mẫu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding matrix "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Word2Vec...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dim:  100\n",
      "Vocabulary size:  26313\n",
      "Shape of the embedding matrix: (26313, 100)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# In thông báo \"Load Word2Vec...\"\n",
    "print(\"Load Word2Vec...\")\n",
    "\n",
    "# Load mô hình Word2Vec từ đường dẫn đã chỉ định\n",
    "word2vec_model = Word2Vec.load(MODEL_FOLDER + sep + WORD2VEC_MODEL)\n",
    "\n",
    "# Lấy kích thước của vector embedding\n",
    "embedding_dim = word2vec_model.wv.vector_size \n",
    "print(\"Embedding dim: \", embedding_dim)\n",
    "\n",
    "# Xác định số lượng từ trong từ điển, không vượt quá số lượng từ trong mô hình Word2Vec\n",
    "num_words = min(len(word_index) + 1, len(word2vec_model.wv.vocab) + 1)\n",
    "print(\"Vocabulary size: \", num_words)\n",
    "\n",
    "# Khởi tạo ma trận embedding với tất cả giá trị là 0\n",
    "embedding_matrix_word2vec = np.zeros((num_words, embedding_dim))\n",
    "\n",
    "# Lặp qua từ điển từ và cập nhật ma trận embedding nếu từ đó có trong mô hình Word2Vec\n",
    "for word, i in word_index.items():\n",
    "    if i >= num_words:\n",
    "        continue\n",
    "    if word in word2vec_model.wv:\n",
    "        embedding_matrix_word2vec[i] = word2vec_model.wv[word]\n",
    "\n",
    "# In thông báo kiểm tra embedding_matrix\n",
    "print(\"Shape of the embedding matrix:\", embedding_matrix_word2vec.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Doc2Vec...\n",
      "Embedding dim:  100\n",
      "Vocabulary size:  26313\n",
      "Shape of the embedding matrix: (26313, 100)\n"
     ]
    }
   ],
   "source": [
    "# In thông báo \"Load Doc2Vec...\"\n",
    "print(\"Load Doc2Vec...\")\n",
    "\n",
    "# Load mô hình Word2Vec từ đường dẫn đã chỉ định\n",
    "doc2vec_model = Doc2Vec.load(MODEL_FOLDER + sep + DOC2VEC_MODEL)\n",
    "\n",
    "# Lấy kích thước của vector embedding\n",
    "embedding_dim = doc2vec_model.wv.vector_size \n",
    "print(\"Embedding dim: \", embedding_dim)\n",
    "\n",
    "# Xác định số lượng từ trong từ điển, không vượt quá số lượng từ trong mô hình Doc2Vec\n",
    "num_words = min(len(word_index) + 1, len(doc2vec_model.wv.vocab) + 1)\n",
    "print(\"Vocabulary size: \", num_words)\n",
    "\n",
    "# Khởi tạo ma trận embedding với tất cả giá trị là 0\n",
    "embedding_matrix_doc2vec = np.zeros((num_words, embedding_dim))\n",
    "\n",
    "# Lặp qua từ điển từ và cập nhật ma trận embedding nếu từ đó có trong mô hình Doc2Vec\n",
    "for word, i in word_index.items():\n",
    "    if i >= num_words:\n",
    "        continue\n",
    "    if word in doc2vec_model.wv:\n",
    "        embedding_matrix_doc2vec[i] = doc2vec_model.wv[word]\n",
    "\n",
    "# In thông báo kiểm tra embedding_matrix\n",
    "print(\"Shape of the embedding matrix:\", embedding_matrix_doc2vec.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_bilstm_model(lstm_units_1, lstm_units_2, dense_units, dropout_rate, learning_rate, embedding_matrix):\n",
    "    model = Sequential()\n",
    "    # Lớp Embedding với ma trận embedding đã được truyền vào\n",
    "    model.add(Embedding(input_dim=num_words, \n",
    "                        output_dim=embedding_dim, \n",
    "                        input_length=maxlen, \n",
    "                        weights=[embedding_matrix]))\n",
    "    # Lớp LSTM 1 với dropout\n",
    "    model.add(Bidirectional(LSTM(lstm_units_1, return_sequences=True)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    # Lớp LSTM 2 với dropout\n",
    "    model.add(Bidirectional(LSTM(lstm_units_2, return_sequences=False)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    # Lớp Dense với dropout và kích hoạt ReLU\n",
    "    model.add(Dense(dense_units, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    # Lớp Dense cuối cùng với kích hoạt softmax\n",
    "    model.add(Dense(12, activation='softmax'))\n",
    "    # Sử dụng tối ưu hóa Adam với learning rate được truyền vào\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    # Biên soạn mô hình\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_model(lstm_units_1, lstm_units_2, dense_units, dropout_rate, learning_rate, embedding_matrix):\n",
    "    model = Sequential()\n",
    "    # Lớp Embedding với ma trận embedding đã được truyền vào\n",
    "    model.add(Embedding(input_dim=num_words, \n",
    "                        output_dim=embedding_dim, \n",
    "                        input_length=maxlen, \n",
    "                        weights=[embedding_matrix]))\n",
    "    # Lớp LSTM 1 với dropout\n",
    "    model.add(LSTM(lstm_units_1, return_sequences=True))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    # Lớp LSTM 2 với dropout\n",
    "    model.add(LSTM(lstm_units_2, return_sequences=False))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    # Lớp Dense với dropout và kích hoạt ReLU\n",
    "    model.add(Dense(dense_units, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    # Lớp Dense cuối cùng với kích hoạt softmax\n",
    "    model.add(Dense(12, activation='softmax'))\n",
    "    # Sử dụng tối ưu hóa Adam với learning rate được truyền vào\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    \n",
    "    # Biên soạn mô hình\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_gru_model(gru_units_1, gru_units_2, dense_units, dropout_rate, learning_rate, embedding_matrix):\n",
    "    model = Sequential()\n",
    "    # Lớp Embedding với ma trận embedding đã được truyền vào\n",
    "    model.add(Embedding(input_dim=num_words, \n",
    "                        output_dim=embedding_dim, \n",
    "                        input_length=maxlen, \n",
    "                        weights=[embedding_matrix]))\n",
    "    # Lớp LSTM 1 với dropout\n",
    "    model.add(GRU(gru_units_1, return_sequences=True))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    # Lớp LSTM 2 với dropout\n",
    "    model.add(GRU(gru_units_2, return_sequences=False))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    # Lớp Dense với dropout và kích hoạt ReLU\n",
    "    model.add(Dense(dense_units, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    # Lớp Dense cuối cùng với kích hoạt softmax\n",
    "    model.add(Dense(12, activation='softmax'))\n",
    "    # Sử dụng tối ưu hóa Adam với learning rate được truyền vào\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    # Biên soạn mô hình\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_bilstm(trial, embedding_matrix):\n",
    "    lstm_units_1 = trial.suggest_int('lstm_units_1', 64, 512, step=32)\n",
    "    lstm_units_2 = trial.suggest_int('lstm_units_2', lstm_units_1//2, lstm_units_1, step=32)\n",
    "    dense_units = trial.suggest_int('dense_units', 64, 512, step=32)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.2, 0.5, step=0.1)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-2, log=True)\n",
    "    epochs = 10\n",
    "    batch_size = 256\n",
    "\n",
    "    print(f\"Trying hyperparameters: lstm_units_1={lstm_units_1}, lstm_units_2={lstm_units_2}, dense_units={dense_units}, \"\n",
    "          f\"dropout_rate={dropout_rate}, learning_rate={learning_rate}, batch_size={batch_size}\")\n",
    "\n",
    "    model = build_bilstm_model(lstm_units_1, lstm_units_2, dense_units, dropout_rate, learning_rate, embedding_matrix)\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,\n",
    "              validation_data=(X_val, y_val), callbacks=[TFKerasPruningCallback(trial, \"val_loss\")], verbose=1)\n",
    "\n",
    "    _, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_gru(trial, embedding_matrix ):\n",
    "    gru_units_1 = trial.suggest_int('gru_units_1', 64, 512, step=32)\n",
    "    gru_units_2 = trial.suggest_int('gru_units_2', 64, 512, step=32)\n",
    "    dense_units = trial.suggest_int('dense_units', 64, 512, step=32)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.2, 0.5, step=0.1)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-2, log=True)\n",
    "    epochs = 10\n",
    "    batch_size = 256\n",
    "\n",
    "    print(f\"Trying hyperparameters: gru_units_1={gru_units_1}, gru_units_2={gru_units_2}, dense_units={dense_units}, \"\n",
    "          f\"dropout_rate={dropout_rate}, learning_rate={learning_rate}, batch_size={batch_size}\")\n",
    "\n",
    "    model = build_gru_model(gru_units_1, gru_units_2, dense_units, dropout_rate, learning_rate, embedding_matrix)\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,\n",
    "              validation_data=(X_val, y_val), callbacks=[TFKerasPruningCallback(trial, \"val_loss\")], verbose=1)\n",
    "\n",
    "    _, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_lstm(trial, embedding_matrix):\n",
    "    lstm_units_1 = trial.suggest_int('lstm_units_1', 64, 512, step=32)\n",
    "    lstm_units_2 = trial.suggest_int('lstm_units_2', lstm_units_1//2, lstm_units_1, step=32)\n",
    "    dense_units = trial.suggest_int('dense_units', 64, 512, step=32)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.2, 0.5, step=0.1)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-2, log=True)\n",
    "    epochs = 20\n",
    "    batch_size = 256\n",
    "\n",
    "    print(f\"Trying hyperparameters: lstm_units_1={lstm_units_1}, lstm_units_2={lstm_units_2}, dense_units={dense_units}, \"\n",
    "          f\"dropout_rate={dropout_rate}, learning_rate={learning_rate}, batch_size={batch_size}\")\n",
    "\n",
    "    model = build_lstm_model(lstm_units_1, lstm_units_2, dense_units, dropout_rate, learning_rate, embedding_matrix)\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,\n",
    "              validation_data=(X_val, y_val), callbacks=[TFKerasPruningCallback(trial, \"val_loss\")], verbose=1)\n",
    "\n",
    "    _, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "    return accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create study and optimize "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### with Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = embedding_matrix_word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying hyperparameters: lstm_units_1=160, lstm_units_2=144, dense_units=192, dropout_rate=0.2, learning_rate=0.0009390052419240196, batch_size=256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 18:01:21.851330: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-12-10 18:01:21.853018: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2023-12-10 18:01:24.722794: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:88:00.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2023-12-10 18:01:24.723560: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:89:00.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2023-12-10 18:01:24.724293: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 2 with properties: \n",
      "pciBusID: 0000:b1:00.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2023-12-10 18:01:24.724997: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 3 with properties: \n",
      "pciBusID: 0000:b2:00.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2023-12-10 18:01:24.725019: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-12-10 18:01:24.730221: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-12-10 18:01:24.730301: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-12-10 18:01:24.733909: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-12-10 18:01:24.734211: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-12-10 18:01:24.738520: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-12-10 18:01:24.741022: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-12-10 18:01:24.748780: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-12-10 18:01:24.754419: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1, 2, 3\n",
      "2023-12-10 18:01:24.758090: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-10 18:01:24.764661: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-12-10 18:01:25.130870: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:88:00.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2023-12-10 18:01:25.131696: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:89:00.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2023-12-10 18:01:25.132457: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 2 with properties: \n",
      "pciBusID: 0000:b1:00.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2023-12-10 18:01:25.133217: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 3 with properties: \n",
      "pciBusID: 0000:b2:00.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2023-12-10 18:01:25.133252: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-12-10 18:01:25.133291: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-12-10 18:01:25.133303: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-12-10 18:01:25.133315: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-12-10 18:01:25.133326: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-12-10 18:01:25.133338: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-12-10 18:01:25.133349: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-12-10 18:01:25.133360: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-12-10 18:01:25.139097: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1, 2, 3\n",
      "2023-12-10 18:01:25.139131: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-12-10 18:01:26.911824: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-12-10 18:01:26.911860: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 2 3 \n",
      "2023-12-10 18:01:26.911865: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N Y Y Y \n",
      "2023-12-10 18:01:26.911868: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   Y N Y Y \n",
      "2023-12-10 18:01:26.911871: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 2:   Y Y N Y \n",
      "2023-12-10 18:01:26.911874: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 3:   Y Y Y N \n",
      "2023-12-10 18:01:26.916548: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13970 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:88:00.0, compute capability: 7.5)\n",
      "2023-12-10 18:01:26.918815: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 13970 MB memory) -> physical GPU (device: 1, name: Tesla T4, pci bus id: 0000:89:00.0, compute capability: 7.5)\n",
      "2023-12-10 18:01:26.920764: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 13970 MB memory) -> physical GPU (device: 2, name: Tesla T4, pci bus id: 0000:b1:00.0, compute capability: 7.5)\n",
      "2023-12-10 18:01:26.922632: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 13970 MB memory) -> physical GPU (device: 3, name: Tesla T4, pci bus id: 0000:b2:00.0, compute capability: 7.5)\n",
      "2023-12-10 18:01:28.790995: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2023-12-10 18:01:28.811764: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2100000000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 18:01:30.684235: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-12-10 18:01:31.009533: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 26s 86ms/step - loss: 1.8042 - accuracy: 0.3529 - val_loss: 1.4355 - val_accuracy: 0.4984\n",
      "Epoch 2/15\n",
      "268/268 [==============================] - 22s 83ms/step - loss: 1.6632 - accuracy: 0.4139 - val_loss: 1.4792 - val_accuracy: 0.4830\n",
      "Epoch 3/15\n",
      "268/268 [==============================] - 22s 83ms/step - loss: 1.4294 - accuracy: 0.5038 - val_loss: 1.2048 - val_accuracy: 0.5882\n",
      "Epoch 4/15\n",
      "268/268 [==============================] - 22s 82ms/step - loss: 1.2582 - accuracy: 0.5661 - val_loss: 1.0259 - val_accuracy: 0.6489\n",
      "Epoch 5/15\n",
      "268/268 [==============================] - 22s 83ms/step - loss: 1.0605 - accuracy: 0.6379 - val_loss: 0.9743 - val_accuracy: 0.6620\n",
      "Epoch 6/15\n",
      "268/268 [==============================] - 22s 83ms/step - loss: 1.0286 - accuracy: 0.6442 - val_loss: 1.1194 - val_accuracy: 0.5981\n",
      "Epoch 7/15\n",
      "268/268 [==============================] - 22s 83ms/step - loss: 1.0529 - accuracy: 0.6333 - val_loss: 1.0307 - val_accuracy: 0.6438\n",
      "Epoch 8/15\n",
      "268/268 [==============================] - 22s 83ms/step - loss: 1.1594 - accuracy: 0.5954 - val_loss: 1.0569 - val_accuracy: 0.6315\n",
      "Epoch 9/15\n",
      "268/268 [==============================] - 22s 83ms/step - loss: 1.0053 - accuracy: 0.6501 - val_loss: 0.8824 - val_accuracy: 0.6884\n",
      "Epoch 10/15\n",
      "268/268 [==============================] - 22s 83ms/step - loss: 0.8731 - accuracy: 0.6913 - val_loss: 0.7534 - val_accuracy: 0.7303\n",
      "Epoch 11/15\n",
      "268/268 [==============================] - 22s 83ms/step - loss: 0.7642 - accuracy: 0.7343 - val_loss: 0.7022 - val_accuracy: 0.7495\n",
      "Epoch 12/15\n",
      "268/268 [==============================] - 22s 83ms/step - loss: 0.7059 - accuracy: 0.7526 - val_loss: 0.6553 - val_accuracy: 0.7660\n",
      "Epoch 13/15\n",
      "268/268 [==============================] - 22s 82ms/step - loss: 0.6476 - accuracy: 0.7749 - val_loss: 0.6109 - val_accuracy: 0.7869\n",
      "Epoch 14/15\n",
      "268/268 [==============================] - 22s 83ms/step - loss: 0.5994 - accuracy: 0.7948 - val_loss: 0.5813 - val_accuracy: 0.7963\n",
      "Epoch 15/15\n",
      "268/268 [==============================] - 22s 83ms/step - loss: 0.5480 - accuracy: 0.8121 - val_loss: 0.5417 - val_accuracy: 0.8136\n",
      "Trying hyperparameters: lstm_units_1=64, lstm_units_2=64, dense_units=64, dropout_rate=0.5, learning_rate=0.0002926309183622114, batch_size=256\n",
      "Epoch 1/15\n",
      "268/268 [==============================] - 18s 59ms/step - loss: 2.2287 - accuracy: 0.2093 - val_loss: 1.4689 - val_accuracy: 0.4581\n",
      "Epoch 2/15\n",
      "268/268 [==============================] - 15s 57ms/step - loss: 1.5202 - accuracy: 0.4472 - val_loss: 1.3752 - val_accuracy: 0.4943\n",
      "Epoch 3/15\n",
      "268/268 [==============================] - 15s 57ms/step - loss: 1.4434 - accuracy: 0.5002 - val_loss: 1.3074 - val_accuracy: 0.5480\n",
      "Epoch 4/15\n",
      "268/268 [==============================] - 15s 57ms/step - loss: 1.3222 - accuracy: 0.5463 - val_loss: 1.2027 - val_accuracy: 0.5784\n",
      "Epoch 5/15\n",
      "268/268 [==============================] - 15s 57ms/step - loss: 1.3785 - accuracy: 0.5154 - val_loss: 1.3494 - val_accuracy: 0.5014\n",
      "Epoch 6/15\n",
      "268/268 [==============================] - 15s 57ms/step - loss: 1.3857 - accuracy: 0.5045 - val_loss: 1.3122 - val_accuracy: 0.5217\n",
      "Epoch 7/15\n",
      "268/268 [==============================] - 15s 57ms/step - loss: 1.3202 - accuracy: 0.5325 - val_loss: 1.2155 - val_accuracy: 0.5742\n",
      "Epoch 8/15\n",
      "268/268 [==============================] - 15s 57ms/step - loss: 1.2830 - accuracy: 0.5645 - val_loss: 1.3506 - val_accuracy: 0.5106\n",
      "Epoch 9/15\n",
      "268/268 [==============================] - 15s 56ms/step - loss: 1.3171 - accuracy: 0.5384 - val_loss: 1.1615 - val_accuracy: 0.5831\n",
      "Epoch 10/15\n",
      "268/268 [==============================] - 15s 56ms/step - loss: 1.2169 - accuracy: 0.5715 - val_loss: 1.1713 - val_accuracy: 0.5716\n",
      "Epoch 11/15\n",
      "268/268 [==============================] - 15s 57ms/step - loss: 1.2057 - accuracy: 0.5600 - val_loss: 1.3116 - val_accuracy: 0.5206\n",
      "Epoch 12/15\n",
      "268/268 [==============================] - 15s 56ms/step - loss: 1.2899 - accuracy: 0.5390 - val_loss: 1.1209 - val_accuracy: 0.5851\n",
      "Epoch 13/15\n",
      "268/268 [==============================] - 15s 57ms/step - loss: 1.1763 - accuracy: 0.5814 - val_loss: 1.1181 - val_accuracy: 0.5913\n",
      "Epoch 14/15\n",
      "268/268 [==============================] - 15s 57ms/step - loss: 1.1419 - accuracy: 0.5932 - val_loss: 1.0821 - val_accuracy: 0.6105\n",
      "Epoch 15/15\n",
      "268/268 [==============================] - 15s 57ms/step - loss: 1.1130 - accuracy: 0.6093 - val_loss: 1.0534 - val_accuracy: 0.6297\n",
      "Trying hyperparameters: lstm_units_1=256, lstm_units_2=192, dense_units=96, dropout_rate=0.30000000000000004, learning_rate=0.0017594777792019648, batch_size=256\n",
      "Epoch 1/15\n",
      "268/268 [==============================] - 35s 120ms/step - loss: 1.9319 - accuracy: 0.3239 - val_loss: 1.0457 - val_accuracy: 0.6296\n",
      "Epoch 2/15\n",
      "268/268 [==============================] - 32s 119ms/step - loss: 1.0104 - accuracy: 0.6503 - val_loss: 0.7473 - val_accuracy: 0.7323\n",
      "Epoch 3/15\n",
      "268/268 [==============================] - 32s 119ms/step - loss: 0.7632 - accuracy: 0.7430 - val_loss: 0.7394 - val_accuracy: 0.7380\n",
      "Epoch 4/15\n",
      "268/268 [==============================] - 32s 120ms/step - loss: 0.7161 - accuracy: 0.7589 - val_loss: 0.6188 - val_accuracy: 0.7888\n",
      "Epoch 5/15\n",
      "268/268 [==============================] - 32s 120ms/step - loss: 0.5850 - accuracy: 0.8056 - val_loss: 0.5428 - val_accuracy: 0.8177\n",
      "Epoch 6/15\n",
      "268/268 [==============================] - 32s 120ms/step - loss: 0.4921 - accuracy: 0.8374 - val_loss: 0.5290 - val_accuracy: 0.8262\n",
      "Epoch 7/15\n",
      "268/268 [==============================] - 32s 120ms/step - loss: 0.4419 - accuracy: 0.8547 - val_loss: 0.4676 - val_accuracy: 0.8452\n",
      "Epoch 8/15\n",
      "268/268 [==============================] - 32s 120ms/step - loss: 0.3809 - accuracy: 0.8755 - val_loss: 0.4484 - val_accuracy: 0.8547\n",
      "Epoch 9/15\n",
      "268/268 [==============================] - 32s 120ms/step - loss: 0.3303 - accuracy: 0.8941 - val_loss: 0.4358 - val_accuracy: 0.8616\n",
      "Epoch 10/15\n",
      "268/268 [==============================] - 32s 120ms/step - loss: 0.2865 - accuracy: 0.9082 - val_loss: 0.4454 - val_accuracy: 0.8619\n",
      "Epoch 11/15\n",
      "268/268 [==============================] - 32s 120ms/step - loss: 0.2497 - accuracy: 0.9210 - val_loss: 0.4488 - val_accuracy: 0.8623\n",
      "Epoch 12/15\n",
      "268/268 [==============================] - 32s 121ms/step - loss: 0.2063 - accuracy: 0.9364 - val_loss: 0.4727 - val_accuracy: 0.8668\n",
      "Epoch 13/15\n",
      "268/268 [==============================] - 32s 120ms/step - loss: 0.1846 - accuracy: 0.9426 - val_loss: 0.4614 - val_accuracy: 0.8652\n",
      "Epoch 14/15\n",
      "268/268 [==============================] - 32s 120ms/step - loss: 0.1889 - accuracy: 0.9403 - val_loss: 0.4935 - val_accuracy: 0.8617\n",
      "Epoch 15/15\n",
      "268/268 [==============================] - 32s 121ms/step - loss: 0.1381 - accuracy: 0.9582 - val_loss: 0.5021 - val_accuracy: 0.8672\n",
      "Trying hyperparameters: lstm_units_1=128, lstm_units_2=96, dense_units=416, dropout_rate=0.2, learning_rate=0.00038918700543874135, batch_size=256\n",
      "Epoch 1/15\n",
      "268/268 [==============================] - 21s 70ms/step - loss: 1.9181 - accuracy: 0.3186 - val_loss: 1.6533 - val_accuracy: 0.3777\n",
      "Epoch 2/15\n",
      "268/268 [==============================] - 18s 68ms/step - loss: 1.6020 - accuracy: 0.4469 - val_loss: 1.2834 - val_accuracy: 0.5627\n",
      "Epoch 3/15\n",
      "268/268 [==============================] - 18s 67ms/step - loss: 1.2659 - accuracy: 0.5628 - val_loss: 1.1128 - val_accuracy: 0.6087\n",
      "Epoch 4/15\n",
      "268/268 [==============================] - 18s 68ms/step - loss: 1.1358 - accuracy: 0.6084 - val_loss: 1.0393 - val_accuracy: 0.6500\n",
      "Epoch 5/15\n",
      "268/268 [==============================] - 18s 68ms/step - loss: 1.0362 - accuracy: 0.6558 - val_loss: 1.1462 - val_accuracy: 0.6079\n",
      "Epoch 6/15\n",
      "268/268 [==============================] - 18s 68ms/step - loss: 1.1944 - accuracy: 0.5922 - val_loss: 1.0300 - val_accuracy: 0.6375\n",
      "Epoch 7/15\n",
      "268/268 [==============================] - 18s 68ms/step - loss: 1.0648 - accuracy: 0.6358 - val_loss: 1.0312 - val_accuracy: 0.6347\n",
      "Epoch 8/15\n",
      "268/268 [==============================] - 18s 69ms/step - loss: 1.1327 - accuracy: 0.6177 - val_loss: 1.0740 - val_accuracy: 0.6335\n",
      "Epoch 9/15\n",
      "268/268 [==============================] - 18s 68ms/step - loss: 1.0862 - accuracy: 0.6335 - val_loss: 1.0325 - val_accuracy: 0.6373\n",
      "Epoch 10/15\n",
      "268/268 [==============================] - 18s 68ms/step - loss: 1.0632 - accuracy: 0.6258 - val_loss: 1.0979 - val_accuracy: 0.6368\n",
      "Epoch 11/15\n",
      "268/268 [==============================] - 18s 68ms/step - loss: 1.0894 - accuracy: 0.6412 - val_loss: 0.9698 - val_accuracy: 0.6815\n",
      "Epoch 12/15\n",
      "268/268 [==============================] - 18s 68ms/step - loss: 0.9975 - accuracy: 0.6715 - val_loss: 0.9391 - val_accuracy: 0.6991\n",
      "Epoch 13/15\n",
      "268/268 [==============================] - 18s 68ms/step - loss: 1.0201 - accuracy: 0.6675 - val_loss: 0.9265 - val_accuracy: 0.6899\n",
      "Epoch 14/15\n",
      "268/268 [==============================] - 18s 68ms/step - loss: 0.9317 - accuracy: 0.6950 - val_loss: 0.9351 - val_accuracy: 0.6906\n",
      "Epoch 15/15\n",
      "268/268 [==============================] - 18s 68ms/step - loss: 0.9203 - accuracy: 0.6975 - val_loss: 0.8694 - val_accuracy: 0.7112\n",
      "Trying hyperparameters: lstm_units_1=192, lstm_units_2=160, dense_units=352, dropout_rate=0.5, learning_rate=0.00021759003517509337, batch_size=256\n",
      "Epoch 1/15\n",
      "268/268 [==============================] - 28s 97ms/step - loss: 1.9922 - accuracy: 0.2972 - val_loss: 1.3499 - val_accuracy: 0.5234\n",
      "Epoch 2/15\n",
      "268/268 [==============================] - 25s 95ms/step - loss: 1.2599 - accuracy: 0.5566 - val_loss: 1.2316 - val_accuracy: 0.5668\n",
      "Epoch 3/15\n",
      "268/268 [==============================] - 25s 95ms/step - loss: 1.2532 - accuracy: 0.5787 - val_loss: 1.1622 - val_accuracy: 0.5996\n",
      "Epoch 4/15\n",
      "268/268 [==============================] - 26s 95ms/step - loss: 1.2479 - accuracy: 0.5863 - val_loss: 1.2327 - val_accuracy: 0.5939\n",
      "Epoch 5/15\n",
      "268/268 [==============================] - 26s 95ms/step - loss: 1.2071 - accuracy: 0.6011 - val_loss: 1.1289 - val_accuracy: 0.6162\n",
      "Epoch 6/15\n",
      "268/268 [==============================] - 26s 95ms/step - loss: 1.1692 - accuracy: 0.6104 - val_loss: 1.1269 - val_accuracy: 0.6255\n",
      "Epoch 7/15\n",
      "268/268 [==============================] - 25s 95ms/step - loss: 1.4073 - accuracy: 0.5303 - val_loss: 1.3590 - val_accuracy: 0.5180\n",
      "Epoch 8/15\n",
      "268/268 [==============================] - 26s 95ms/step - loss: 1.3962 - accuracy: 0.5119 - val_loss: 1.5317 - val_accuracy: 0.4905\n",
      "Epoch 9/15\n",
      "268/268 [==============================] - 26s 95ms/step - loss: 1.4438 - accuracy: 0.4945 - val_loss: 1.2371 - val_accuracy: 0.5687\n",
      "Epoch 10/15\n",
      "268/268 [==============================] - 25s 95ms/step - loss: 1.2762 - accuracy: 0.5546 - val_loss: 1.1507 - val_accuracy: 0.6096\n",
      "Epoch 11/15\n",
      "268/268 [==============================] - 26s 95ms/step - loss: 1.2062 - accuracy: 0.5790 - val_loss: 1.0370 - val_accuracy: 0.6524\n",
      "Epoch 12/15\n",
      "268/268 [==============================] - 26s 95ms/step - loss: 1.0809 - accuracy: 0.6406 - val_loss: 0.9979 - val_accuracy: 0.6606\n",
      "Epoch 13/15\n",
      "268/268 [==============================] - 26s 95ms/step - loss: 1.0323 - accuracy: 0.6553 - val_loss: 1.0645 - val_accuracy: 0.6158\n",
      "Epoch 14/15\n",
      "268/268 [==============================] - 26s 95ms/step - loss: 1.0902 - accuracy: 0.6184 - val_loss: 1.0603 - val_accuracy: 0.6238\n",
      "Epoch 15/15\n",
      "268/268 [==============================] - 25s 95ms/step - loss: 1.1112 - accuracy: 0.6168 - val_loss: 1.0413 - val_accuracy: 0.6349\n",
      "Trying hyperparameters: lstm_units_1=480, lstm_units_2=336, dense_units=512, dropout_rate=0.5, learning_rate=0.005859212429028231, batch_size=256\n",
      "Epoch 1/15\n",
      "268/268 [==============================] - 80s 291ms/step - loss: 2.2517 - accuracy: 0.1907 - val_loss: 1.4358 - val_accuracy: 0.4562\n",
      "Epoch 2/15\n",
      "268/268 [==============================] - 78s 291ms/step - loss: 1.2222 - accuracy: 0.5498 - val_loss: 0.7866 - val_accuracy: 0.7181\n",
      "Epoch 3/15\n",
      "268/268 [==============================] - 78s 292ms/step - loss: 0.7324 - accuracy: 0.7433 - val_loss: 0.5955 - val_accuracy: 0.8065\n",
      "Epoch 4/15\n",
      "268/268 [==============================] - 78s 292ms/step - loss: 0.5424 - accuracy: 0.8266 - val_loss: 0.5644 - val_accuracy: 0.8224\n",
      "Trying hyperparameters: lstm_units_1=480, lstm_units_2=304, dense_units=384, dropout_rate=0.5, learning_rate=0.0043696646937675864, batch_size=256\n",
      "Epoch 1/15\n",
      "268/268 [==============================] - 76s 275ms/step - loss: 1.9133 - accuracy: 0.3438 - val_loss: 1.0079 - val_accuracy: 0.6261\n",
      "Epoch 2/15\n",
      "268/268 [==============================] - 73s 274ms/step - loss: 0.9736 - accuracy: 0.6549 - val_loss: 0.7304 - val_accuracy: 0.7348\n",
      "Trying hyperparameters: lstm_units_1=64, lstm_units_2=32, dense_units=512, dropout_rate=0.2, learning_rate=0.00027117237544933766, batch_size=256\n",
      "Epoch 1/15\n",
      "268/268 [==============================] - 20s 62ms/step - loss: 2.1995 - accuracy: 0.2243 - val_loss: 1.4426 - val_accuracy: 0.4688\n",
      "Epoch 2/15\n",
      "268/268 [==============================] - 16s 59ms/step - loss: 1.4383 - accuracy: 0.4834 - val_loss: 1.3191 - val_accuracy: 0.5355\n",
      "Epoch 3/15\n",
      "268/268 [==============================] - 16s 61ms/step - loss: 1.3452 - accuracy: 0.5275 - val_loss: 1.2486 - val_accuracy: 0.5632\n",
      "Epoch 4/15\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 1.2560 - accuracy: 0.5669 - val_loss: 1.1776 - val_accuracy: 0.5936\n",
      "Trying hyperparameters: lstm_units_1=352, lstm_units_2=176, dense_units=416, dropout_rate=0.4, learning_rate=0.0024761585724771256, batch_size=256\n",
      "Epoch 1/15\n",
      "268/268 [==============================] - 45s 161ms/step - loss: 1.8965 - accuracy: 0.3387 - val_loss: 1.0168 - val_accuracy: 0.6247\n",
      "Epoch 2/15\n",
      "268/268 [==============================] - 43s 160ms/step - loss: 0.9238 - accuracy: 0.6732 - val_loss: 0.6894 - val_accuracy: 0.7589\n",
      "Epoch 3/15\n",
      "268/268 [==============================] - 43s 160ms/step - loss: 0.6566 - accuracy: 0.7738 - val_loss: 0.5584 - val_accuracy: 0.8073\n",
      "Epoch 4/15\n",
      "268/268 [==============================] - 43s 161ms/step - loss: 0.5209 - accuracy: 0.8253 - val_loss: 0.5001 - val_accuracy: 0.8310\n",
      "Trying hyperparameters: lstm_units_1=224, lstm_units_2=176, dense_units=416, dropout_rate=0.4, learning_rate=0.006464860947958475, batch_size=256\n",
      "Epoch 1/15\n",
      "268/268 [==============================] - 32s 114ms/step - loss: 1.6675 - accuracy: 0.4160 - val_loss: 0.6903 - val_accuracy: 0.7561\n",
      "Epoch 2/15\n",
      "268/268 [==============================] - 30s 112ms/step - loss: 0.6869 - accuracy: 0.7668 - val_loss: 0.5524 - val_accuracy: 0.8168\n",
      "Epoch 3/15\n",
      "268/268 [==============================] - 30s 111ms/step - loss: 0.4996 - accuracy: 0.8377 - val_loss: 0.4594 - val_accuracy: 0.8497\n",
      "Epoch 4/15\n",
      "268/268 [==============================] - 30s 112ms/step - loss: 0.3739 - accuracy: 0.8820 - val_loss: 0.4607 - val_accuracy: 0.8536\n",
      "Trying hyperparameters: lstm_units_1=288, lstm_units_2=240, dense_units=96, dropout_rate=0.30000000000000004, learning_rate=0.0015744571506486546, batch_size=256\n",
      "Epoch 1/15\n",
      "268/268 [==============================] - 46s 158ms/step - loss: 1.8789 - accuracy: 0.3333 - val_loss: 0.9355 - val_accuracy: 0.6695\n",
      "Epoch 2/15\n",
      "268/268 [==============================] - 42s 157ms/step - loss: 0.8559 - accuracy: 0.7058 - val_loss: 0.6917 - val_accuracy: 0.7540\n",
      "Epoch 3/15\n",
      "268/268 [==============================] - 42s 157ms/step - loss: 0.6691 - accuracy: 0.7687 - val_loss: 0.6018 - val_accuracy: 0.7972\n",
      "Epoch 4/15\n",
      "268/268 [==============================] - 42s 157ms/step - loss: 0.5639 - accuracy: 0.8118 - val_loss: 0.5188 - val_accuracy: 0.8236\n",
      "Epoch 5/15\n",
      "268/268 [==============================] - 42s 156ms/step - loss: 0.4830 - accuracy: 0.8406 - val_loss: 0.4787 - val_accuracy: 0.8399\n",
      "Epoch 6/15\n",
      "268/268 [==============================] - 42s 156ms/step - loss: 0.4221 - accuracy: 0.8595 - val_loss: 0.4544 - val_accuracy: 0.8497\n",
      "Epoch 7/15\n",
      "268/268 [==============================] - 42s 157ms/step - loss: 0.3769 - accuracy: 0.8762 - val_loss: 0.4302 - val_accuracy: 0.8576\n",
      "Epoch 8/15\n",
      "268/268 [==============================] - 42s 157ms/step - loss: 0.3217 - accuracy: 0.8954 - val_loss: 0.4161 - val_accuracy: 0.8656\n",
      "Epoch 9/15\n",
      "268/268 [==============================] - 42s 157ms/step - loss: 0.2766 - accuracy: 0.9110 - val_loss: 0.4244 - val_accuracy: 0.8656\n",
      "Epoch 10/15\n",
      "268/268 [==============================] - 42s 157ms/step - loss: 0.2407 - accuracy: 0.9214 - val_loss: 0.4193 - val_accuracy: 0.8702\n",
      "Epoch 11/15\n",
      "268/268 [==============================] - 42s 157ms/step - loss: 0.1996 - accuracy: 0.9360 - val_loss: 0.4459 - val_accuracy: 0.8698\n",
      "Epoch 12/15\n",
      "268/268 [==============================] - 42s 157ms/step - loss: 0.1695 - accuracy: 0.9459 - val_loss: 0.4774 - val_accuracy: 0.8668\n",
      "Epoch 13/15\n",
      "268/268 [==============================] - 42s 156ms/step - loss: 0.1565 - accuracy: 0.9498 - val_loss: 0.4700 - val_accuracy: 0.8725\n",
      "Epoch 14/15\n",
      "268/268 [==============================] - 42s 157ms/step - loss: 0.1174 - accuracy: 0.9627 - val_loss: 0.5045 - val_accuracy: 0.8698\n",
      "Epoch 15/15\n",
      "268/268 [==============================] - 42s 157ms/step - loss: 0.0985 - accuracy: 0.9697 - val_loss: 0.5218 - val_accuracy: 0.8714\n",
      "Trying hyperparameters: lstm_units_1=352, lstm_units_2=240, dense_units=64, dropout_rate=0.30000000000000004, learning_rate=0.0012875090360000038, batch_size=256\n",
      "Epoch 1/15\n",
      "268/268 [==============================] - 51s 182ms/step - loss: 1.8502 - accuracy: 0.3418 - val_loss: 1.3783 - val_accuracy: 0.5081\n",
      "Epoch 2/15\n",
      "268/268 [==============================] - 48s 180ms/step - loss: 1.1192 - accuracy: 0.6065 - val_loss: 0.7367 - val_accuracy: 0.7340\n",
      "Epoch 3/15\n",
      "268/268 [==============================] - 48s 180ms/step - loss: 0.7334 - accuracy: 0.7417 - val_loss: 0.6473 - val_accuracy: 0.7733\n",
      "Epoch 4/15\n",
      "268/268 [==============================] - 48s 180ms/step - loss: 0.6261 - accuracy: 0.7870 - val_loss: 0.5924 - val_accuracy: 0.7874\n",
      "Trying hyperparameters: lstm_units_1=288, lstm_units_2=240, dense_units=192, dropout_rate=0.30000000000000004, learning_rate=0.0020946722894479393, batch_size=256\n",
      "Epoch 1/15\n",
      "268/268 [==============================] - 44s 158ms/step - loss: 1.7965 - accuracy: 0.3720 - val_loss: 1.0264 - val_accuracy: 0.6356\n",
      "Epoch 2/15\n",
      "268/268 [==============================] - 42s 156ms/step - loss: 0.9067 - accuracy: 0.6849 - val_loss: 0.7219 - val_accuracy: 0.7563\n",
      "Trying hyperparameters: lstm_units_1=288, lstm_units_2=240, dense_units=160, dropout_rate=0.30000000000000004, learning_rate=0.0007415277064755045, batch_size=256\n",
      "Epoch 1/15\n",
      "268/268 [==============================] - 44s 158ms/step - loss: 1.7601 - accuracy: 0.3779 - val_loss: 1.3555 - val_accuracy: 0.5355\n",
      "Epoch 2/15\n",
      "268/268 [==============================] - 42s 156ms/step - loss: 1.2539 - accuracy: 0.5696 - val_loss: 1.2500 - val_accuracy: 0.5491\n",
      "Trying hyperparameters: lstm_units_1=352, lstm_units_2=272, dense_units=128, dropout_rate=0.30000000000000004, learning_rate=0.00010452270037211634, batch_size=256\n",
      "Epoch 1/15\n",
      "268/268 [==============================] - 55s 198ms/step - loss: 1.9892 - accuracy: 0.3078 - val_loss: 1.2775 - val_accuracy: 0.5490\n",
      "Epoch 2/15\n",
      "268/268 [==============================] - 53s 197ms/step - loss: 1.3178 - accuracy: 0.5327 - val_loss: 1.0601 - val_accuracy: 0.6471\n",
      "Epoch 3/15\n",
      "268/268 [==============================] - 53s 198ms/step - loss: 1.0445 - accuracy: 0.6500 - val_loss: 0.9322 - val_accuracy: 0.7026\n",
      "Epoch 4/15\n",
      "268/268 [==============================] - 53s 197ms/step - loss: 0.9945 - accuracy: 0.6737 - val_loss: 0.9012 - val_accuracy: 0.6922\n",
      "Trying hyperparameters: lstm_units_1=416, lstm_units_2=400, dense_units=256, dropout_rate=0.4, learning_rate=0.009193522165302285, batch_size=256\n",
      "Epoch 1/15\n",
      "268/268 [==============================] - 82s 294ms/step - loss: 1.8796 - accuracy: 0.3500 - val_loss: 0.7834 - val_accuracy: 0.7309\n",
      "Epoch 2/15\n",
      "268/268 [==============================] - 78s 293ms/step - loss: 0.7146 - accuracy: 0.7522 - val_loss: 0.5563 - val_accuracy: 0.8140\n",
      "Epoch 3/15\n",
      "268/268 [==============================] - 79s 294ms/step - loss: 0.5135 - accuracy: 0.8340 - val_loss: 0.5235 - val_accuracy: 0.8343\n",
      "Epoch 4/15\n",
      "268/268 [==============================] - 79s 295ms/step - loss: 0.4140 - accuracy: 0.8686 - val_loss: 0.5160 - val_accuracy: 0.8368\n",
      "Trying hyperparameters: lstm_units_1=256, lstm_units_2=192, dense_units=256, dropout_rate=0.30000000000000004, learning_rate=0.002542043321115942, batch_size=256\n",
      "Epoch 1/15\n",
      "268/268 [==============================] - 35s 122ms/step - loss: 1.8859 - accuracy: 0.3353 - val_loss: 1.0632 - val_accuracy: 0.6257\n",
      "Epoch 2/15\n",
      "268/268 [==============================] - 32s 120ms/step - loss: 0.9607 - accuracy: 0.6650 - val_loss: 0.6614 - val_accuracy: 0.7607\n",
      "Epoch 3/15\n",
      "268/268 [==============================] - 32s 120ms/step - loss: 0.6392 - accuracy: 0.7772 - val_loss: 0.5635 - val_accuracy: 0.8058\n",
      "Epoch 4/15\n",
      "268/268 [==============================] - 32s 120ms/step - loss: 0.5172 - accuracy: 0.8257 - val_loss: 0.4973 - val_accuracy: 0.8315\n",
      "Trying hyperparameters: lstm_units_1=416, lstm_units_2=272, dense_units=128, dropout_rate=0.4, learning_rate=0.0013969465167280254, batch_size=256\n",
      "Epoch 1/15\n",
      "268/268 [==============================] - 65s 236ms/step - loss: 2.1395 - accuracy: 0.2434 - val_loss: 1.3235 - val_accuracy: 0.5350\n",
      "Epoch 2/15\n",
      "268/268 [==============================] - 63s 235ms/step - loss: 1.2212 - accuracy: 0.5659 - val_loss: 0.7669 - val_accuracy: 0.7344\n",
      "Trying hyperparameters: lstm_units_1=128, lstm_units_2=96, dense_units=96, dropout_rate=0.2, learning_rate=0.0007398629474488835, batch_size=256\n",
      "Epoch 1/15\n",
      "268/268 [==============================] - 22s 70ms/step - loss: 1.8777 - accuracy: 0.3302 - val_loss: 1.5309 - val_accuracy: 0.4346\n",
      "Epoch 2/15\n",
      "268/268 [==============================] - 18s 68ms/step - loss: 1.5315 - accuracy: 0.4354 - val_loss: 1.4260 - val_accuracy: 0.4852\n",
      "Epoch 3/15\n",
      "268/268 [==============================] - 18s 68ms/step - loss: 1.6815 - accuracy: 0.4112 - val_loss: 1.4513 - val_accuracy: 0.5015\n",
      "Epoch 4/15\n",
      "268/268 [==============================] - 18s 67ms/step - loss: 1.4212 - accuracy: 0.5001 - val_loss: 1.2585 - val_accuracy: 0.5692\n",
      "Epoch 5/15\n",
      "268/268 [==============================] - 18s 68ms/step - loss: 1.2744 - accuracy: 0.5569 - val_loss: 1.1737 - val_accuracy: 0.5875\n",
      "Epoch 6/15\n",
      "268/268 [==============================] - 18s 68ms/step - loss: 1.2177 - accuracy: 0.5797 - val_loss: 1.1010 - val_accuracy: 0.6244\n",
      "Epoch 7/15\n",
      "268/268 [==============================] - 18s 68ms/step - loss: 1.0690 - accuracy: 0.6336 - val_loss: 0.9921 - val_accuracy: 0.6583\n",
      "Epoch 8/15\n",
      "268/268 [==============================] - 18s 67ms/step - loss: 1.0397 - accuracy: 0.6441 - val_loss: 0.9811 - val_accuracy: 0.6617\n",
      "Epoch 9/15\n",
      "268/268 [==============================] - 18s 68ms/step - loss: 0.9612 - accuracy: 0.6633 - val_loss: 0.8850 - val_accuracy: 0.6829\n",
      "Epoch 10/15\n",
      "268/268 [==============================] - 18s 68ms/step - loss: 0.9433 - accuracy: 0.6727 - val_loss: 0.8408 - val_accuracy: 0.6945\n",
      "Trying hyperparameters: lstm_units_1=224, lstm_units_2=176, dense_units=320, dropout_rate=0.30000000000000004, learning_rate=0.003742838479379268, batch_size=256\n",
      "Epoch 1/15\n",
      "268/268 [==============================] - 32s 113ms/step - loss: 1.9811 - accuracy: 0.3218 - val_loss: 0.9705 - val_accuracy: 0.6460\n",
      "Epoch 2/15\n",
      "268/268 [==============================] - 30s 111ms/step - loss: 0.9010 - accuracy: 0.6746 - val_loss: 0.6835 - val_accuracy: 0.7386\n",
      "Trying hyperparameters: lstm_units_1=288, lstm_units_2=208, dense_units=224, dropout_rate=0.4, learning_rate=0.0015719449082859445, batch_size=256\n",
      "Epoch 1/15\n",
      "268/268 [==============================] - 42s 150ms/step - loss: 2.0234 - accuracy: 0.2876 - val_loss: 1.3219 - val_accuracy: 0.5058\n",
      "Epoch 2/15\n",
      "268/268 [==============================] - 40s 148ms/step - loss: 1.2606 - accuracy: 0.5498 - val_loss: 1.0719 - val_accuracy: 0.6295\n",
      "Trying hyperparameters: lstm_units_1=160, lstm_units_2=112, dense_units=160, dropout_rate=0.2, learning_rate=0.0009075883504161729, batch_size=256\n",
      "Epoch 1/15\n",
      "268/268 [==============================] - 23s 79ms/step - loss: 1.7509 - accuracy: 0.3828 - val_loss: 1.2779 - val_accuracy: 0.6073\n",
      "Epoch 2/15\n",
      "268/268 [==============================] - 21s 77ms/step - loss: 1.4267 - accuracy: 0.5221 - val_loss: 1.0290 - val_accuracy: 0.6572\n",
      "Trying hyperparameters: lstm_units_1=192, lstm_units_2=128, dense_units=192, dropout_rate=0.2, learning_rate=0.0010459960926192035, batch_size=256\n",
      "Epoch 1/15\n",
      "268/268 [==============================] - 26s 91ms/step - loss: 1.8896 - accuracy: 0.3277 - val_loss: 1.5141 - val_accuracy: 0.5003\n",
      "Epoch 2/15\n",
      "268/268 [==============================] - 24s 88ms/step - loss: 1.6203 - accuracy: 0.4478 - val_loss: 1.6669 - val_accuracy: 0.4000\n",
      "Epoch 3/15\n",
      "268/268 [==============================] - 24s 88ms/step - loss: 1.5677 - accuracy: 0.4368 - val_loss: 1.1660 - val_accuracy: 0.5947\n",
      "Epoch 4/15\n",
      "268/268 [==============================] - 24s 88ms/step - loss: 1.0933 - accuracy: 0.6219 - val_loss: 0.9054 - val_accuracy: 0.6839\n",
      "Epoch 5/15\n",
      "268/268 [==============================] - 24s 89ms/step - loss: 1.0282 - accuracy: 0.6548 - val_loss: 0.8407 - val_accuracy: 0.7036\n",
      "Epoch 6/15\n",
      "268/268 [==============================] - 24s 89ms/step - loss: 0.8257 - accuracy: 0.7158 - val_loss: 0.7528 - val_accuracy: 0.7351\n",
      "Epoch 7/15\n",
      "268/268 [==============================] - 24s 89ms/step - loss: 0.7363 - accuracy: 0.7415 - val_loss: 0.6903 - val_accuracy: 0.7624\n",
      "Epoch 8/15\n",
      "268/268 [==============================] - 24s 88ms/step - loss: 0.6739 - accuracy: 0.7699 - val_loss: 0.6359 - val_accuracy: 0.7840\n",
      "Epoch 9/15\n",
      "268/268 [==============================] - 24s 89ms/step - loss: 0.6233 - accuracy: 0.7894 - val_loss: 0.6007 - val_accuracy: 0.7967\n",
      "Epoch 10/15\n",
      "268/268 [==============================] - 24s 89ms/step - loss: 0.5698 - accuracy: 0.8077 - val_loss: 0.5877 - val_accuracy: 0.8061\n",
      "Epoch 11/15\n",
      "268/268 [==============================] - 24s 88ms/step - loss: 0.5298 - accuracy: 0.8206 - val_loss: 0.5545 - val_accuracy: 0.8169\n",
      "Epoch 12/15\n",
      "268/268 [==============================] - 24s 88ms/step - loss: 0.4840 - accuracy: 0.8378 - val_loss: 0.5458 - val_accuracy: 0.8202\n",
      "Epoch 13/15\n",
      "268/268 [==============================] - 24s 89ms/step - loss: 0.4892 - accuracy: 0.8370 - val_loss: 0.5315 - val_accuracy: 0.8234\n",
      "Epoch 14/15\n",
      "268/268 [==============================] - 24s 89ms/step - loss: 0.4403 - accuracy: 0.8506 - val_loss: 0.4870 - val_accuracy: 0.8397\n",
      "Epoch 15/15\n",
      "268/268 [==============================] - 24s 89ms/step - loss: 0.3890 - accuracy: 0.8700 - val_loss: 0.5047 - val_accuracy: 0.8371\n",
      "Trying hyperparameters: lstm_units_1=224, lstm_units_2=144, dense_units=96, dropout_rate=0.2, learning_rate=0.0018428577825057042, batch_size=256\n",
      "Epoch 1/15\n",
      "268/268 [==============================] - 31s 104ms/step - loss: 1.7344 - accuracy: 0.3894 - val_loss: 1.2038 - val_accuracy: 0.6024\n",
      "Epoch 2/15\n",
      "268/268 [==============================] - 27s 102ms/step - loss: 1.0021 - accuracy: 0.6495 - val_loss: 0.7058 - val_accuracy: 0.7465\n",
      "Trying hyperparameters: lstm_units_1=320, lstm_units_2=224, dense_units=128, dropout_rate=0.30000000000000004, learning_rate=0.0031399096170848023, batch_size=256\n",
      "Epoch 1/15\n",
      "268/268 [==============================] - 45s 159ms/step - loss: 1.9667 - accuracy: 0.3113 - val_loss: 1.2771 - val_accuracy: 0.5302\n",
      "Epoch 2/15\n",
      "268/268 [==============================] - 42s 157ms/step - loss: 1.1597 - accuracy: 0.5856 - val_loss: 0.7948 - val_accuracy: 0.7059\n",
      "Trying hyperparameters: lstm_units_1=256, lstm_units_2=192, dense_units=192, dropout_rate=0.30000000000000004, learning_rate=0.0012614375069095473, batch_size=256\n",
      "Epoch 1/15\n",
      "268/268 [==============================] - 35s 122ms/step - loss: 1.8587 - accuracy: 0.3457 - val_loss: 1.0578 - val_accuracy: 0.6347\n",
      "Epoch 2/15\n",
      "268/268 [==============================] - 32s 120ms/step - loss: 0.9343 - accuracy: 0.6790 - val_loss: 0.6989 - val_accuracy: 0.7546\n",
      "Trying hyperparameters: lstm_units_1=192, lstm_units_2=128, dense_units=64, dropout_rate=0.2, learning_rate=0.0005355023289382822, batch_size=256\n",
      "Epoch 1/15\n",
      "268/268 [==============================] - 28s 90ms/step - loss: 1.9194 - accuracy: 0.3229 - val_loss: 1.3515 - val_accuracy: 0.5301\n",
      "Epoch 2/15\n",
      "268/268 [==============================] - 24s 89ms/step - loss: 1.3630 - accuracy: 0.5353 - val_loss: 1.3032 - val_accuracy: 0.5117\n",
      "Epoch 3/15\n",
      "268/268 [==============================] - 24s 88ms/step - loss: 1.2171 - accuracy: 0.5670 - val_loss: 1.1730 - val_accuracy: 0.5868\n",
      "Epoch 4/15\n",
      "268/268 [==============================] - 24s 88ms/step - loss: 1.1377 - accuracy: 0.6157 - val_loss: 0.9892 - val_accuracy: 0.6611\n",
      "Epoch 5/15\n",
      "268/268 [==============================] - 24s 88ms/step - loss: 1.0935 - accuracy: 0.6322 - val_loss: 0.9086 - val_accuracy: 0.6860\n",
      "Epoch 6/15\n",
      "268/268 [==============================] - 24s 89ms/step - loss: 0.9793 - accuracy: 0.6786 - val_loss: 0.8953 - val_accuracy: 0.7053\n",
      "Epoch 7/15\n",
      "268/268 [==============================] - 24s 88ms/step - loss: 0.9174 - accuracy: 0.6964 - val_loss: 0.9825 - val_accuracy: 0.6916\n",
      "Epoch 8/15\n",
      "268/268 [==============================] - 24s 88ms/step - loss: 0.9936 - accuracy: 0.6798 - val_loss: 0.8234 - val_accuracy: 0.7328\n",
      "Epoch 9/15\n",
      "268/268 [==============================] - 24s 88ms/step - loss: 0.8928 - accuracy: 0.7096 - val_loss: 0.7904 - val_accuracy: 0.7455\n",
      "Epoch 10/15\n",
      "268/268 [==============================] - 24s 89ms/step - loss: 0.7948 - accuracy: 0.7451 - val_loss: 0.8014 - val_accuracy: 0.7310\n",
      "Epoch 11/15\n",
      "268/268 [==============================] - 24s 88ms/step - loss: 0.7842 - accuracy: 0.7487 - val_loss: 0.8622 - val_accuracy: 0.7194\n",
      "Epoch 12/15\n",
      "268/268 [==============================] - 24s 88ms/step - loss: 0.8324 - accuracy: 0.7317 - val_loss: 0.6919 - val_accuracy: 0.7696\n",
      "Epoch 13/15\n",
      "268/268 [==============================] - 24s 88ms/step - loss: 0.6959 - accuracy: 0.7710 - val_loss: 0.6324 - val_accuracy: 0.7873\n",
      "Epoch 14/15\n",
      "268/268 [==============================] - 24s 88ms/step - loss: 0.6231 - accuracy: 0.7938 - val_loss: 0.5957 - val_accuracy: 0.7974\n",
      "Epoch 15/15\n",
      "268/268 [==============================] - 24s 88ms/step - loss: 0.5775 - accuracy: 0.8053 - val_loss: 0.5663 - val_accuracy: 0.8070\n",
      "Trying hyperparameters: lstm_units_1=416, lstm_units_2=272, dense_units=96, dropout_rate=0.30000000000000004, learning_rate=0.001814692366581265, batch_size=256\n",
      "Epoch 1/15\n",
      "268/268 [==============================] - 65s 236ms/step - loss: 2.1659 - accuracy: 0.2369 - val_loss: 1.2339 - val_accuracy: 0.5538\n",
      "Epoch 2/15\n",
      "268/268 [==============================] - 63s 236ms/step - loss: 1.1232 - accuracy: 0.6034 - val_loss: 0.7569 - val_accuracy: 0.7175\n",
      "Epoch 3/15\n",
      "268/268 [==============================] - 63s 236ms/step - loss: 0.7673 - accuracy: 0.7273 - val_loss: 0.6875 - val_accuracy: 0.7609\n",
      "Epoch 4/15\n",
      "268/268 [==============================] - 63s 237ms/step - loss: 0.6442 - accuracy: 0.7824 - val_loss: 0.5538 - val_accuracy: 0.8104\n",
      "Trying hyperparameters: lstm_units_1=320, lstm_units_2=224, dense_units=160, dropout_rate=0.2, learning_rate=0.0011060322085117208, batch_size=256\n",
      "Epoch 1/15\n",
      "268/268 [==============================] - 46s 165ms/step - loss: 1.8392 - accuracy: 0.3399 - val_loss: 1.1823 - val_accuracy: 0.5958\n",
      "Epoch 2/15\n",
      "268/268 [==============================] - 42s 158ms/step - loss: 1.1773 - accuracy: 0.5936 - val_loss: 0.7841 - val_accuracy: 0.7290\n",
      "Trying hyperparameters: lstm_units_1=128, lstm_units_2=64, dense_units=224, dropout_rate=0.2, learning_rate=0.0009335505337217502, batch_size=256\n",
      "Epoch 1/15\n",
      "268/268 [==============================] - 20s 67ms/step - loss: 1.8698 - accuracy: 0.3349 - val_loss: 1.3474 - val_accuracy: 0.5039\n",
      "Epoch 2/15\n",
      "268/268 [==============================] - 17s 65ms/step - loss: 1.4081 - accuracy: 0.5034 - val_loss: 1.6842 - val_accuracy: 0.4244\n",
      "Epoch 3/15\n",
      "268/268 [==============================] - 17s 65ms/step - loss: 1.4607 - accuracy: 0.4869 - val_loss: 1.1666 - val_accuracy: 0.5949\n",
      "Epoch 4/15\n",
      "268/268 [==============================] - 17s 65ms/step - loss: 1.1296 - accuracy: 0.6106 - val_loss: 0.9569 - val_accuracy: 0.6633\n",
      "Trying hyperparameters: lstm_units_1=160, lstm_units_2=112, dense_units=288, dropout_rate=0.30000000000000004, learning_rate=0.002590998961085461, batch_size=256\n",
      "Epoch 1/15\n",
      "268/268 [==============================] - 23s 79ms/step - loss: 1.8580 - accuracy: 0.3388 - val_loss: 1.4706 - val_accuracy: 0.4918\n",
      "Epoch 2/15\n",
      "268/268 [==============================] - 21s 77ms/step - loss: 1.2726 - accuracy: 0.5621 - val_loss: 0.9203 - val_accuracy: 0.6680\n",
      "Trying hyperparameters: lstm_units_1=64, lstm_units_2=32, dense_units=192, dropout_rate=0.2, learning_rate=0.0016134263600931476, batch_size=256\n",
      "Epoch 1/15\n",
      "268/268 [==============================] - 20s 63ms/step - loss: 1.9396 - accuracy: 0.3075 - val_loss: 1.5989 - val_accuracy: 0.4143\n",
      "Epoch 2/15\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 1.5009 - accuracy: 0.4545 - val_loss: 1.3452 - val_accuracy: 0.5236\n",
      "Epoch 3/15\n",
      "268/268 [==============================] - 16s 59ms/step - loss: 1.3203 - accuracy: 0.5429 - val_loss: 1.1609 - val_accuracy: 0.6027\n",
      "Epoch 4/15\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 1.1430 - accuracy: 0.6059 - val_loss: 1.0036 - val_accuracy: 0.6551\n",
      "Epoch 5/15\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 1.0669 - accuracy: 0.6385 - val_loss: 0.9095 - val_accuracy: 0.6915\n",
      "Epoch 6/15\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 1.0791 - accuracy: 0.6253 - val_loss: 1.1583 - val_accuracy: 0.5943\n",
      "Epoch 7/15\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 1.0827 - accuracy: 0.6214 - val_loss: 0.8171 - val_accuracy: 0.7172\n",
      "Epoch 8/15\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 0.8175 - accuracy: 0.7215 - val_loss: 0.7245 - val_accuracy: 0.7501\n",
      "Epoch 9/15\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 0.7314 - accuracy: 0.7509 - val_loss: 0.7004 - val_accuracy: 0.7595\n",
      "Epoch 10/15\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 0.6794 - accuracy: 0.7704 - val_loss: 0.6443 - val_accuracy: 0.7824\n",
      "Trying hyperparameters: lstm_units_1=192, lstm_units_2=128, dense_units=64, dropout_rate=0.2, learning_rate=0.0010837826039645439, batch_size=256\n",
      "Epoch 1/15\n",
      "268/268 [==============================] - 26s 89ms/step - loss: 1.8059 - accuracy: 0.3687 - val_loss: 1.4081 - val_accuracy: 0.5113\n",
      "Epoch 2/15\n",
      "268/268 [==============================] - 23s 87ms/step - loss: 1.3316 - accuracy: 0.5484 - val_loss: 1.4269 - val_accuracy: 0.5032\n",
      "Epoch 3/15\n",
      "268/268 [==============================] - 23s 87ms/step - loss: 1.2557 - accuracy: 0.5613 - val_loss: 0.9854 - val_accuracy: 0.6561\n",
      "Epoch 4/15\n",
      "268/268 [==============================] - 23s 87ms/step - loss: 1.0502 - accuracy: 0.6426 - val_loss: 0.8798 - val_accuracy: 0.6938\n",
      "Trying hyperparameters: lstm_units_1=96, lstm_units_2=48, dense_units=128, dropout_rate=0.2, learning_rate=0.000573185150839891, batch_size=256\n",
      "Epoch 1/15\n",
      "268/268 [==============================] - 19s 65ms/step - loss: 2.0299 - accuracy: 0.2853 - val_loss: 1.6969 - val_accuracy: 0.3972\n",
      "Epoch 2/15\n",
      "268/268 [==============================] - 17s 63ms/step - loss: 1.4363 - accuracy: 0.4901 - val_loss: 1.4129 - val_accuracy: 0.4978\n",
      "Epoch 3/15\n",
      "268/268 [==============================] - 17s 62ms/step - loss: 1.4057 - accuracy: 0.4929 - val_loss: 1.4310 - val_accuracy: 0.4629\n",
      "Epoch 4/15\n",
      "268/268 [==============================] - 17s 63ms/step - loss: 1.4505 - accuracy: 0.4657 - val_loss: 1.3796 - val_accuracy: 0.5266\n",
      "Epoch 5/15\n",
      "268/268 [==============================] - 17s 63ms/step - loss: 1.4029 - accuracy: 0.4968 - val_loss: 1.2205 - val_accuracy: 0.5510\n",
      "Epoch 6/15\n",
      "268/268 [==============================] - 17s 62ms/step - loss: 1.2492 - accuracy: 0.5525 - val_loss: 1.2207 - val_accuracy: 0.5736\n",
      "Epoch 7/15\n",
      "268/268 [==============================] - 17s 63ms/step - loss: 1.2056 - accuracy: 0.5762 - val_loss: 1.0878 - val_accuracy: 0.6061\n",
      "Epoch 8/15\n",
      "268/268 [==============================] - 17s 63ms/step - loss: 1.0913 - accuracy: 0.6101 - val_loss: 0.9344 - val_accuracy: 0.6721\n",
      "Epoch 9/15\n",
      "268/268 [==============================] - 17s 63ms/step - loss: 0.9877 - accuracy: 0.6588 - val_loss: 0.9629 - val_accuracy: 0.6647\n",
      "Epoch 10/15\n",
      "268/268 [==============================] - 17s 63ms/step - loss: 0.9692 - accuracy: 0.6667 - val_loss: 0.8685 - val_accuracy: 0.6939\n",
      "Trying hyperparameters: lstm_units_1=160, lstm_units_2=112, dense_units=224, dropout_rate=0.2, learning_rate=0.002029745096185806, batch_size=256\n",
      "Epoch 1/15\n",
      "268/268 [==============================] - 24s 78ms/step - loss: 1.6706 - accuracy: 0.4051 - val_loss: 0.7668 - val_accuracy: 0.7216\n",
      "Epoch 2/15\n",
      "268/268 [==============================] - 20s 76ms/step - loss: 0.8061 - accuracy: 0.7136 - val_loss: 0.6182 - val_accuracy: 0.7756\n",
      "Epoch 3/15\n",
      "268/268 [==============================] - 20s 76ms/step - loss: 0.5798 - accuracy: 0.7960 - val_loss: 0.5209 - val_accuracy: 0.8199\n",
      "Epoch 4/15\n",
      "268/268 [==============================] - 20s 76ms/step - loss: 0.4880 - accuracy: 0.8335 - val_loss: 0.4698 - val_accuracy: 0.8397\n",
      "Epoch 5/15\n",
      "268/268 [==============================] - 20s 76ms/step - loss: 0.4028 - accuracy: 0.8663 - val_loss: 0.4454 - val_accuracy: 0.8511\n",
      "Epoch 6/15\n",
      "268/268 [==============================] - 20s 76ms/step - loss: 0.3246 - accuracy: 0.8919 - val_loss: 0.4370 - val_accuracy: 0.8584\n",
      "Epoch 7/15\n",
      "268/268 [==============================] - 20s 76ms/step - loss: 0.2693 - accuracy: 0.9114 - val_loss: 0.4448 - val_accuracy: 0.8632\n",
      "Epoch 8/15\n",
      "268/268 [==============================] - 21s 77ms/step - loss: 0.2227 - accuracy: 0.9283 - val_loss: 0.4505 - val_accuracy: 0.8663\n",
      "Epoch 9/15\n",
      "268/268 [==============================] - 21s 77ms/step - loss: 0.1732 - accuracy: 0.9442 - val_loss: 0.4681 - val_accuracy: 0.8691\n",
      "Epoch 10/15\n",
      "268/268 [==============================] - 20s 76ms/step - loss: 0.1371 - accuracy: 0.9566 - val_loss: 0.4954 - val_accuracy: 0.8715\n",
      "Trying hyperparameters: lstm_units_1=256, lstm_units_2=160, dense_units=96, dropout_rate=0.30000000000000004, learning_rate=0.0013790309636780873, batch_size=256\n",
      "Epoch 1/15\n",
      "268/268 [==============================] - 33s 116ms/step - loss: 1.8543 - accuracy: 0.3466 - val_loss: 1.5267 - val_accuracy: 0.4337\n",
      "Epoch 2/15\n",
      "268/268 [==============================] - 31s 114ms/step - loss: 1.5291 - accuracy: 0.4407 - val_loss: 1.3782 - val_accuracy: 0.5216\n",
      "Epoch 3/15\n",
      "268/268 [==============================] - 30s 114ms/step - loss: 1.2274 - accuracy: 0.5736 - val_loss: 0.8255 - val_accuracy: 0.6996\n",
      "Epoch 4/15\n",
      "268/268 [==============================] - 31s 114ms/step - loss: 0.8523 - accuracy: 0.7018 - val_loss: 0.7076 - val_accuracy: 0.7491\n",
      "Trying hyperparameters: lstm_units_1=192, lstm_units_2=128, dense_units=160, dropout_rate=0.2, learning_rate=0.0004235675859508999, batch_size=256\n",
      "Epoch 1/15\n",
      "268/268 [==============================] - 26s 91ms/step - loss: 1.8684 - accuracy: 0.3355 - val_loss: 1.2587 - val_accuracy: 0.5400\n",
      "Epoch 2/15\n",
      "268/268 [==============================] - 24s 88ms/step - loss: 1.2573 - accuracy: 0.5563 - val_loss: 1.0845 - val_accuracy: 0.6335\n",
      "Trying hyperparameters: lstm_units_1=96, lstm_units_2=48, dense_units=288, dropout_rate=0.5, learning_rate=0.0008040041851725829, batch_size=256\n",
      "Epoch 1/15\n",
      "268/268 [==============================] - 21s 66ms/step - loss: 1.9806 - accuracy: 0.2904 - val_loss: 1.4352 - val_accuracy: 0.4625\n",
      "Epoch 2/15\n",
      "268/268 [==============================] - 17s 63ms/step - loss: 1.5342 - accuracy: 0.4534 - val_loss: 1.3214 - val_accuracy: 0.5033\n",
      "Trying hyperparameters: lstm_units_1=224, lstm_units_2=144, dense_units=320, dropout_rate=0.4, learning_rate=0.0010249316844499533, batch_size=256\n",
      "Epoch 1/15\n",
      "268/268 [==============================] - 30s 104ms/step - loss: 1.8816 - accuracy: 0.3311 - val_loss: 1.2643 - val_accuracy: 0.5442\n",
      "Epoch 2/15\n",
      "268/268 [==============================] - 27s 102ms/step - loss: 1.0147 - accuracy: 0.6456 - val_loss: 0.7090 - val_accuracy: 0.7473\n",
      "Trying hyperparameters: lstm_units_1=320, lstm_units_2=192, dense_units=256, dropout_rate=0.30000000000000004, learning_rate=0.0006993419300824015, batch_size=256\n",
      "Epoch 1/15\n",
      "268/268 [==============================] - 41s 147ms/step - loss: 1.7356 - accuracy: 0.3914 - val_loss: 1.3493 - val_accuracy: 0.5650\n",
      "Epoch 2/15\n",
      "268/268 [==============================] - 39s 145ms/step - loss: 1.3831 - accuracy: 0.5213 - val_loss: 0.9800 - val_accuracy: 0.6530\n",
      "Epoch 3/15\n",
      "268/268 [==============================] - 39s 146ms/step - loss: 0.9376 - accuracy: 0.6732 - val_loss: 0.7076 - val_accuracy: 0.7503\n",
      "Epoch 4/15\n",
      "268/268 [==============================] - 39s 146ms/step - loss: 0.7111 - accuracy: 0.7562 - val_loss: 0.6122 - val_accuracy: 0.7893\n",
      "Trying hyperparameters: lstm_units_1=256, lstm_units_2=160, dense_units=192, dropout_rate=0.2, learning_rate=0.0012988948185724556, batch_size=256\n",
      "Epoch 1/15\n",
      "268/268 [==============================] - 33s 117ms/step - loss: 1.8456 - accuracy: 0.3475 - val_loss: 1.6454 - val_accuracy: 0.4254\n",
      "Epoch 2/15\n",
      "268/268 [==============================] - 31s 115ms/step - loss: 1.2903 - accuracy: 0.5531 - val_loss: 1.1320 - val_accuracy: 0.6101\n",
      "Epoch 3/15\n",
      "268/268 [==============================] - 31s 114ms/step - loss: 1.0599 - accuracy: 0.6324 - val_loss: 0.7593 - val_accuracy: 0.7387\n",
      "Epoch 4/15\n",
      "268/268 [==============================] - 31s 114ms/step - loss: 0.7730 - accuracy: 0.7370 - val_loss: 0.6539 - val_accuracy: 0.7752\n",
      "Trying hyperparameters: lstm_units_1=192, lstm_units_2=128, dense_units=64, dropout_rate=0.2, learning_rate=0.0005411429897684961, batch_size=256\n",
      "Epoch 1/15\n",
      "268/268 [==============================] - 26s 91ms/step - loss: 1.8777 - accuracy: 0.3476 - val_loss: 1.2380 - val_accuracy: 0.5615\n",
      "Epoch 2/15\n",
      "268/268 [==============================] - 24s 89ms/step - loss: 1.3246 - accuracy: 0.5504 - val_loss: 0.9601 - val_accuracy: 0.6761\n",
      "Trying hyperparameters: lstm_units_1=192, lstm_units_2=128, dense_units=64, dropout_rate=0.2, learning_rate=0.0009653811535788055, batch_size=256\n",
      "Epoch 1/15\n",
      "268/268 [==============================] - 28s 91ms/step - loss: 1.8648 - accuracy: 0.3465 - val_loss: 1.3260 - val_accuracy: 0.5393\n",
      "Epoch 2/15\n",
      "268/268 [==============================] - 24s 89ms/step - loss: 1.2360 - accuracy: 0.5866 - val_loss: 0.9498 - val_accuracy: 0.6746\n",
      "Trying hyperparameters: lstm_units_1=160, lstm_units_2=112, dense_units=96, dropout_rate=0.2, learning_rate=0.0005902153146869164, batch_size=256\n",
      "Epoch 1/15\n",
      "268/268 [==============================] - 23s 79ms/step - loss: 2.0018 - accuracy: 0.2920 - val_loss: 1.3873 - val_accuracy: 0.5275\n",
      "Epoch 2/15\n",
      "268/268 [==============================] - 21s 77ms/step - loss: 1.4725 - accuracy: 0.4935 - val_loss: 1.2981 - val_accuracy: 0.5523\n",
      "Epoch 3/15\n",
      "268/268 [==============================] - 20s 76ms/step - loss: 1.4696 - accuracy: 0.4933 - val_loss: 1.8191 - val_accuracy: 0.3737\n",
      "Epoch 4/15\n",
      "268/268 [==============================] - 20s 76ms/step - loss: 1.7135 - accuracy: 0.3810 - val_loss: 1.3766 - val_accuracy: 0.5089\n",
      "Epoch 5/15\n",
      "268/268 [==============================] - 21s 77ms/step - loss: 1.4080 - accuracy: 0.4939 - val_loss: 1.2742 - val_accuracy: 0.5504\n",
      "Epoch 6/15\n",
      "268/268 [==============================] - 20s 76ms/step - loss: 1.4113 - accuracy: 0.5043 - val_loss: 1.0148 - val_accuracy: 0.6380\n",
      "Epoch 7/15\n",
      "268/268 [==============================] - 20s 76ms/step - loss: 1.0191 - accuracy: 0.6484 - val_loss: 0.8834 - val_accuracy: 0.6910\n",
      "Epoch 8/15\n",
      "268/268 [==============================] - 20s 76ms/step - loss: 0.8599 - accuracy: 0.6979 - val_loss: 0.7467 - val_accuracy: 0.7246\n",
      "Epoch 9/15\n",
      "268/268 [==============================] - 21s 77ms/step - loss: 0.7494 - accuracy: 0.7334 - val_loss: 0.6806 - val_accuracy: 0.7593\n",
      "Epoch 10/15\n",
      "268/268 [==============================] - 21s 77ms/step - loss: 0.6722 - accuracy: 0.7686 - val_loss: 0.6416 - val_accuracy: 0.7734\n",
      "Trying hyperparameters: lstm_units_1=224, lstm_units_2=144, dense_units=128, dropout_rate=0.30000000000000004, learning_rate=0.00042189130095009625, batch_size=256\n",
      "Epoch 1/15\n",
      "268/268 [==============================] - 30s 104ms/step - loss: 1.8434 - accuracy: 0.3514 - val_loss: 1.4210 - val_accuracy: 0.4975\n",
      "Epoch 2/15\n",
      "268/268 [==============================] - 27s 102ms/step - loss: 1.4235 - accuracy: 0.4830 - val_loss: 1.2785 - val_accuracy: 0.5291\n",
      "Epoch 3/15\n",
      "268/268 [==============================] - 27s 102ms/step - loss: 1.4079 - accuracy: 0.5168 - val_loss: 1.1969 - val_accuracy: 0.6166\n",
      "Epoch 4/15\n",
      "268/268 [==============================] - 27s 102ms/step - loss: 1.4966 - accuracy: 0.4988 - val_loss: 1.3089 - val_accuracy: 0.5490\n",
      "Epoch 5/15\n",
      "268/268 [==============================] - 27s 102ms/step - loss: 1.2392 - accuracy: 0.5836 - val_loss: 1.1590 - val_accuracy: 0.6218\n",
      "Epoch 6/15\n",
      "268/268 [==============================] - 27s 102ms/step - loss: 1.1532 - accuracy: 0.6240 - val_loss: 1.1457 - val_accuracy: 0.6245\n",
      "Epoch 7/15\n",
      "268/268 [==============================] - 27s 102ms/step - loss: 1.1486 - accuracy: 0.6234 - val_loss: 1.1111 - val_accuracy: 0.6216\n",
      "Epoch 8/15\n",
      "268/268 [==============================] - 27s 102ms/step - loss: 1.1055 - accuracy: 0.6318 - val_loss: 1.0321 - val_accuracy: 0.6537\n",
      "Epoch 9/15\n",
      "268/268 [==============================] - 27s 102ms/step - loss: 1.0488 - accuracy: 0.6518 - val_loss: 0.9036 - val_accuracy: 0.6910\n",
      "Epoch 10/15\n",
      "268/268 [==============================] - 27s 102ms/step - loss: 0.9542 - accuracy: 0.6789 - val_loss: 0.9033 - val_accuracy: 0.6995\n",
      "Trying hyperparameters: lstm_units_1=96, lstm_units_2=48, dense_units=64, dropout_rate=0.2, learning_rate=0.0003138348358231337, batch_size=256\n",
      "Epoch 1/15\n",
      "268/268 [==============================] - 21s 65ms/step - loss: 2.1719 - accuracy: 0.2344 - val_loss: 1.4172 - val_accuracy: 0.4817\n",
      "Epoch 2/15\n",
      "268/268 [==============================] - 17s 63ms/step - loss: 1.4055 - accuracy: 0.4992 - val_loss: 1.2862 - val_accuracy: 0.5439\n",
      "Trying hyperparameters: lstm_units_1=256, lstm_units_2=160, dense_units=384, dropout_rate=0.30000000000000004, learning_rate=0.0022181675441969727, batch_size=256\n",
      "Epoch 1/15\n",
      "268/268 [==============================] - 33s 116ms/step - loss: 1.8128 - accuracy: 0.3619 - val_loss: 0.7857 - val_accuracy: 0.7100\n",
      "Epoch 2/15\n",
      "268/268 [==============================] - 31s 115ms/step - loss: 0.7681 - accuracy: 0.7265 - val_loss: 0.6064 - val_accuracy: 0.7869\n",
      "Epoch 3/15\n",
      "268/268 [==============================] - 31s 114ms/step - loss: 0.6012 - accuracy: 0.7960 - val_loss: 0.5186 - val_accuracy: 0.8254\n",
      "Epoch 4/15\n",
      "268/268 [==============================] - 31s 115ms/step - loss: 0.4800 - accuracy: 0.8385 - val_loss: 0.4749 - val_accuracy: 0.8432\n",
      "Epoch 5/15\n",
      "268/268 [==============================] - 31s 115ms/step - loss: 0.4150 - accuracy: 0.8616 - val_loss: 0.4356 - val_accuracy: 0.8551\n",
      "Epoch 6/15\n",
      "268/268 [==============================] - 31s 114ms/step - loss: 0.3419 - accuracy: 0.8887 - val_loss: 0.4243 - val_accuracy: 0.8631\n",
      "Epoch 7/15\n",
      "268/268 [==============================] - 31s 115ms/step - loss: 0.2798 - accuracy: 0.9100 - val_loss: 0.4335 - val_accuracy: 0.8640\n",
      "Epoch 8/15\n",
      "268/268 [==============================] - 31s 115ms/step - loss: 0.2369 - accuracy: 0.9245 - val_loss: 0.4381 - val_accuracy: 0.8643\n",
      "Epoch 9/15\n",
      "268/268 [==============================] - 31s 114ms/step - loss: 0.1944 - accuracy: 0.9378 - val_loss: 0.4514 - val_accuracy: 0.8689\n",
      "Epoch 10/15\n",
      "268/268 [==============================] - 31s 115ms/step - loss: 0.1514 - accuracy: 0.9527 - val_loss: 0.4900 - val_accuracy: 0.8646\n",
      "Trying hyperparameters: lstm_units_1=384, lstm_units_2=224, dense_units=96, dropout_rate=0.2, learning_rate=0.0016525717329437194, batch_size=256\n",
      "Epoch 1/15\n",
      "268/268 [==============================] - 51s 184ms/step - loss: 2.0175 - accuracy: 0.2908 - val_loss: 1.0565 - val_accuracy: 0.6346\n",
      "Epoch 2/15\n",
      "268/268 [==============================] - 49s 183ms/step - loss: 0.9685 - accuracy: 0.6610 - val_loss: 0.7250 - val_accuracy: 0.7335\n",
      "Epoch 3/15\n",
      "268/268 [==============================] - 49s 183ms/step - loss: 0.7014 - accuracy: 0.7525 - val_loss: 0.6494 - val_accuracy: 0.7757\n",
      "Epoch 4/15\n",
      "268/268 [==============================] - 49s 184ms/step - loss: 0.5949 - accuracy: 0.7985 - val_loss: 0.5487 - val_accuracy: 0.8153\n",
      "Trying hyperparameters: lstm_units_1=128, lstm_units_2=96, dense_units=480, dropout_rate=0.4, learning_rate=0.0012525008998445423, batch_size=256\n",
      "Epoch 1/15\n",
      "268/268 [==============================] - 22s 70ms/step - loss: 1.8348 - accuracy: 0.3513 - val_loss: 1.7098 - val_accuracy: 0.3866\n",
      "Epoch 2/15\n",
      "268/268 [==============================] - 18s 68ms/step - loss: 1.5813 - accuracy: 0.4261 - val_loss: 1.3592 - val_accuracy: 0.4904\n",
      "Epoch 3/15\n",
      "268/268 [==============================] - 18s 68ms/step - loss: 1.5009 - accuracy: 0.4743 - val_loss: 1.0186 - val_accuracy: 0.6356\n",
      "Epoch 4/15\n",
      "268/268 [==============================] - 18s 68ms/step - loss: 1.0244 - accuracy: 0.6405 - val_loss: 0.8366 - val_accuracy: 0.6894\n",
      "Trying hyperparameters: lstm_units_1=288, lstm_units_2=176, dense_units=160, dropout_rate=0.30000000000000004, learning_rate=0.0008112944705398481, batch_size=256\n",
      "Epoch 1/15\n",
      "268/268 [==============================] - 40s 141ms/step - loss: 1.9959 - accuracy: 0.2993 - val_loss: 1.7906 - val_accuracy: 0.4208\n",
      "Epoch 2/15\n",
      "268/268 [==============================] - 38s 140ms/step - loss: 1.6133 - accuracy: 0.4428 - val_loss: 1.2236 - val_accuracy: 0.6271\n"
     ]
    }
   ],
   "source": [
    "study_lstm_word2vec = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler(), pruner=optuna.pruners.HyperbandPruner())\n",
    "study_lstm_word2vec.optimize(lambda trial: objective_lstm(trial, embedding_matrix), n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying hyperparameters: lstm_units_1=256, lstm_units_2=256, dense_units=160, dropout_rate=0.2, learning_rate=0.00016188936476430271, batch_size=256\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 39s 137ms/step - loss: 1.9695 - accuracy: 0.3091 - val_loss: 1.3654 - val_accuracy: 0.4905\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 36s 135ms/step - loss: 1.6126 - accuracy: 0.4302 - val_loss: 1.4670 - val_accuracy: 0.5073\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 37s 136ms/step - loss: 1.3920 - accuracy: 0.5213 - val_loss: 1.3228 - val_accuracy: 0.5473\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 37s 138ms/step - loss: 1.2954 - accuracy: 0.5460 - val_loss: 1.1367 - val_accuracy: 0.6047\n",
      "Epoch 5/20\n",
      "268/268 [==============================] - 37s 139ms/step - loss: 1.1680 - accuracy: 0.5962 - val_loss: 1.0648 - val_accuracy: 0.6362\n",
      "Epoch 6/20\n",
      "268/268 [==============================] - 37s 139ms/step - loss: 1.0759 - accuracy: 0.6338 - val_loss: 0.9795 - val_accuracy: 0.6660\n",
      "Epoch 7/20\n",
      "268/268 [==============================] - 38s 140ms/step - loss: 0.9566 - accuracy: 0.6726 - val_loss: 1.1052 - val_accuracy: 0.6296\n",
      "Epoch 8/20\n",
      "268/268 [==============================] - 38s 140ms/step - loss: 1.1808 - accuracy: 0.6064 - val_loss: 1.0804 - val_accuracy: 0.6362\n",
      "Epoch 9/20\n",
      "268/268 [==============================] - 38s 141ms/step - loss: 1.0451 - accuracy: 0.6479 - val_loss: 0.9784 - val_accuracy: 0.6583\n",
      "Epoch 10/20\n",
      "268/268 [==============================] - 38s 141ms/step - loss: 1.0457 - accuracy: 0.6474 - val_loss: 1.0520 - val_accuracy: 0.6309\n",
      "Epoch 11/20\n",
      "268/268 [==============================] - 38s 142ms/step - loss: 1.0616 - accuracy: 0.6461 - val_loss: 1.0460 - val_accuracy: 0.6398\n",
      "Epoch 12/20\n",
      "268/268 [==============================] - 38s 141ms/step - loss: 0.9734 - accuracy: 0.6753 - val_loss: 0.9003 - val_accuracy: 0.6946\n",
      "Epoch 13/20\n",
      "268/268 [==============================] - 38s 141ms/step - loss: 0.8991 - accuracy: 0.6896 - val_loss: 0.8695 - val_accuracy: 0.6928\n",
      "Epoch 14/20\n",
      "268/268 [==============================] - 38s 141ms/step - loss: 0.8559 - accuracy: 0.7010 - val_loss: 0.8302 - val_accuracy: 0.7060\n",
      "Epoch 15/20\n",
      "268/268 [==============================] - 38s 141ms/step - loss: 0.8291 - accuracy: 0.7096 - val_loss: 0.8344 - val_accuracy: 0.7142\n",
      "Epoch 16/20\n",
      "268/268 [==============================] - 38s 142ms/step - loss: 0.8219 - accuracy: 0.7150 - val_loss: 0.7901 - val_accuracy: 0.7233\n",
      "Epoch 17/20\n",
      "268/268 [==============================] - 38s 141ms/step - loss: 0.7783 - accuracy: 0.7260 - val_loss: 0.7307 - val_accuracy: 0.7424\n",
      "Epoch 18/20\n",
      "268/268 [==============================] - 38s 141ms/step - loss: 0.7337 - accuracy: 0.7414 - val_loss: 0.6972 - val_accuracy: 0.7528\n",
      "Epoch 19/20\n",
      "268/268 [==============================] - 38s 141ms/step - loss: 0.6974 - accuracy: 0.7527 - val_loss: 0.6946 - val_accuracy: 0.7535\n",
      "Epoch 20/20\n",
      "268/268 [==============================] - 38s 142ms/step - loss: 0.6878 - accuracy: 0.7572 - val_loss: 0.6915 - val_accuracy: 0.7563\n",
      "Trying hyperparameters: lstm_units_1=448, lstm_units_2=256, dense_units=288, dropout_rate=0.4, learning_rate=0.0013684003983172668, batch_size=256\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 67s 243ms/step - loss: 1.7357 - accuracy: 0.4006 - val_loss: 0.9947 - val_accuracy: 0.6547\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 63s 236ms/step - loss: 0.8864 - accuracy: 0.6858 - val_loss: 0.7240 - val_accuracy: 0.7359\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 63s 237ms/step - loss: 0.6963 - accuracy: 0.7506 - val_loss: 0.5886 - val_accuracy: 0.7957\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 63s 237ms/step - loss: 0.5756 - accuracy: 0.8045 - val_loss: 0.5155 - val_accuracy: 0.8287\n",
      "Epoch 5/20\n",
      "268/268 [==============================] - 63s 237ms/step - loss: 0.4881 - accuracy: 0.8383 - val_loss: 0.4736 - val_accuracy: 0.8419\n",
      "Epoch 6/20\n",
      "268/268 [==============================] - 64s 237ms/step - loss: 0.4250 - accuracy: 0.8595 - val_loss: 0.4407 - val_accuracy: 0.8516\n",
      "Epoch 7/20\n",
      "268/268 [==============================] - 64s 237ms/step - loss: 0.3670 - accuracy: 0.8787 - val_loss: 0.4350 - val_accuracy: 0.8578\n",
      "Epoch 8/20\n",
      "268/268 [==============================] - 64s 237ms/step - loss: 0.3268 - accuracy: 0.8941 - val_loss: 0.4202 - val_accuracy: 0.8642\n",
      "Epoch 9/20\n",
      "268/268 [==============================] - 64s 237ms/step - loss: 0.2831 - accuracy: 0.9061 - val_loss: 0.4049 - val_accuracy: 0.8680\n",
      "Epoch 10/20\n",
      "268/268 [==============================] - 64s 238ms/step - loss: 0.2392 - accuracy: 0.9238 - val_loss: 0.4223 - val_accuracy: 0.8687\n",
      "Epoch 11/20\n",
      "268/268 [==============================] - 63s 237ms/step - loss: 0.2015 - accuracy: 0.9352 - val_loss: 0.4329 - val_accuracy: 0.8733\n",
      "Epoch 12/20\n",
      "268/268 [==============================] - 63s 237ms/step - loss: 0.2126 - accuracy: 0.9340 - val_loss: 0.4313 - val_accuracy: 0.8736\n",
      "Epoch 13/20\n",
      "268/268 [==============================] - 64s 238ms/step - loss: 0.1685 - accuracy: 0.9457 - val_loss: 0.4501 - val_accuracy: 0.8742\n",
      "Epoch 14/20\n",
      "268/268 [==============================] - 64s 237ms/step - loss: 0.1255 - accuracy: 0.9604 - val_loss: 0.4862 - val_accuracy: 0.8709\n",
      "Epoch 15/20\n",
      "268/268 [==============================] - 64s 238ms/step - loss: 0.1025 - accuracy: 0.9682 - val_loss: 0.5077 - val_accuracy: 0.8725\n",
      "Epoch 16/20\n",
      "268/268 [==============================] - 64s 237ms/step - loss: 0.0911 - accuracy: 0.9716 - val_loss: 0.5522 - val_accuracy: 0.8712\n",
      "Epoch 17/20\n",
      "268/268 [==============================] - 64s 237ms/step - loss: 0.0782 - accuracy: 0.9760 - val_loss: 0.6236 - val_accuracy: 0.8676\n",
      "Epoch 18/20\n",
      "268/268 [==============================] - 64s 237ms/step - loss: 0.0633 - accuracy: 0.9812 - val_loss: 0.5807 - val_accuracy: 0.8652\n",
      "Epoch 19/20\n",
      "268/268 [==============================] - 63s 237ms/step - loss: 0.0682 - accuracy: 0.9784 - val_loss: 0.6170 - val_accuracy: 0.8719\n",
      "Epoch 20/20\n",
      "268/268 [==============================] - 64s 237ms/step - loss: 0.0528 - accuracy: 0.9837 - val_loss: 0.5936 - val_accuracy: 0.8682\n",
      "Trying hyperparameters: lstm_units_1=192, lstm_units_2=96, dense_units=128, dropout_rate=0.4, learning_rate=0.0009587255397435608, batch_size=256\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 25s 85ms/step - loss: 1.8581 - accuracy: 0.3373 - val_loss: 1.6129 - val_accuracy: 0.4358\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 22s 83ms/step - loss: 1.6702 - accuracy: 0.3990 - val_loss: 1.1016 - val_accuracy: 0.6177\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 22s 82ms/step - loss: 1.1160 - accuracy: 0.6222 - val_loss: 0.8971 - val_accuracy: 0.6841\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 22s 82ms/step - loss: 0.9692 - accuracy: 0.6665 - val_loss: 0.9458 - val_accuracy: 0.6404\n",
      "Epoch 5/20\n",
      "268/268 [==============================] - 22s 82ms/step - loss: 0.8751 - accuracy: 0.6897 - val_loss: 0.7071 - val_accuracy: 0.7489\n",
      "Epoch 6/20\n",
      "268/268 [==============================] - 22s 82ms/step - loss: 0.7434 - accuracy: 0.7430 - val_loss: 0.6490 - val_accuracy: 0.7743\n",
      "Epoch 7/20\n",
      "268/268 [==============================] - 22s 83ms/step - loss: 0.6520 - accuracy: 0.7796 - val_loss: 0.5823 - val_accuracy: 0.8010\n",
      "Epoch 8/20\n",
      "268/268 [==============================] - 22s 82ms/step - loss: 0.5785 - accuracy: 0.8059 - val_loss: 0.5567 - val_accuracy: 0.8111\n",
      "Epoch 9/20\n",
      "268/268 [==============================] - 22s 82ms/step - loss: 0.5402 - accuracy: 0.8196 - val_loss: 0.5226 - val_accuracy: 0.8232\n",
      "Epoch 10/20\n",
      "268/268 [==============================] - 22s 82ms/step - loss: 0.4882 - accuracy: 0.8378 - val_loss: 0.5081 - val_accuracy: 0.8280\n",
      "Epoch 11/20\n",
      "268/268 [==============================] - 22s 82ms/step - loss: 0.4543 - accuracy: 0.8523 - val_loss: 0.4918 - val_accuracy: 0.8376\n",
      "Epoch 12/20\n",
      "268/268 [==============================] - 22s 82ms/step - loss: 0.4152 - accuracy: 0.8627 - val_loss: 0.4738 - val_accuracy: 0.8437\n",
      "Epoch 13/20\n",
      "268/268 [==============================] - 22s 82ms/step - loss: 0.3914 - accuracy: 0.8736 - val_loss: 0.4739 - val_accuracy: 0.8476\n",
      "Epoch 14/20\n",
      "268/268 [==============================] - 22s 82ms/step - loss: 0.3512 - accuracy: 0.8865 - val_loss: 0.4608 - val_accuracy: 0.8548\n",
      "Epoch 15/20\n",
      "268/268 [==============================] - 22s 83ms/step - loss: 0.3160 - accuracy: 0.8978 - val_loss: 0.4529 - val_accuracy: 0.8579\n",
      "Epoch 16/20\n",
      "268/268 [==============================] - 22s 83ms/step - loss: 0.2811 - accuracy: 0.9100 - val_loss: 0.4665 - val_accuracy: 0.8612\n",
      "Epoch 17/20\n",
      "268/268 [==============================] - 22s 82ms/step - loss: 0.2568 - accuracy: 0.9182 - val_loss: 0.4580 - val_accuracy: 0.8648\n",
      "Epoch 18/20\n",
      "268/268 [==============================] - 22s 82ms/step - loss: 0.2277 - accuracy: 0.9295 - val_loss: 0.4618 - val_accuracy: 0.8660\n",
      "Epoch 19/20\n",
      "268/268 [==============================] - 22s 82ms/step - loss: 0.2075 - accuracy: 0.9361 - val_loss: 0.4851 - val_accuracy: 0.8632\n",
      "Epoch 20/20\n",
      "268/268 [==============================] - 22s 83ms/step - loss: 0.1891 - accuracy: 0.9423 - val_loss: 0.4908 - val_accuracy: 0.8676\n",
      "Trying hyperparameters: lstm_units_1=416, lstm_units_2=240, dense_units=160, dropout_rate=0.4, learning_rate=0.0036950477964349665, batch_size=256\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 58s 211ms/step - loss: 1.9250 - accuracy: 0.3319 - val_loss: 1.5980 - val_accuracy: 0.4199\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 56s 210ms/step - loss: 1.4624 - accuracy: 0.4746 - val_loss: 1.0726 - val_accuracy: 0.5986\n",
      "Trying hyperparameters: lstm_units_1=512, lstm_units_2=512, dense_units=96, dropout_rate=0.30000000000000004, learning_rate=0.0011046062277489863, batch_size=256\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 113s 416ms/step - loss: 1.8131 - accuracy: 0.3646 - val_loss: 0.9005 - val_accuracy: 0.6762\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 109s 406ms/step - loss: 0.8537 - accuracy: 0.6993 - val_loss: 0.6779 - val_accuracy: 0.7509\n",
      "Trying hyperparameters: lstm_units_1=224, lstm_units_2=112, dense_units=256, dropout_rate=0.30000000000000004, learning_rate=0.0013688934643345725, batch_size=256\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 28s 97ms/step - loss: 1.8275 - accuracy: 0.3481 - val_loss: 1.3138 - val_accuracy: 0.5372\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 25s 95ms/step - loss: 1.2213 - accuracy: 0.5753 - val_loss: 0.9407 - val_accuracy: 0.6674\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 25s 95ms/step - loss: 1.0453 - accuracy: 0.6310 - val_loss: 0.7671 - val_accuracy: 0.7289\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 25s 94ms/step - loss: 0.7402 - accuracy: 0.7416 - val_loss: 0.6355 - val_accuracy: 0.7807\n",
      "Epoch 5/20\n",
      "268/268 [==============================] - 25s 95ms/step - loss: 0.6178 - accuracy: 0.7899 - val_loss: 0.5634 - val_accuracy: 0.8076\n",
      "Epoch 6/20\n",
      "268/268 [==============================] - 25s 95ms/step - loss: 0.5483 - accuracy: 0.8184 - val_loss: 0.5258 - val_accuracy: 0.8251\n",
      "Epoch 7/20\n",
      "268/268 [==============================] - 25s 95ms/step - loss: 0.4812 - accuracy: 0.8407 - val_loss: 0.4865 - val_accuracy: 0.8313\n",
      "Epoch 8/20\n",
      "268/268 [==============================] - 25s 94ms/step - loss: 0.4299 - accuracy: 0.8588 - val_loss: 0.4594 - val_accuracy: 0.8478\n",
      "Epoch 9/20\n",
      "268/268 [==============================] - 25s 94ms/step - loss: 0.3715 - accuracy: 0.8785 - val_loss: 0.4428 - val_accuracy: 0.8538\n",
      "Epoch 10/20\n",
      "268/268 [==============================] - 25s 95ms/step - loss: 0.3322 - accuracy: 0.8906 - val_loss: 0.4389 - val_accuracy: 0.8593\n",
      "Epoch 11/20\n",
      "268/268 [==============================] - 25s 94ms/step - loss: 0.2886 - accuracy: 0.9069 - val_loss: 0.4370 - val_accuracy: 0.8663\n",
      "Epoch 12/20\n",
      "268/268 [==============================] - 25s 94ms/step - loss: 0.2493 - accuracy: 0.9184 - val_loss: 0.4609 - val_accuracy: 0.8579\n",
      "Epoch 13/20\n",
      "268/268 [==============================] - 25s 94ms/step - loss: 0.2277 - accuracy: 0.9262 - val_loss: 0.4750 - val_accuracy: 0.8604\n",
      "Epoch 14/20\n",
      "268/268 [==============================] - 25s 94ms/step - loss: 0.1875 - accuracy: 0.9403 - val_loss: 0.4594 - val_accuracy: 0.8692\n",
      "Epoch 15/20\n",
      "268/268 [==============================] - 25s 95ms/step - loss: 0.1534 - accuracy: 0.9526 - val_loss: 0.6114 - val_accuracy: 0.8293\n",
      "Epoch 16/20\n",
      "268/268 [==============================] - 25s 95ms/step - loss: 0.3392 - accuracy: 0.8915 - val_loss: 0.4537 - val_accuracy: 0.8648\n",
      "Epoch 17/20\n",
      "268/268 [==============================] - 25s 94ms/step - loss: 0.1675 - accuracy: 0.9470 - val_loss: 0.5320 - val_accuracy: 0.8630\n",
      "Epoch 18/20\n",
      "268/268 [==============================] - 25s 94ms/step - loss: 0.1284 - accuracy: 0.9601 - val_loss: 0.5165 - val_accuracy: 0.8723\n",
      "Epoch 19/20\n",
      "268/268 [==============================] - 25s 94ms/step - loss: 0.0998 - accuracy: 0.9702 - val_loss: 0.5609 - val_accuracy: 0.8694\n",
      "Epoch 20/20\n",
      "268/268 [==============================] - 25s 95ms/step - loss: 0.0819 - accuracy: 0.9754 - val_loss: 0.5833 - val_accuracy: 0.8691\n",
      "Trying hyperparameters: lstm_units_1=288, lstm_units_2=144, dense_units=448, dropout_rate=0.30000000000000004, learning_rate=0.00483766869496949, batch_size=256\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 37s 132ms/step - loss: 1.6405 - accuracy: 0.4293 - val_loss: 0.6448 - val_accuracy: 0.7813\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 35s 130ms/step - loss: 0.6364 - accuracy: 0.7904 - val_loss: 0.5316 - val_accuracy: 0.8241\n",
      "Trying hyperparameters: lstm_units_1=384, lstm_units_2=352, dense_units=96, dropout_rate=0.4, learning_rate=0.0009148631614626868, batch_size=256\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 66s 240ms/step - loss: 1.7934 - accuracy: 0.3704 - val_loss: 1.1444 - val_accuracy: 0.6134\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 64s 239ms/step - loss: 1.1292 - accuracy: 0.6253 - val_loss: 0.9262 - val_accuracy: 0.7019\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 64s 240ms/step - loss: 0.8779 - accuracy: 0.7068 - val_loss: 0.7956 - val_accuracy: 0.7311\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 64s 240ms/step - loss: 0.7784 - accuracy: 0.7375 - val_loss: 0.6655 - val_accuracy: 0.7752\n",
      "Epoch 5/20\n",
      "268/268 [==============================] - 64s 240ms/step - loss: 0.6772 - accuracy: 0.7735 - val_loss: 0.6528 - val_accuracy: 0.7621\n",
      "Epoch 6/20\n",
      "268/268 [==============================] - 64s 240ms/step - loss: 0.6276 - accuracy: 0.7817 - val_loss: 0.5706 - val_accuracy: 0.8087\n",
      "Epoch 7/20\n",
      "268/268 [==============================] - 64s 240ms/step - loss: 0.5518 - accuracy: 0.8162 - val_loss: 0.5352 - val_accuracy: 0.8174\n",
      "Epoch 8/20\n",
      "268/268 [==============================] - 64s 240ms/step - loss: 0.4921 - accuracy: 0.8365 - val_loss: 0.5183 - val_accuracy: 0.8276\n",
      "Epoch 9/20\n",
      "268/268 [==============================] - 64s 240ms/step - loss: 0.4762 - accuracy: 0.8436 - val_loss: 0.4861 - val_accuracy: 0.8392\n",
      "Epoch 10/20\n",
      "268/268 [==============================] - 64s 240ms/step - loss: 0.4291 - accuracy: 0.8595 - val_loss: 0.4668 - val_accuracy: 0.8465\n",
      "Epoch 11/20\n",
      "268/268 [==============================] - 64s 240ms/step - loss: 0.3968 - accuracy: 0.8697 - val_loss: 0.4420 - val_accuracy: 0.8552\n",
      "Epoch 12/20\n",
      "268/268 [==============================] - 64s 240ms/step - loss: 0.3590 - accuracy: 0.8843 - val_loss: 0.4472 - val_accuracy: 0.8547\n",
      "Epoch 13/20\n",
      "268/268 [==============================] - 64s 240ms/step - loss: 0.3336 - accuracy: 0.8895 - val_loss: 0.4286 - val_accuracy: 0.8629\n",
      "Epoch 14/20\n",
      "268/268 [==============================] - 64s 240ms/step - loss: 0.2993 - accuracy: 0.9029 - val_loss: 0.4257 - val_accuracy: 0.8630\n",
      "Epoch 15/20\n",
      "268/268 [==============================] - 64s 240ms/step - loss: 0.2604 - accuracy: 0.9170 - val_loss: 0.4305 - val_accuracy: 0.8662\n",
      "Epoch 16/20\n",
      "268/268 [==============================] - 64s 240ms/step - loss: 0.2366 - accuracy: 0.9249 - val_loss: 0.4543 - val_accuracy: 0.8664\n",
      "Epoch 17/20\n",
      "268/268 [==============================] - 64s 240ms/step - loss: 0.2113 - accuracy: 0.9320 - val_loss: 0.4410 - val_accuracy: 0.8669\n",
      "Epoch 18/20\n",
      "268/268 [==============================] - 64s 240ms/step - loss: 0.1848 - accuracy: 0.9428 - val_loss: 0.4615 - val_accuracy: 0.8707\n",
      "Epoch 19/20\n",
      "268/268 [==============================] - 64s 240ms/step - loss: 0.1607 - accuracy: 0.9498 - val_loss: 0.4676 - val_accuracy: 0.8717\n",
      "Epoch 20/20\n",
      "268/268 [==============================] - 64s 240ms/step - loss: 0.1369 - accuracy: 0.9578 - val_loss: 0.5124 - val_accuracy: 0.8678\n",
      "Trying hyperparameters: lstm_units_1=96, lstm_units_2=80, dense_units=64, dropout_rate=0.5, learning_rate=0.005275670841888882, batch_size=256\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 20s 67ms/step - loss: 1.9257 - accuracy: 0.3208 - val_loss: 1.4107 - val_accuracy: 0.4742\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 17s 65ms/step - loss: 1.3278 - accuracy: 0.5252 - val_loss: 0.8981 - val_accuracy: 0.6695\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 17s 64ms/step - loss: 0.8808 - accuracy: 0.6890 - val_loss: 0.7065 - val_accuracy: 0.7495\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 17s 64ms/step - loss: 0.6857 - accuracy: 0.7611 - val_loss: 0.6128 - val_accuracy: 0.7910\n",
      "Trying hyperparameters: lstm_units_1=384, lstm_units_2=192, dense_units=96, dropout_rate=0.5, learning_rate=0.00329579972690909, batch_size=256\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 48s 173ms/step - loss: 1.8954 - accuracy: 0.3423 - val_loss: 1.3305 - val_accuracy: 0.5067\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 46s 172ms/step - loss: 1.0517 - accuracy: 0.6270 - val_loss: 0.7799 - val_accuracy: 0.7258\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 46s 172ms/step - loss: 0.7859 - accuracy: 0.7251 - val_loss: 0.7029 - val_accuracy: 0.7548\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 46s 172ms/step - loss: 0.6891 - accuracy: 0.7643 - val_loss: 0.6099 - val_accuracy: 0.7930\n",
      "Trying hyperparameters: lstm_units_1=512, lstm_units_2=384, dense_units=416, dropout_rate=0.2, learning_rate=0.009312405535859143, batch_size=256\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 90s 331ms/step - loss: 2.1411 - accuracy: 0.2471 - val_loss: 0.8994 - val_accuracy: 0.6679\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 87s 324ms/step - loss: 0.8678 - accuracy: 0.6841 - val_loss: 0.7034 - val_accuracy: 0.7531\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 87s 326ms/step - loss: 0.6632 - accuracy: 0.7691 - val_loss: 0.7822 - val_accuracy: 0.7233\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 87s 326ms/step - loss: 0.6644 - accuracy: 0.7795 - val_loss: 0.5800 - val_accuracy: 0.8091\n",
      "Trying hyperparameters: lstm_units_1=384, lstm_units_2=320, dense_units=320, dropout_rate=0.4, learning_rate=0.0005627085598550614, batch_size=256\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 63s 227ms/step - loss: 1.7867 - accuracy: 0.3632 - val_loss: 1.5231 - val_accuracy: 0.4903\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 60s 224ms/step - loss: 1.5897 - accuracy: 0.4558 - val_loss: 1.3956 - val_accuracy: 0.4810\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 60s 224ms/step - loss: 1.3520 - accuracy: 0.5408 - val_loss: 1.0651 - val_accuracy: 0.6293\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 60s 223ms/step - loss: 1.1414 - accuracy: 0.6145 - val_loss: 0.9497 - val_accuracy: 0.6694\n",
      "Epoch 5/20\n",
      "268/268 [==============================] - 60s 224ms/step - loss: 0.9282 - accuracy: 0.6711 - val_loss: 0.7749 - val_accuracy: 0.7234\n",
      "Epoch 6/20\n",
      "268/268 [==============================] - 60s 224ms/step - loss: 0.7882 - accuracy: 0.7179 - val_loss: 0.7222 - val_accuracy: 0.7384\n",
      "Epoch 7/20\n",
      "268/268 [==============================] - 60s 223ms/step - loss: 0.7282 - accuracy: 0.7397 - val_loss: 0.7252 - val_accuracy: 0.7340\n",
      "Epoch 8/20\n",
      "268/268 [==============================] - 60s 223ms/step - loss: 0.7238 - accuracy: 0.7435 - val_loss: 0.6345 - val_accuracy: 0.7764\n",
      "Epoch 9/20\n",
      "268/268 [==============================] - 60s 223ms/step - loss: 0.6502 - accuracy: 0.7767 - val_loss: 0.5936 - val_accuracy: 0.7941\n",
      "Epoch 10/20\n",
      "268/268 [==============================] - 60s 223ms/step - loss: 0.5827 - accuracy: 0.8015 - val_loss: 0.5670 - val_accuracy: 0.8076\n",
      "Epoch 11/20\n",
      "268/268 [==============================] - 60s 223ms/step - loss: 0.5610 - accuracy: 0.8095 - val_loss: 0.5308 - val_accuracy: 0.8190\n",
      "Epoch 12/20\n",
      "268/268 [==============================] - 60s 223ms/step - loss: 0.5220 - accuracy: 0.8260 - val_loss: 0.5187 - val_accuracy: 0.8254\n",
      "Epoch 13/20\n",
      "268/268 [==============================] - 60s 223ms/step - loss: 0.4974 - accuracy: 0.8359 - val_loss: 0.5047 - val_accuracy: 0.8298\n",
      "Epoch 14/20\n",
      "268/268 [==============================] - 60s 223ms/step - loss: 0.4740 - accuracy: 0.8425 - val_loss: 0.4971 - val_accuracy: 0.8345\n",
      "Epoch 15/20\n",
      "268/268 [==============================] - 60s 223ms/step - loss: 0.4298 - accuracy: 0.8574 - val_loss: 0.4716 - val_accuracy: 0.8418\n",
      "Epoch 16/20\n",
      "268/268 [==============================] - 60s 223ms/step - loss: 0.4590 - accuracy: 0.8488 - val_loss: 0.4608 - val_accuracy: 0.8471\n",
      "Epoch 17/20\n",
      "268/268 [==============================] - 60s 223ms/step - loss: 0.3990 - accuracy: 0.8684 - val_loss: 0.4612 - val_accuracy: 0.8457\n",
      "Epoch 18/20\n",
      "268/268 [==============================] - 60s 223ms/step - loss: 0.3699 - accuracy: 0.8791 - val_loss: 0.4352 - val_accuracy: 0.8563\n",
      "Epoch 19/20\n",
      "268/268 [==============================] - 60s 223ms/step - loss: 0.3408 - accuracy: 0.8902 - val_loss: 0.4515 - val_accuracy: 0.8554\n",
      "Epoch 20/20\n",
      "268/268 [==============================] - 60s 224ms/step - loss: 0.3134 - accuracy: 0.8989 - val_loss: 0.4336 - val_accuracy: 0.8612\n",
      "Trying hyperparameters: lstm_units_1=448, lstm_units_2=352, dense_units=256, dropout_rate=0.4, learning_rate=0.00033538592058385226, batch_size=256\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 77s 280ms/step - loss: 1.6802 - accuracy: 0.4040 - val_loss: 1.1809 - val_accuracy: 0.6166\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 74s 278ms/step - loss: 1.2678 - accuracy: 0.5887 - val_loss: 1.1438 - val_accuracy: 0.6167\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 74s 278ms/step - loss: 1.1951 - accuracy: 0.5979 - val_loss: 0.9734 - val_accuracy: 0.6587\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 74s 278ms/step - loss: 0.9667 - accuracy: 0.6760 - val_loss: 0.8286 - val_accuracy: 0.7142\n",
      "Trying hyperparameters: lstm_units_1=352, lstm_units_2=304, dense_units=352, dropout_rate=0.5, learning_rate=0.0017527207296692097, batch_size=256\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 57s 205ms/step - loss: 2.0080 - accuracy: 0.2805 - val_loss: 1.1873 - val_accuracy: 0.5831\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 54s 203ms/step - loss: 1.1104 - accuracy: 0.6043 - val_loss: 0.7410 - val_accuracy: 0.7291\n",
      "Trying hyperparameters: lstm_units_1=320, lstm_units_2=256, dense_units=512, dropout_rate=0.4, learning_rate=0.0004815103208988489, batch_size=256\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 47s 169ms/step - loss: 1.7438 - accuracy: 0.3821 - val_loss: 1.3693 - val_accuracy: 0.5181\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 45s 167ms/step - loss: 1.4054 - accuracy: 0.5096 - val_loss: 1.3585 - val_accuracy: 0.5139\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 45s 168ms/step - loss: 1.3881 - accuracy: 0.5156 - val_loss: 0.9473 - val_accuracy: 0.6554\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 45s 167ms/step - loss: 0.9658 - accuracy: 0.6673 - val_loss: 0.8473 - val_accuracy: 0.6902\n",
      "Epoch 5/20\n",
      "268/268 [==============================] - 45s 168ms/step - loss: 0.8576 - accuracy: 0.6963 - val_loss: 0.7711 - val_accuracy: 0.7218\n",
      "Epoch 6/20\n",
      "268/268 [==============================] - 45s 168ms/step - loss: 0.8010 - accuracy: 0.7185 - val_loss: 0.7137 - val_accuracy: 0.7474\n",
      "Epoch 7/20\n",
      "268/268 [==============================] - 45s 168ms/step - loss: 0.7479 - accuracy: 0.7416 - val_loss: 0.6879 - val_accuracy: 0.7636\n",
      "Epoch 8/20\n",
      "268/268 [==============================] - 45s 168ms/step - loss: 0.6960 - accuracy: 0.7630 - val_loss: 0.6618 - val_accuracy: 0.7764\n",
      "Epoch 9/20\n",
      "268/268 [==============================] - 45s 168ms/step - loss: 0.6339 - accuracy: 0.7881 - val_loss: 0.5850 - val_accuracy: 0.8032\n",
      "Epoch 10/20\n",
      "268/268 [==============================] - 45s 168ms/step - loss: 0.5767 - accuracy: 0.8101 - val_loss: 0.5603 - val_accuracy: 0.8119\n",
      "Epoch 11/20\n",
      "268/268 [==============================] - 45s 168ms/step - loss: 0.5390 - accuracy: 0.8196 - val_loss: 0.5270 - val_accuracy: 0.8252\n",
      "Epoch 12/20\n",
      "268/268 [==============================] - 45s 167ms/step - loss: 0.5098 - accuracy: 0.8311 - val_loss: 0.5078 - val_accuracy: 0.8301\n",
      "Epoch 13/20\n",
      "268/268 [==============================] - 45s 168ms/step - loss: 0.4799 - accuracy: 0.8431 - val_loss: 0.4960 - val_accuracy: 0.8333\n",
      "Epoch 14/20\n",
      "268/268 [==============================] - 45s 168ms/step - loss: 0.4551 - accuracy: 0.8494 - val_loss: 0.4679 - val_accuracy: 0.8445\n",
      "Epoch 15/20\n",
      "268/268 [==============================] - 45s 168ms/step - loss: 0.4108 - accuracy: 0.8628 - val_loss: 0.4508 - val_accuracy: 0.8497\n",
      "Epoch 16/20\n",
      "268/268 [==============================] - 45s 168ms/step - loss: 0.3969 - accuracy: 0.8667 - val_loss: 0.4462 - val_accuracy: 0.8536\n",
      "Epoch 17/20\n",
      "268/268 [==============================] - 45s 168ms/step - loss: 0.3699 - accuracy: 0.8784 - val_loss: 0.4347 - val_accuracy: 0.8560\n",
      "Epoch 18/20\n",
      "268/268 [==============================] - 45s 167ms/step - loss: 0.3537 - accuracy: 0.8837 - val_loss: 0.4384 - val_accuracy: 0.8583\n",
      "Epoch 19/20\n",
      "268/268 [==============================] - 45s 167ms/step - loss: 0.3456 - accuracy: 0.8882 - val_loss: 0.4329 - val_accuracy: 0.8595\n",
      "Epoch 20/20\n",
      "268/268 [==============================] - 45s 168ms/step - loss: 0.3058 - accuracy: 0.9017 - val_loss: 0.4202 - val_accuracy: 0.8656\n",
      "Trying hyperparameters: lstm_units_1=480, lstm_units_2=432, dense_units=224, dropout_rate=0.30000000000000004, learning_rate=0.0020034712933219233, batch_size=256\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 96s 351ms/step - loss: 2.0716 - accuracy: 0.2787 - val_loss: 1.0727 - val_accuracy: 0.6136\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 94s 351ms/step - loss: 1.0756 - accuracy: 0.6237 - val_loss: 0.7464 - val_accuracy: 0.7315\n",
      "Trying hyperparameters: lstm_units_1=448, lstm_units_2=384, dense_units=192, dropout_rate=0.5, learning_rate=0.0007710208608714972, batch_size=256\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 82s 295ms/step - loss: 1.8647 - accuracy: 0.3316 - val_loss: 1.3315 - val_accuracy: 0.5423\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 79s 294ms/step - loss: 1.2713 - accuracy: 0.5738 - val_loss: 1.2600 - val_accuracy: 0.5790\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 79s 293ms/step - loss: 1.1331 - accuracy: 0.6126 - val_loss: 1.0792 - val_accuracy: 0.6268\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 79s 294ms/step - loss: 1.0135 - accuracy: 0.6469 - val_loss: 0.7325 - val_accuracy: 0.7357\n",
      "Epoch 5/20\n",
      "268/268 [==============================] - 79s 294ms/step - loss: 0.7256 - accuracy: 0.7444 - val_loss: 0.6430 - val_accuracy: 0.7736\n",
      "Epoch 6/20\n",
      "268/268 [==============================] - 79s 295ms/step - loss: 0.6472 - accuracy: 0.7741 - val_loss: 0.6165 - val_accuracy: 0.7835\n",
      "Epoch 7/20\n",
      "268/268 [==============================] - 79s 293ms/step - loss: 0.5815 - accuracy: 0.8026 - val_loss: 0.5512 - val_accuracy: 0.8098\n",
      "Epoch 8/20\n",
      "268/268 [==============================] - 79s 293ms/step - loss: 0.5340 - accuracy: 0.8166 - val_loss: 0.5154 - val_accuracy: 0.8238\n",
      "Epoch 9/20\n",
      "268/268 [==============================] - 79s 293ms/step - loss: 0.4870 - accuracy: 0.8344 - val_loss: 0.4928 - val_accuracy: 0.8331\n",
      "Epoch 10/20\n",
      "268/268 [==============================] - 78s 293ms/step - loss: 0.4485 - accuracy: 0.8482 - val_loss: 0.5034 - val_accuracy: 0.8319\n",
      "Trying hyperparameters: lstm_units_1=160, lstm_units_2=112, dense_units=384, dropout_rate=0.4, learning_rate=0.0022466449619262647, batch_size=256\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 23s 79ms/step - loss: 1.8435 - accuracy: 0.3386 - val_loss: 1.3792 - val_accuracy: 0.5386\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 20s 76ms/step - loss: 1.2386 - accuracy: 0.5735 - val_loss: 0.8650 - val_accuracy: 0.6883\n",
      "Trying hyperparameters: lstm_units_1=320, lstm_units_2=192, dense_units=288, dropout_rate=0.30000000000000004, learning_rate=0.0013288862869592778, batch_size=256\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 41s 146ms/step - loss: 1.8017 - accuracy: 0.3696 - val_loss: 1.5887 - val_accuracy: 0.4754\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 39s 144ms/step - loss: 1.4834 - accuracy: 0.4770 - val_loss: 0.9080 - val_accuracy: 0.6816\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 39s 144ms/step - loss: 0.9351 - accuracy: 0.6675 - val_loss: 0.7452 - val_accuracy: 0.7250\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 39s 144ms/step - loss: 0.7521 - accuracy: 0.7257 - val_loss: 0.6625 - val_accuracy: 0.7599\n",
      "Trying hyperparameters: lstm_units_1=416, lstm_units_2=304, dense_units=448, dropout_rate=0.5, learning_rate=0.0002993805408372818, batch_size=256\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 68s 246ms/step - loss: 1.7795 - accuracy: 0.3566 - val_loss: 1.7393 - val_accuracy: 0.3967\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 64s 238ms/step - loss: 1.6462 - accuracy: 0.4168 - val_loss: 1.3707 - val_accuracy: 0.5086\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 64s 239ms/step - loss: 1.4585 - accuracy: 0.4946 - val_loss: 1.1590 - val_accuracy: 0.5997\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 64s 239ms/step - loss: 1.1746 - accuracy: 0.5963 - val_loss: 0.9419 - val_accuracy: 0.6730\n",
      "Trying hyperparameters: lstm_units_1=64, lstm_units_2=32, dense_units=512, dropout_rate=0.4, learning_rate=0.000698781119998909, batch_size=256\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 19s 63ms/step - loss: 2.0142 - accuracy: 0.2795 - val_loss: 1.2347 - val_accuracy: 0.5606\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 1.3277 - accuracy: 0.5409 - val_loss: 1.2271 - val_accuracy: 0.5756\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 1.2511 - accuracy: 0.5832 - val_loss: 1.2249 - val_accuracy: 0.5924\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 1.2337 - accuracy: 0.5963 - val_loss: 1.1067 - val_accuracy: 0.6154\n",
      "Epoch 5/20\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 1.1644 - accuracy: 0.6141 - val_loss: 1.1051 - val_accuracy: 0.6231\n",
      "Epoch 6/20\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 1.2519 - accuracy: 0.5842 - val_loss: 1.1078 - val_accuracy: 0.6221\n",
      "Epoch 7/20\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 1.1908 - accuracy: 0.6099 - val_loss: 1.1405 - val_accuracy: 0.6076\n",
      "Epoch 8/20\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 1.1973 - accuracy: 0.6073 - val_loss: 1.1347 - val_accuracy: 0.6173\n",
      "Epoch 9/20\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 1.1669 - accuracy: 0.6129 - val_loss: 1.1545 - val_accuracy: 0.5475\n",
      "Epoch 10/20\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 1.2772 - accuracy: 0.5276 - val_loss: 1.2739 - val_accuracy: 0.5354\n",
      "Epoch 11/20\n",
      "268/268 [==============================] - 16s 61ms/step - loss: 1.3382 - accuracy: 0.5185 - val_loss: 1.1330 - val_accuracy: 0.5780\n",
      "Epoch 12/20\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 1.1806 - accuracy: 0.5612 - val_loss: 1.0668 - val_accuracy: 0.6026\n",
      "Epoch 13/20\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 1.1400 - accuracy: 0.5859 - val_loss: 1.2983 - val_accuracy: 0.5602\n",
      "Epoch 14/20\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 1.2511 - accuracy: 0.5659 - val_loss: 1.0111 - val_accuracy: 0.6611\n",
      "Epoch 15/20\n",
      "268/268 [==============================] - 16s 61ms/step - loss: 1.0938 - accuracy: 0.6399 - val_loss: 0.9673 - val_accuracy: 0.6736\n",
      "Epoch 16/20\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 1.0932 - accuracy: 0.6311 - val_loss: 1.0705 - val_accuracy: 0.6205\n",
      "Epoch 17/20\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 1.0978 - accuracy: 0.6187 - val_loss: 1.0579 - val_accuracy: 0.6288\n",
      "Epoch 18/20\n",
      "268/268 [==============================] - 16s 61ms/step - loss: 1.0870 - accuracy: 0.6284 - val_loss: 0.9627 - val_accuracy: 0.6625\n",
      "Epoch 19/20\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 1.0512 - accuracy: 0.6480 - val_loss: 0.9763 - val_accuracy: 0.6625\n",
      "Epoch 20/20\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 1.0169 - accuracy: 0.6631 - val_loss: 1.0470 - val_accuracy: 0.6314\n",
      "Trying hyperparameters: lstm_units_1=192, lstm_units_2=128, dense_units=128, dropout_rate=0.4, learning_rate=0.0012911503305504748, batch_size=256\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 26s 88ms/step - loss: 1.8958 - accuracy: 0.3245 - val_loss: 1.1749 - val_accuracy: 0.6144\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 23s 86ms/step - loss: 1.1852 - accuracy: 0.5978 - val_loss: 0.9546 - val_accuracy: 0.6661\n",
      "Trying hyperparameters: lstm_units_1=128, lstm_units_2=64, dense_units=64, dropout_rate=0.4, learning_rate=0.0009511165874729555, batch_size=256\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 20s 67ms/step - loss: 1.8695 - accuracy: 0.3421 - val_loss: 1.2308 - val_accuracy: 0.5697\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 17s 65ms/step - loss: 1.3415 - accuracy: 0.5410 - val_loss: 1.2854 - val_accuracy: 0.5610\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 17s 65ms/step - loss: 1.2783 - accuracy: 0.5641 - val_loss: 1.0072 - val_accuracy: 0.6520\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 17s 64ms/step - loss: 1.1560 - accuracy: 0.6005 - val_loss: 0.8940 - val_accuracy: 0.6855\n",
      "Epoch 5/20\n",
      "268/268 [==============================] - 17s 65ms/step - loss: 0.9399 - accuracy: 0.6826 - val_loss: 0.9263 - val_accuracy: 0.6943\n",
      "Epoch 6/20\n",
      "268/268 [==============================] - 17s 65ms/step - loss: 0.9240 - accuracy: 0.6829 - val_loss: 0.8588 - val_accuracy: 0.6950\n",
      "Epoch 7/20\n",
      "268/268 [==============================] - 18s 65ms/step - loss: 0.8625 - accuracy: 0.6993 - val_loss: 0.7440 - val_accuracy: 0.7274\n",
      "Epoch 8/20\n",
      "268/268 [==============================] - 17s 65ms/step - loss: 0.7753 - accuracy: 0.7274 - val_loss: 0.7126 - val_accuracy: 0.7361\n",
      "Epoch 9/20\n",
      "268/268 [==============================] - 17s 64ms/step - loss: 0.7267 - accuracy: 0.7420 - val_loss: 0.6675 - val_accuracy: 0.7614\n",
      "Epoch 10/20\n",
      "268/268 [==============================] - 17s 65ms/step - loss: 0.7340 - accuracy: 0.7441 - val_loss: 0.7024 - val_accuracy: 0.7504\n",
      "Epoch 11/20\n",
      "268/268 [==============================] - 17s 65ms/step - loss: 0.7210 - accuracy: 0.7520 - val_loss: 0.6443 - val_accuracy: 0.7736\n",
      "Epoch 12/20\n",
      "268/268 [==============================] - 17s 65ms/step - loss: 0.6426 - accuracy: 0.7786 - val_loss: 0.6017 - val_accuracy: 0.7882\n",
      "Epoch 13/20\n",
      "268/268 [==============================] - 17s 65ms/step - loss: 0.5919 - accuracy: 0.7955 - val_loss: 0.5742 - val_accuracy: 0.7990\n",
      "Epoch 14/20\n",
      "268/268 [==============================] - 17s 65ms/step - loss: 0.5570 - accuracy: 0.8148 - val_loss: 0.5534 - val_accuracy: 0.8100\n",
      "Epoch 15/20\n",
      "268/268 [==============================] - 17s 65ms/step - loss: 0.5146 - accuracy: 0.8252 - val_loss: 0.5331 - val_accuracy: 0.8224\n",
      "Epoch 16/20\n",
      "268/268 [==============================] - 18s 66ms/step - loss: 0.4807 - accuracy: 0.8413 - val_loss: 0.5141 - val_accuracy: 0.8275\n",
      "Epoch 17/20\n",
      "268/268 [==============================] - 17s 65ms/step - loss: 0.4518 - accuracy: 0.8515 - val_loss: 0.4977 - val_accuracy: 0.8339\n",
      "Epoch 18/20\n",
      "268/268 [==============================] - 17s 65ms/step - loss: 0.4225 - accuracy: 0.8632 - val_loss: 0.4891 - val_accuracy: 0.8412\n",
      "Epoch 19/20\n",
      "268/268 [==============================] - 17s 64ms/step - loss: 0.3978 - accuracy: 0.8730 - val_loss: 0.4856 - val_accuracy: 0.8422\n",
      "Epoch 20/20\n",
      "268/268 [==============================] - 17s 64ms/step - loss: 0.3686 - accuracy: 0.8828 - val_loss: 0.4737 - val_accuracy: 0.8496\n",
      "Trying hyperparameters: lstm_units_1=256, lstm_units_2=160, dense_units=160, dropout_rate=0.4, learning_rate=0.0007513305606865134, batch_size=256\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 33s 115ms/step - loss: 1.7807 - accuracy: 0.3648 - val_loss: 1.4781 - val_accuracy: 0.5044\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 31s 114ms/step - loss: 1.7257 - accuracy: 0.4012 - val_loss: 1.0776 - val_accuracy: 0.6265\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 31s 115ms/step - loss: 1.1626 - accuracy: 0.6035 - val_loss: 0.9421 - val_accuracy: 0.6702\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 31s 114ms/step - loss: 0.9844 - accuracy: 0.6614 - val_loss: 0.8270 - val_accuracy: 0.7016\n",
      "Trying hyperparameters: lstm_units_1=352, lstm_units_2=240, dense_units=224, dropout_rate=0.30000000000000004, learning_rate=0.0009265279159479217, batch_size=256\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 51s 182ms/step - loss: 1.7972 - accuracy: 0.3623 - val_loss: 1.0376 - val_accuracy: 0.6335\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 48s 180ms/step - loss: 0.9838 - accuracy: 0.6597 - val_loss: 0.6732 - val_accuracy: 0.7621\n",
      "Trying hyperparameters: lstm_units_1=192, lstm_units_2=160, dense_units=128, dropout_rate=0.4, learning_rate=0.0004840687080060693, batch_size=256\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 28s 97ms/step - loss: 1.8001 - accuracy: 0.3669 - val_loss: 1.2463 - val_accuracy: 0.5627\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 26s 95ms/step - loss: 1.2579 - accuracy: 0.5722 - val_loss: 1.0839 - val_accuracy: 0.6531\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 26s 95ms/step - loss: 1.1904 - accuracy: 0.6061 - val_loss: 1.5386 - val_accuracy: 0.4851\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 26s 95ms/step - loss: 1.4367 - accuracy: 0.5017 - val_loss: 1.0708 - val_accuracy: 0.6279\n",
      "Epoch 5/20\n",
      "268/268 [==============================] - 25s 95ms/step - loss: 1.1080 - accuracy: 0.6235 - val_loss: 0.9654 - val_accuracy: 0.6633\n",
      "Epoch 6/20\n",
      "268/268 [==============================] - 26s 95ms/step - loss: 0.9715 - accuracy: 0.6723 - val_loss: 0.9406 - val_accuracy: 0.6857\n",
      "Epoch 7/20\n",
      "268/268 [==============================] - 26s 95ms/step - loss: 1.1063 - accuracy: 0.6272 - val_loss: 1.0092 - val_accuracy: 0.6585\n",
      "Epoch 8/20\n",
      "268/268 [==============================] - 26s 96ms/step - loss: 1.0185 - accuracy: 0.6543 - val_loss: 0.8770 - val_accuracy: 0.6923\n",
      "Epoch 9/20\n",
      "268/268 [==============================] - 26s 96ms/step - loss: 1.0090 - accuracy: 0.6614 - val_loss: 0.8271 - val_accuracy: 0.7073\n",
      "Epoch 10/20\n",
      "268/268 [==============================] - 25s 95ms/step - loss: 0.8375 - accuracy: 0.7143 - val_loss: 0.8158 - val_accuracy: 0.7301\n",
      "Epoch 11/20\n",
      "268/268 [==============================] - 26s 95ms/step - loss: 0.8198 - accuracy: 0.7219 - val_loss: 0.7519 - val_accuracy: 0.7359\n",
      "Epoch 12/20\n",
      "268/268 [==============================] - 26s 95ms/step - loss: 0.7580 - accuracy: 0.7352 - val_loss: 0.8189 - val_accuracy: 0.7344\n",
      "Epoch 13/20\n",
      "268/268 [==============================] - 26s 95ms/step - loss: 0.7825 - accuracy: 0.7381 - val_loss: 0.6994 - val_accuracy: 0.7570\n",
      "Epoch 14/20\n",
      "268/268 [==============================] - 26s 96ms/step - loss: 0.6923 - accuracy: 0.7656 - val_loss: 0.6608 - val_accuracy: 0.7766\n",
      "Epoch 15/20\n",
      "268/268 [==============================] - 26s 96ms/step - loss: 0.6720 - accuracy: 0.7760 - val_loss: 0.6406 - val_accuracy: 0.7865\n",
      "Epoch 16/20\n",
      "268/268 [==============================] - 26s 95ms/step - loss: 0.6298 - accuracy: 0.7888 - val_loss: 0.6041 - val_accuracy: 0.8003\n",
      "Epoch 17/20\n",
      "268/268 [==============================] - 26s 95ms/step - loss: 0.5871 - accuracy: 0.8054 - val_loss: 0.5881 - val_accuracy: 0.8065\n",
      "Epoch 18/20\n",
      "268/268 [==============================] - 25s 95ms/step - loss: 0.5702 - accuracy: 0.8132 - val_loss: 0.5660 - val_accuracy: 0.8132\n",
      "Epoch 19/20\n",
      "268/268 [==============================] - 26s 95ms/step - loss: 0.5448 - accuracy: 0.8209 - val_loss: 0.5402 - val_accuracy: 0.8244\n",
      "Epoch 20/20\n",
      "268/268 [==============================] - 26s 96ms/step - loss: 0.5276 - accuracy: 0.8319 - val_loss: 0.6977 - val_accuracy: 0.7741\n",
      "Trying hyperparameters: lstm_units_1=448, lstm_units_2=352, dense_units=96, dropout_rate=0.5, learning_rate=0.0017933202610893903, batch_size=256\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 77s 279ms/step - loss: 2.1410 - accuracy: 0.2661 - val_loss: 1.1889 - val_accuracy: 0.5782\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 75s 279ms/step - loss: 1.0756 - accuracy: 0.6227 - val_loss: 0.7958 - val_accuracy: 0.7092\n",
      "Trying hyperparameters: lstm_units_1=384, lstm_units_2=288, dense_units=192, dropout_rate=0.4, learning_rate=0.0011235914069548, batch_size=256\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 61s 220ms/step - loss: 1.9513 - accuracy: 0.3111 - val_loss: 1.6766 - val_accuracy: 0.3801\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 59s 219ms/step - loss: 1.4531 - accuracy: 0.4735 - val_loss: 0.8883 - val_accuracy: 0.6795\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 59s 219ms/step - loss: 1.0458 - accuracy: 0.6387 - val_loss: 0.7907 - val_accuracy: 0.7183\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 59s 220ms/step - loss: 0.9213 - accuracy: 0.6772 - val_loss: 0.7546 - val_accuracy: 0.7399\n",
      "Trying hyperparameters: lstm_units_1=288, lstm_units_2=208, dense_units=288, dropout_rate=0.30000000000000004, learning_rate=0.00258165066228411, batch_size=256\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 44s 157ms/step - loss: 1.6598 - accuracy: 0.4109 - val_loss: 0.7966 - val_accuracy: 0.7164\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 40s 149ms/step - loss: 0.7631 - accuracy: 0.7341 - val_loss: 0.5711 - val_accuracy: 0.8042\n",
      "Trying hyperparameters: lstm_units_1=224, lstm_units_2=176, dense_units=128, dropout_rate=0.2, learning_rate=0.00036812524357872155, batch_size=256\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 32s 114ms/step - loss: 1.7915 - accuracy: 0.3616 - val_loss: 1.3107 - val_accuracy: 0.5473\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 30s 112ms/step - loss: 1.2858 - accuracy: 0.5648 - val_loss: 1.1834 - val_accuracy: 0.6051\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 30s 112ms/step - loss: 1.1755 - accuracy: 0.6072 - val_loss: 1.0389 - val_accuracy: 0.6466\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 30s 112ms/step - loss: 1.1265 - accuracy: 0.6214 - val_loss: 1.1792 - val_accuracy: 0.5939\n",
      "Epoch 5/20\n",
      "268/268 [==============================] - 30s 112ms/step - loss: 1.2531 - accuracy: 0.5798 - val_loss: 1.0303 - val_accuracy: 0.6579\n",
      "Epoch 6/20\n",
      "268/268 [==============================] - 30s 112ms/step - loss: 1.0379 - accuracy: 0.6626 - val_loss: 0.9996 - val_accuracy: 0.6629\n",
      "Epoch 7/20\n",
      "268/268 [==============================] - 30s 112ms/step - loss: 0.9484 - accuracy: 0.6792 - val_loss: 0.8265 - val_accuracy: 0.7144\n",
      "Epoch 8/20\n",
      "268/268 [==============================] - 30s 112ms/step - loss: 0.8471 - accuracy: 0.7105 - val_loss: 0.7707 - val_accuracy: 0.7256\n",
      "Epoch 9/20\n",
      "268/268 [==============================] - 30s 112ms/step - loss: 0.7778 - accuracy: 0.7331 - val_loss: 0.7431 - val_accuracy: 0.7476\n",
      "Epoch 10/20\n",
      "268/268 [==============================] - 30s 112ms/step - loss: 0.8284 - accuracy: 0.7219 - val_loss: 0.7821 - val_accuracy: 0.7376\n",
      "Trying hyperparameters: lstm_units_1=416, lstm_units_2=336, dense_units=192, dropout_rate=0.5, learning_rate=0.00020887461063286006, batch_size=256\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 72s 261ms/step - loss: 1.7784 - accuracy: 0.3761 - val_loss: 1.0676 - val_accuracy: 0.6404\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 70s 259ms/step - loss: 1.2398 - accuracy: 0.5970 - val_loss: 1.0865 - val_accuracy: 0.6480\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 70s 260ms/step - loss: 1.0301 - accuracy: 0.6699 - val_loss: 1.0889 - val_accuracy: 0.6450\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 70s 261ms/step - loss: 1.0591 - accuracy: 0.6633 - val_loss: 1.2738 - val_accuracy: 0.5813\n",
      "Epoch 5/20\n",
      "268/268 [==============================] - 70s 260ms/step - loss: 1.3321 - accuracy: 0.5676 - val_loss: 1.2195 - val_accuracy: 0.6088\n",
      "Epoch 6/20\n",
      "268/268 [==============================] - 70s 260ms/step - loss: 1.1935 - accuracy: 0.6111 - val_loss: 1.0792 - val_accuracy: 0.6573\n",
      "Epoch 7/20\n",
      "268/268 [==============================] - 70s 260ms/step - loss: 1.0169 - accuracy: 0.6756 - val_loss: 0.9692 - val_accuracy: 0.6919\n",
      "Epoch 8/20\n",
      "268/268 [==============================] - 70s 260ms/step - loss: 1.0287 - accuracy: 0.6718 - val_loss: 0.8084 - val_accuracy: 0.7408\n",
      "Epoch 9/20\n",
      "268/268 [==============================] - 70s 260ms/step - loss: 0.8466 - accuracy: 0.7290 - val_loss: 0.7711 - val_accuracy: 0.7447\n",
      "Epoch 10/20\n",
      "268/268 [==============================] - 70s 260ms/step - loss: 0.7828 - accuracy: 0.7486 - val_loss: 0.6963 - val_accuracy: 0.7706\n",
      "Epoch 11/20\n",
      "268/268 [==============================] - 70s 260ms/step - loss: 0.7037 - accuracy: 0.7716 - val_loss: 0.6777 - val_accuracy: 0.7729\n",
      "Epoch 12/20\n",
      "268/268 [==============================] - 70s 260ms/step - loss: 0.6692 - accuracy: 0.7786 - val_loss: 0.6252 - val_accuracy: 0.7893\n",
      "Epoch 13/20\n",
      "268/268 [==============================] - 70s 260ms/step - loss: 0.6282 - accuracy: 0.7921 - val_loss: 0.6096 - val_accuracy: 0.7936\n",
      "Epoch 14/20\n",
      "268/268 [==============================] - 70s 260ms/step - loss: 0.5867 - accuracy: 0.8064 - val_loss: 0.5777 - val_accuracy: 0.8058\n",
      "Epoch 15/20\n",
      "268/268 [==============================] - 69s 259ms/step - loss: 0.5539 - accuracy: 0.8156 - val_loss: 0.5612 - val_accuracy: 0.8120\n",
      "Epoch 16/20\n",
      "268/268 [==============================] - 70s 260ms/step - loss: 0.5343 - accuracy: 0.8215 - val_loss: 0.5359 - val_accuracy: 0.8202\n",
      "Epoch 17/20\n",
      "268/268 [==============================] - 70s 260ms/step - loss: 0.5004 - accuracy: 0.8318 - val_loss: 0.5167 - val_accuracy: 0.8267\n",
      "Epoch 18/20\n",
      "268/268 [==============================] - 70s 260ms/step - loss: 0.4958 - accuracy: 0.8358 - val_loss: 0.5176 - val_accuracy: 0.8276\n",
      "Epoch 19/20\n",
      "268/268 [==============================] - 69s 259ms/step - loss: 0.4687 - accuracy: 0.8444 - val_loss: 0.4942 - val_accuracy: 0.8353\n",
      "Epoch 20/20\n",
      "268/268 [==============================] - 70s 260ms/step - loss: 0.4445 - accuracy: 0.8531 - val_loss: 0.4836 - val_accuracy: 0.8377\n",
      "Trying hyperparameters: lstm_units_1=224, lstm_units_2=112, dense_units=256, dropout_rate=0.30000000000000004, learning_rate=0.0014044157816303468, batch_size=256\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 28s 97ms/step - loss: 1.7450 - accuracy: 0.3856 - val_loss: 1.3156 - val_accuracy: 0.5511\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 25s 95ms/step - loss: 1.2524 - accuracy: 0.5728 - val_loss: 0.8555 - val_accuracy: 0.6898\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 25s 95ms/step - loss: 0.8012 - accuracy: 0.7101 - val_loss: 0.6658 - val_accuracy: 0.7570\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 25s 95ms/step - loss: 0.6506 - accuracy: 0.7698 - val_loss: 0.5852 - val_accuracy: 0.7985\n",
      "Trying hyperparameters: lstm_units_1=160, lstm_units_2=112, dense_units=352, dropout_rate=0.2, learning_rate=0.001438675273199011, batch_size=256\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 25s 79ms/step - loss: 1.8347 - accuracy: 0.3430 - val_loss: 1.4805 - val_accuracy: 0.5138\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 21s 77ms/step - loss: 1.4551 - accuracy: 0.4942 - val_loss: 1.1920 - val_accuracy: 0.5712\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 21s 77ms/step - loss: 1.1062 - accuracy: 0.6192 - val_loss: 0.8153 - val_accuracy: 0.7080\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 20s 76ms/step - loss: 0.8248 - accuracy: 0.7112 - val_loss: 0.7408 - val_accuracy: 0.7479\n",
      "Trying hyperparameters: lstm_units_1=256, lstm_units_2=224, dense_units=320, dropout_rate=0.30000000000000004, learning_rate=0.00096978757328838, batch_size=256\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 37s 133ms/step - loss: 1.8526 - accuracy: 0.3416 - val_loss: 1.4765 - val_accuracy: 0.4707\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 35s 131ms/step - loss: 1.7129 - accuracy: 0.3890 - val_loss: 1.2262 - val_accuracy: 0.5551\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 35s 131ms/step - loss: 1.2395 - accuracy: 0.5548 - val_loss: 0.8244 - val_accuracy: 0.7056\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 35s 131ms/step - loss: 0.8679 - accuracy: 0.6958 - val_loss: 0.7104 - val_accuracy: 0.7319\n",
      "Trying hyperparameters: lstm_units_1=224, lstm_units_2=144, dense_units=160, dropout_rate=0.4, learning_rate=0.00011774491095496701, batch_size=256\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 30s 104ms/step - loss: 2.1663 - accuracy: 0.2374 - val_loss: 1.2979 - val_accuracy: 0.5434\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 27s 102ms/step - loss: 1.2378 - accuracy: 0.5819 - val_loss: 1.2669 - val_accuracy: 0.5954\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 27s 103ms/step - loss: 1.1553 - accuracy: 0.6144 - val_loss: 1.1677 - val_accuracy: 0.6159\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 27s 102ms/step - loss: 1.0706 - accuracy: 0.6591 - val_loss: 0.9811 - val_accuracy: 0.6843\n",
      "Epoch 5/20\n",
      "268/268 [==============================] - 27s 102ms/step - loss: 0.9801 - accuracy: 0.6952 - val_loss: 0.9541 - val_accuracy: 0.6867\n",
      "Epoch 6/20\n",
      "268/268 [==============================] - 27s 102ms/step - loss: 0.9655 - accuracy: 0.6931 - val_loss: 0.9366 - val_accuracy: 0.6987\n",
      "Epoch 7/20\n",
      "268/268 [==============================] - 27s 102ms/step - loss: 0.9568 - accuracy: 0.7015 - val_loss: 0.9318 - val_accuracy: 0.7059\n",
      "Epoch 8/20\n",
      "268/268 [==============================] - 27s 102ms/step - loss: 0.9112 - accuracy: 0.7188 - val_loss: 0.8941 - val_accuracy: 0.7051\n",
      "Epoch 9/20\n",
      "268/268 [==============================] - 27s 102ms/step - loss: 0.8986 - accuracy: 0.7146 - val_loss: 0.8591 - val_accuracy: 0.7272\n",
      "Epoch 10/20\n",
      "268/268 [==============================] - 27s 102ms/step - loss: 0.9462 - accuracy: 0.6997 - val_loss: 1.0740 - val_accuracy: 0.6304\n",
      "Epoch 11/20\n",
      "268/268 [==============================] - 27s 102ms/step - loss: 1.0181 - accuracy: 0.6671 - val_loss: 0.9268 - val_accuracy: 0.6945\n",
      "Epoch 12/20\n",
      "268/268 [==============================] - 27s 102ms/step - loss: 0.9175 - accuracy: 0.7042 - val_loss: 0.8898 - val_accuracy: 0.7103\n",
      "Epoch 13/20\n",
      "268/268 [==============================] - 27s 102ms/step - loss: 0.8864 - accuracy: 0.7178 - val_loss: 0.8498 - val_accuracy: 0.7255\n",
      "Epoch 14/20\n",
      "268/268 [==============================] - 27s 103ms/step - loss: 0.8508 - accuracy: 0.7322 - val_loss: 0.8617 - val_accuracy: 0.7253\n",
      "Epoch 15/20\n",
      "268/268 [==============================] - 27s 102ms/step - loss: 0.8613 - accuracy: 0.7294 - val_loss: 0.8283 - val_accuracy: 0.7332\n",
      "Epoch 16/20\n",
      "268/268 [==============================] - 27s 102ms/step - loss: 0.8402 - accuracy: 0.7351 - val_loss: 0.8234 - val_accuracy: 0.7377\n",
      "Epoch 17/20\n",
      "268/268 [==============================] - 27s 102ms/step - loss: 0.8451 - accuracy: 0.7412 - val_loss: 0.9351 - val_accuracy: 0.7162\n",
      "Epoch 18/20\n",
      "268/268 [==============================] - 27s 102ms/step - loss: 0.8751 - accuracy: 0.7308 - val_loss: 0.7952 - val_accuracy: 0.7433\n",
      "Epoch 19/20\n",
      "268/268 [==============================] - 27s 102ms/step - loss: 0.8152 - accuracy: 0.7472 - val_loss: 0.7922 - val_accuracy: 0.7464\n",
      "Epoch 20/20\n",
      "268/268 [==============================] - 27s 102ms/step - loss: 0.8803 - accuracy: 0.7204 - val_loss: 0.8423 - val_accuracy: 0.7305\n",
      "Trying hyperparameters: lstm_units_1=480, lstm_units_2=464, dense_units=64, dropout_rate=0.30000000000000004, learning_rate=0.0015655578860369695, batch_size=256\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 104s 377ms/step - loss: 1.9289 - accuracy: 0.3259 - val_loss: 1.0123 - val_accuracy: 0.6407\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 102s 379ms/step - loss: 0.9823 - accuracy: 0.6523 - val_loss: 0.7409 - val_accuracy: 0.7355\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 102s 381ms/step - loss: 0.7192 - accuracy: 0.7486 - val_loss: 0.6214 - val_accuracy: 0.7861\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 102s 381ms/step - loss: 0.5905 - accuracy: 0.7998 - val_loss: 0.5406 - val_accuracy: 0.8203\n",
      "Epoch 5/20\n",
      "268/268 [==============================] - 102s 382ms/step - loss: 0.5018 - accuracy: 0.8322 - val_loss: 0.4973 - val_accuracy: 0.8366\n",
      "Epoch 6/20\n",
      "268/268 [==============================] - 102s 381ms/step - loss: 0.4362 - accuracy: 0.8537 - val_loss: 0.4623 - val_accuracy: 0.8452\n",
      "Epoch 7/20\n",
      "268/268 [==============================] - 102s 382ms/step - loss: 0.3726 - accuracy: 0.8769 - val_loss: 0.4530 - val_accuracy: 0.8520\n",
      "Epoch 8/20\n",
      "268/268 [==============================] - 102s 382ms/step - loss: 0.3228 - accuracy: 0.8932 - val_loss: 0.4304 - val_accuracy: 0.8631\n",
      "Epoch 9/20\n",
      "268/268 [==============================] - 102s 382ms/step - loss: 0.2801 - accuracy: 0.9095 - val_loss: 0.4345 - val_accuracy: 0.8631\n",
      "Epoch 10/20\n",
      "268/268 [==============================] - 102s 382ms/step - loss: 0.2316 - accuracy: 0.9258 - val_loss: 0.4377 - val_accuracy: 0.8640\n",
      "Trying hyperparameters: lstm_units_1=128, lstm_units_2=96, dense_units=224, dropout_rate=0.4, learning_rate=0.001025075609561311, batch_size=256\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 21s 71ms/step - loss: 1.7987 - accuracy: 0.3544 - val_loss: 1.5457 - val_accuracy: 0.4436\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 18s 68ms/step - loss: 1.5483 - accuracy: 0.4605 - val_loss: 1.3712 - val_accuracy: 0.4997\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 18s 68ms/step - loss: 1.3327 - accuracy: 0.5393 - val_loss: 1.1342 - val_accuracy: 0.5977\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 18s 68ms/step - loss: 1.2485 - accuracy: 0.5753 - val_loss: 1.0154 - val_accuracy: 0.6513\n",
      "Epoch 5/20\n",
      "268/268 [==============================] - 18s 68ms/step - loss: 1.0772 - accuracy: 0.6341 - val_loss: 0.9377 - val_accuracy: 0.6756\n",
      "Epoch 6/20\n",
      "268/268 [==============================] - 18s 68ms/step - loss: 0.9864 - accuracy: 0.6649 - val_loss: 0.8915 - val_accuracy: 0.6831\n",
      "Epoch 7/20\n",
      "268/268 [==============================] - 18s 68ms/step - loss: 0.9598 - accuracy: 0.6636 - val_loss: 0.7892 - val_accuracy: 0.7229\n",
      "Epoch 8/20\n",
      "268/268 [==============================] - 18s 68ms/step - loss: 0.8309 - accuracy: 0.7166 - val_loss: 0.7144 - val_accuracy: 0.7518\n",
      "Epoch 9/20\n",
      "268/268 [==============================] - 18s 68ms/step - loss: 0.7218 - accuracy: 0.7536 - val_loss: 0.6697 - val_accuracy: 0.7656\n",
      "Epoch 10/20\n",
      "268/268 [==============================] - 18s 68ms/step - loss: 0.6679 - accuracy: 0.7731 - val_loss: 0.6319 - val_accuracy: 0.7848\n",
      "Trying hyperparameters: lstm_units_1=192, lstm_units_2=128, dense_units=256, dropout_rate=0.30000000000000004, learning_rate=0.002246463296780509, batch_size=256\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 26s 90ms/step - loss: 1.8287 - accuracy: 0.3520 - val_loss: 0.8201 - val_accuracy: 0.7104\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 24s 88ms/step - loss: 0.7887 - accuracy: 0.7180 - val_loss: 0.6528 - val_accuracy: 0.7739\n",
      "Trying hyperparameters: lstm_units_1=288, lstm_units_2=240, dense_units=96, dropout_rate=0.4, learning_rate=0.000603031517039846, batch_size=256\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 44s 158ms/step - loss: 1.8438 - accuracy: 0.3440 - val_loss: 1.7171 - val_accuracy: 0.4066\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 42s 156ms/step - loss: 1.4752 - accuracy: 0.4882 - val_loss: 1.1348 - val_accuracy: 0.6096\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 42s 156ms/step - loss: 1.1258 - accuracy: 0.6189 - val_loss: 1.0028 - val_accuracy: 0.6550\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 42s 156ms/step - loss: 0.9865 - accuracy: 0.6608 - val_loss: 0.8236 - val_accuracy: 0.7072\n",
      "Trying hyperparameters: lstm_units_1=512, lstm_units_2=416, dense_units=288, dropout_rate=0.30000000000000004, learning_rate=0.0028534212394763633, batch_size=256\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 96s 351ms/step - loss: 1.9330 - accuracy: 0.3177 - val_loss: 0.7992 - val_accuracy: 0.7176\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 94s 352ms/step - loss: 0.8412 - accuracy: 0.7071 - val_loss: 0.6435 - val_accuracy: 0.7815\n",
      "Trying hyperparameters: lstm_units_1=352, lstm_units_2=272, dense_units=96, dropout_rate=0.2, learning_rate=0.0017313222809075242, batch_size=256\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 55s 199ms/step - loss: 1.8595 - accuracy: 0.3422 - val_loss: 1.3229 - val_accuracy: 0.5473\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 53s 198ms/step - loss: 1.2309 - accuracy: 0.5708 - val_loss: 0.9564 - val_accuracy: 0.6528\n",
      "Trying hyperparameters: lstm_units_1=320, lstm_units_2=256, dense_units=480, dropout_rate=0.4, learning_rate=0.0005106763923001617, batch_size=256\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 47s 170ms/step - loss: 1.6531 - accuracy: 0.4176 - val_loss: 1.1504 - val_accuracy: 0.6307\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 45s 168ms/step - loss: 1.1000 - accuracy: 0.6472 - val_loss: 1.3848 - val_accuracy: 0.5486\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 45s 168ms/step - loss: 1.3543 - accuracy: 0.5509 - val_loss: 1.2628 - val_accuracy: 0.5831\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 45s 168ms/step - loss: 1.1990 - accuracy: 0.5946 - val_loss: 0.8974 - val_accuracy: 0.6901\n",
      "Trying hyperparameters: lstm_units_1=320, lstm_units_2=256, dense_units=352, dropout_rate=0.4, learning_rate=0.001133102357165758, batch_size=256\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 47s 169ms/step - loss: 1.8747 - accuracy: 0.3373 - val_loss: 1.5058 - val_accuracy: 0.4778\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 45s 167ms/step - loss: 1.3812 - accuracy: 0.5114 - val_loss: 0.9912 - val_accuracy: 0.6395\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 45s 168ms/step - loss: 0.9364 - accuracy: 0.6676 - val_loss: 0.7466 - val_accuracy: 0.7351\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 45s 168ms/step - loss: 0.7545 - accuracy: 0.7343 - val_loss: 0.6653 - val_accuracy: 0.7683\n",
      "Trying hyperparameters: lstm_units_1=384, lstm_units_2=288, dense_units=320, dropout_rate=0.4, learning_rate=0.0008203844301225715, batch_size=256\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 61s 221ms/step - loss: 1.7873 - accuracy: 0.3753 - val_loss: 1.4347 - val_accuracy: 0.5128\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 60s 224ms/step - loss: 1.4330 - accuracy: 0.5086 - val_loss: 1.0837 - val_accuracy: 0.6109\n",
      "Trying hyperparameters: lstm_units_1=480, lstm_units_2=400, dense_units=416, dropout_rate=0.4, learning_rate=0.0006875236751731518, batch_size=256\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 90s 330ms/step - loss: 1.7802 - accuracy: 0.3826 - val_loss: 1.2613 - val_accuracy: 0.5490\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 88s 329ms/step - loss: 1.1205 - accuracy: 0.6083 - val_loss: 0.8056 - val_accuracy: 0.7159\n",
      "Trying hyperparameters: lstm_units_1=256, lstm_units_2=224, dense_units=384, dropout_rate=0.4, learning_rate=0.0012247882153366676, batch_size=256\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 37s 132ms/step - loss: 1.8669 - accuracy: 0.3342 - val_loss: 2.4272 - val_accuracy: 0.1202\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 35s 130ms/step - loss: 2.3172 - accuracy: 0.1663 - val_loss: 1.5830 - val_accuracy: 0.3903\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 35s 130ms/step - loss: 1.5405 - accuracy: 0.4353 - val_loss: 1.0645 - val_accuracy: 0.6198\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 35s 131ms/step - loss: 1.0194 - accuracy: 0.6382 - val_loss: 0.7827 - val_accuracy: 0.7135\n",
      "Epoch 5/20\n",
      "268/268 [==============================] - 35s 131ms/step - loss: 0.7814 - accuracy: 0.7248 - val_loss: 0.6691 - val_accuracy: 0.7661\n",
      "Epoch 6/20\n",
      "268/268 [==============================] - 35s 131ms/step - loss: 0.6550 - accuracy: 0.7763 - val_loss: 0.6107 - val_accuracy: 0.7913\n",
      "Epoch 7/20\n",
      "268/268 [==============================] - 35s 131ms/step - loss: 0.5731 - accuracy: 0.8082 - val_loss: 0.5556 - val_accuracy: 0.8122\n",
      "Epoch 8/20\n",
      "268/268 [==============================] - 35s 131ms/step - loss: 0.5137 - accuracy: 0.8280 - val_loss: 0.5147 - val_accuracy: 0.8279\n",
      "Epoch 9/20\n",
      "268/268 [==============================] - 35s 131ms/step - loss: 0.4555 - accuracy: 0.8477 - val_loss: 0.4960 - val_accuracy: 0.8356\n",
      "Epoch 10/20\n",
      "268/268 [==============================] - 35s 131ms/step - loss: 0.4098 - accuracy: 0.8643 - val_loss: 0.4754 - val_accuracy: 0.8457\n",
      "Trying hyperparameters: lstm_units_1=416, lstm_units_2=336, dense_units=256, dropout_rate=0.5, learning_rate=0.0004582217885124093, batch_size=256\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 72s 260ms/step - loss: 1.7658 - accuracy: 0.3777 - val_loss: 1.3677 - val_accuracy: 0.5275\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 70s 259ms/step - loss: 1.2681 - accuracy: 0.5727 - val_loss: 1.3962 - val_accuracy: 0.5453\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 70s 260ms/step - loss: 1.2235 - accuracy: 0.5919 - val_loss: 1.0562 - val_accuracy: 0.6337\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 70s 260ms/step - loss: 1.0880 - accuracy: 0.6330 - val_loss: 0.9180 - val_accuracy: 0.6860\n",
      "Trying hyperparameters: lstm_units_1=352, lstm_units_2=272, dense_units=512, dropout_rate=0.4, learning_rate=0.0005909635905198796, batch_size=256\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 55s 200ms/step - loss: 1.7304 - accuracy: 0.3771 - val_loss: 1.4642 - val_accuracy: 0.4927\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 53s 198ms/step - loss: 1.4548 - accuracy: 0.4929 - val_loss: 1.1064 - val_accuracy: 0.6173\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 53s 198ms/step - loss: 1.0191 - accuracy: 0.6450 - val_loss: 0.8028 - val_accuracy: 0.7243\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 53s 199ms/step - loss: 0.7722 - accuracy: 0.7325 - val_loss: 0.6742 - val_accuracy: 0.7653\n",
      "Trying hyperparameters: lstm_units_1=288, lstm_units_2=208, dense_units=160, dropout_rate=0.30000000000000004, learning_rate=0.0015557502187004964, batch_size=256\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 42s 151ms/step - loss: 2.0052 - accuracy: 0.2878 - val_loss: 1.4994 - val_accuracy: 0.4562\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 40s 148ms/step - loss: 1.3853 - accuracy: 0.5098 - val_loss: 0.8283 - val_accuracy: 0.7131\n",
      "Trying hyperparameters: lstm_units_1=160, lstm_units_2=80, dense_units=64, dropout_rate=0.4, learning_rate=0.0008343963884784168, batch_size=256\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 22s 75ms/step - loss: 1.9174 - accuracy: 0.3294 - val_loss: 1.7515 - val_accuracy: 0.3595\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 19s 73ms/step - loss: 1.6121 - accuracy: 0.4336 - val_loss: 1.1117 - val_accuracy: 0.5998\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 19s 73ms/step - loss: 1.2036 - accuracy: 0.5853 - val_loss: 1.0477 - val_accuracy: 0.6311\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 20s 73ms/step - loss: 1.0557 - accuracy: 0.6335 - val_loss: 0.8442 - val_accuracy: 0.6949\n",
      "Epoch 5/20\n",
      "268/268 [==============================] - 19s 73ms/step - loss: 0.9023 - accuracy: 0.6844 - val_loss: 0.7664 - val_accuracy: 0.7210\n",
      "Epoch 6/20\n",
      "268/268 [==============================] - 19s 72ms/step - loss: 0.8063 - accuracy: 0.7198 - val_loss: 0.7228 - val_accuracy: 0.7435\n",
      "Epoch 7/20\n",
      "268/268 [==============================] - 19s 72ms/step - loss: 0.7311 - accuracy: 0.7466 - val_loss: 0.6628 - val_accuracy: 0.7651\n",
      "Epoch 8/20\n",
      "268/268 [==============================] - 19s 72ms/step - loss: 0.6778 - accuracy: 0.7670 - val_loss: 0.6300 - val_accuracy: 0.7840\n",
      "Epoch 9/20\n",
      "268/268 [==============================] - 19s 72ms/step - loss: 0.6271 - accuracy: 0.7882 - val_loss: 0.5928 - val_accuracy: 0.7994\n",
      "Epoch 10/20\n",
      "268/268 [==============================] - 19s 73ms/step - loss: 0.5877 - accuracy: 0.8037 - val_loss: 0.5577 - val_accuracy: 0.8140\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = embedding_matrix_word2vec\n",
    "study_bilstm_word2vec = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler(), pruner=optuna.pruners.HyperbandPruner())\n",
    "study_bilstm_word2vec.optimize(lambda trial: objective_bilstm(trial, embedding_matrix), n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying hyperparameters: gru_units_1=384, gru_units_2=64, dense_units=288, dropout_rate=0.2, learning_rate=0.002134662130371001, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 32s 110ms/step - loss: 1.6722 - accuracy: 0.4063 - val_loss: 0.4949 - val_accuracy: 0.8304\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 29s 109ms/step - loss: 0.4390 - accuracy: 0.8497 - val_loss: 0.4107 - val_accuracy: 0.8605\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 29s 110ms/step - loss: 0.2988 - accuracy: 0.8998 - val_loss: 0.3880 - val_accuracy: 0.8712\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 30s 111ms/step - loss: 0.2109 - accuracy: 0.9297 - val_loss: 0.4093 - val_accuracy: 0.8732\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 30s 112ms/step - loss: 0.1423 - accuracy: 0.9539 - val_loss: 0.5412 - val_accuracy: 0.8299\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 30s 112ms/step - loss: 0.2195 - accuracy: 0.9255 - val_loss: 0.4471 - val_accuracy: 0.8732\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 30s 112ms/step - loss: 0.1794 - accuracy: 0.9440 - val_loss: 0.4919 - val_accuracy: 0.8711\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 30s 112ms/step - loss: 0.0731 - accuracy: 0.9775 - val_loss: 0.5674 - val_accuracy: 0.8705\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 30s 112ms/step - loss: 0.0458 - accuracy: 0.9865 - val_loss: 0.6506 - val_accuracy: 0.8635\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 30s 113ms/step - loss: 0.0392 - accuracy: 0.9890 - val_loss: 0.6831 - val_accuracy: 0.8670\n",
      "Trying hyperparameters: gru_units_1=288, gru_units_2=256, dense_units=288, dropout_rate=0.4, learning_rate=0.00014111368126740154, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 37s 133ms/step - loss: 2.2737 - accuracy: 0.1934 - val_loss: 1.4758 - val_accuracy: 0.4397\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 35s 132ms/step - loss: 1.3954 - accuracy: 0.4813 - val_loss: 0.9281 - val_accuracy: 0.6794\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 35s 131ms/step - loss: 0.8652 - accuracy: 0.7071 - val_loss: 0.7061 - val_accuracy: 0.7582\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 35s 131ms/step - loss: 0.6863 - accuracy: 0.7690 - val_loss: 0.6070 - val_accuracy: 0.7956\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 35s 132ms/step - loss: 0.6036 - accuracy: 0.7990 - val_loss: 0.5629 - val_accuracy: 0.8093\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 35s 132ms/step - loss: 0.5492 - accuracy: 0.8140 - val_loss: 0.5316 - val_accuracy: 0.8180\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 35s 132ms/step - loss: 0.5076 - accuracy: 0.8253 - val_loss: 0.5116 - val_accuracy: 0.8252\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 35s 132ms/step - loss: 0.4737 - accuracy: 0.8357 - val_loss: 0.5028 - val_accuracy: 0.8279\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 35s 132ms/step - loss: 0.4582 - accuracy: 0.8422 - val_loss: 0.4750 - val_accuracy: 0.8398\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 35s 132ms/step - loss: 0.4294 - accuracy: 0.8516 - val_loss: 0.4558 - val_accuracy: 0.8455\n",
      "Trying hyperparameters: gru_units_1=352, gru_units_2=480, dense_units=352, dropout_rate=0.5, learning_rate=0.0006809865027975798, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 67s 234ms/step - loss: 1.7756 - accuracy: 0.3690 - val_loss: 0.5673 - val_accuracy: 0.8016\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 62s 233ms/step - loss: 0.5569 - accuracy: 0.8046 - val_loss: 0.4657 - val_accuracy: 0.8404\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 62s 233ms/step - loss: 0.4420 - accuracy: 0.8475 - val_loss: 0.4255 - val_accuracy: 0.8531\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 63s 234ms/step - loss: 0.3941 - accuracy: 0.8668 - val_loss: 0.4748 - val_accuracy: 0.8396\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 63s 234ms/step - loss: 0.3914 - accuracy: 0.8669 - val_loss: 0.3927 - val_accuracy: 0.8666\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 63s 234ms/step - loss: 0.3111 - accuracy: 0.8936 - val_loss: 0.3885 - val_accuracy: 0.8700\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 63s 234ms/step - loss: 0.2708 - accuracy: 0.9090 - val_loss: 0.3912 - val_accuracy: 0.8715\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 63s 234ms/step - loss: 0.2230 - accuracy: 0.9252 - val_loss: 0.4045 - val_accuracy: 0.8717\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 63s 235ms/step - loss: 0.1893 - accuracy: 0.9359 - val_loss: 0.4485 - val_accuracy: 0.8667\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 63s 235ms/step - loss: 0.1553 - accuracy: 0.9475 - val_loss: 0.4511 - val_accuracy: 0.8698\n",
      "Trying hyperparameters: gru_units_1=416, gru_units_2=448, dense_units=96, dropout_rate=0.4, learning_rate=0.00015772496837895155, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 70s 253ms/step - loss: 2.1942 - accuracy: 0.2194 - val_loss: 1.4772 - val_accuracy: 0.4888\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 67s 251ms/step - loss: 1.4884 - accuracy: 0.4804 - val_loss: 1.0549 - val_accuracy: 0.6448\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 68s 252ms/step - loss: 1.0119 - accuracy: 0.6599 - val_loss: 0.8774 - val_accuracy: 0.7019\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 68s 252ms/step - loss: 0.8589 - accuracy: 0.7071 - val_loss: 1.2725 - val_accuracy: 0.6137\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 68s 252ms/step - loss: 1.0221 - accuracy: 0.6656 - val_loss: 0.7229 - val_accuracy: 0.7468\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 68s 253ms/step - loss: 0.7278 - accuracy: 0.7448 - val_loss: 0.6410 - val_accuracy: 0.7721\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 68s 253ms/step - loss: 0.6498 - accuracy: 0.7748 - val_loss: 0.6027 - val_accuracy: 0.7878\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 68s 253ms/step - loss: 0.5898 - accuracy: 0.7961 - val_loss: 0.5529 - val_accuracy: 0.8064\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 68s 253ms/step - loss: 0.5475 - accuracy: 0.8094 - val_loss: 0.5303 - val_accuracy: 0.8176\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 68s 253ms/step - loss: 0.5108 - accuracy: 0.8242 - val_loss: 0.5196 - val_accuracy: 0.8196\n",
      "Trying hyperparameters: gru_units_1=320, gru_units_2=512, dense_units=256, dropout_rate=0.5, learning_rate=0.00044775334485244316, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 65s 234ms/step - loss: 1.8624 - accuracy: 0.3357 - val_loss: 0.6838 - val_accuracy: 0.7637\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 62s 233ms/step - loss: 0.6724 - accuracy: 0.7734 - val_loss: 0.6241 - val_accuracy: 0.7978\n",
      "Trying hyperparameters: gru_units_1=448, gru_units_2=224, dense_units=320, dropout_rate=0.30000000000000004, learning_rate=0.0005828247632791901, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 52s 187ms/step - loss: 1.8259 - accuracy: 0.3478 - val_loss: 0.6741 - val_accuracy: 0.7657\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 49s 185ms/step - loss: 0.6163 - accuracy: 0.7849 - val_loss: 0.5292 - val_accuracy: 0.8141\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 50s 185ms/step - loss: 0.4908 - accuracy: 0.8285 - val_loss: 0.4565 - val_accuracy: 0.8407\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 50s 185ms/step - loss: 0.4313 - accuracy: 0.8501 - val_loss: 0.4380 - val_accuracy: 0.8483\n",
      "Trying hyperparameters: gru_units_1=416, gru_units_2=416, dense_units=160, dropout_rate=0.4, learning_rate=0.0025481515201665338, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 66s 239ms/step - loss: 1.4993 - accuracy: 0.4773 - val_loss: 0.4748 - val_accuracy: 0.8360\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 64s 238ms/step - loss: 0.4342 - accuracy: 0.8498 - val_loss: 0.4262 - val_accuracy: 0.8558\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 64s 238ms/step - loss: 0.3032 - accuracy: 0.8963 - val_loss: 0.4107 - val_accuracy: 0.8639\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 64s 239ms/step - loss: 0.2069 - accuracy: 0.9320 - val_loss: 0.4200 - val_accuracy: 0.8710\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 64s 238ms/step - loss: 0.1476 - accuracy: 0.9516 - val_loss: 0.4609 - val_accuracy: 0.8682\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 64s 238ms/step - loss: 0.1109 - accuracy: 0.9645 - val_loss: 0.4993 - val_accuracy: 0.8645\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 64s 239ms/step - loss: 0.1010 - accuracy: 0.9672 - val_loss: 0.5163 - val_accuracy: 0.8653\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 64s 240ms/step - loss: 0.0914 - accuracy: 0.9701 - val_loss: 0.5410 - val_accuracy: 0.8615\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 64s 240ms/step - loss: 0.0884 - accuracy: 0.9716 - val_loss: 0.5604 - val_accuracy: 0.8624\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 64s 240ms/step - loss: 0.0920 - accuracy: 0.9702 - val_loss: 0.5615 - val_accuracy: 0.8595\n",
      "Trying hyperparameters: gru_units_1=160, gru_units_2=224, dense_units=64, dropout_rate=0.2, learning_rate=0.00018355835454236428, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 26s 91ms/step - loss: 2.2466 - accuracy: 0.1996 - val_loss: 1.3868 - val_accuracy: 0.4993\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 24s 90ms/step - loss: 1.2743 - accuracy: 0.5352 - val_loss: 1.0238 - val_accuracy: 0.6408\n",
      "Trying hyperparameters: gru_units_1=224, gru_units_2=224, dense_units=512, dropout_rate=0.4, learning_rate=0.004240691022815976, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 31s 109ms/step - loss: 1.5230 - accuracy: 0.4674 - val_loss: 0.4709 - val_accuracy: 0.8398\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 29s 107ms/step - loss: 0.4137 - accuracy: 0.8600 - val_loss: 0.4093 - val_accuracy: 0.8646\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 29s 107ms/step - loss: 0.2900 - accuracy: 0.9032 - val_loss: 0.4122 - val_accuracy: 0.8667\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 29s 107ms/step - loss: 0.2025 - accuracy: 0.9348 - val_loss: 0.4538 - val_accuracy: 0.8664\n",
      "Trying hyperparameters: gru_units_1=256, gru_units_2=256, dense_units=160, dropout_rate=0.4, learning_rate=0.0001266389336311864, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 34s 120ms/step - loss: 2.2917 - accuracy: 0.1927 - val_loss: 1.6468 - val_accuracy: 0.3818\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 32s 118ms/step - loss: 1.5072 - accuracy: 0.4429 - val_loss: 1.0883 - val_accuracy: 0.6183\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 32s 119ms/step - loss: 1.0409 - accuracy: 0.6342 - val_loss: 0.8592 - val_accuracy: 0.6945\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 32s 118ms/step - loss: 0.8380 - accuracy: 0.7104 - val_loss: 0.6767 - val_accuracy: 0.7622\n",
      "Trying hyperparameters: gru_units_1=512, gru_units_2=352, dense_units=448, dropout_rate=0.5, learning_rate=0.008531968225534677, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 69s 249ms/step - loss: 1.3427 - accuracy: 0.5417 - val_loss: 0.5920 - val_accuracy: 0.7992\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 63s 234ms/step - loss: 0.7507 - accuracy: 0.7459 - val_loss: 2.4829 - val_accuracy: 0.0949\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 57s 212ms/step - loss: 2.4839 - accuracy: 0.0939 - val_loss: 2.4828 - val_accuracy: 0.0897\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 57s 212ms/step - loss: 2.4835 - accuracy: 0.0923 - val_loss: 2.4831 - val_accuracy: 0.0949\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 57s 212ms/step - loss: 2.4830 - accuracy: 0.0950 - val_loss: 2.4837 - val_accuracy: 0.0949\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 57s 212ms/step - loss: 2.4834 - accuracy: 0.0939 - val_loss: 2.4833 - val_accuracy: 0.0949\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 57s 212ms/step - loss: 2.4833 - accuracy: 0.0894 - val_loss: 2.4828 - val_accuracy: 0.0949\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 57s 212ms/step - loss: 2.4834 - accuracy: 0.0941 - val_loss: 2.4835 - val_accuracy: 0.0949\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 57s 212ms/step - loss: 2.4831 - accuracy: 0.0945 - val_loss: 2.4833 - val_accuracy: 0.0949\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 57s 212ms/step - loss: 2.4836 - accuracy: 0.0919 - val_loss: 2.4834 - val_accuracy: 0.0949\n",
      "Trying hyperparameters: gru_units_1=352, gru_units_2=96, dense_units=384, dropout_rate=0.2, learning_rate=0.0014012526438692211, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 33s 117ms/step - loss: 1.6563 - accuracy: 0.4120 - val_loss: 0.6145 - val_accuracy: 0.7780\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 31s 115ms/step - loss: 0.5583 - accuracy: 0.8042 - val_loss: 0.4741 - val_accuracy: 0.8331\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 31s 115ms/step - loss: 0.4415 - accuracy: 0.8489 - val_loss: 0.4318 - val_accuracy: 0.8508\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 31s 115ms/step - loss: 0.3678 - accuracy: 0.8740 - val_loss: 0.4076 - val_accuracy: 0.8621\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 31s 115ms/step - loss: 0.2977 - accuracy: 0.8980 - val_loss: 0.3828 - val_accuracy: 0.8708\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 31s 115ms/step - loss: 0.2451 - accuracy: 0.9170 - val_loss: 0.3954 - val_accuracy: 0.8717\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 31s 115ms/step - loss: 0.1867 - accuracy: 0.9379 - val_loss: 0.4334 - val_accuracy: 0.8705\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 31s 115ms/step - loss: 0.1444 - accuracy: 0.9525 - val_loss: 0.4487 - val_accuracy: 0.8733\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 31s 115ms/step - loss: 0.1075 - accuracy: 0.9645 - val_loss: 0.5276 - val_accuracy: 0.8652\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 31s 115ms/step - loss: 0.0835 - accuracy: 0.9720 - val_loss: 0.5590 - val_accuracy: 0.8661\n",
      "Trying hyperparameters: gru_units_1=64, gru_units_2=64, dense_units=352, dropout_rate=0.30000000000000004, learning_rate=0.0016518062704933903, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 18s 60ms/step - loss: 2.0087 - accuracy: 0.2763 - val_loss: 0.9025 - val_accuracy: 0.6765\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 15s 57ms/step - loss: 0.8797 - accuracy: 0.6856 - val_loss: 0.6588 - val_accuracy: 0.7652\n",
      "Trying hyperparameters: gru_units_1=352, gru_units_2=128, dense_units=224, dropout_rate=0.2, learning_rate=0.0006840281266478486, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 36s 120ms/step - loss: 1.9012 - accuracy: 0.3291 - val_loss: 0.7912 - val_accuracy: 0.7232\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 32s 119ms/step - loss: 0.7265 - accuracy: 0.7491 - val_loss: 0.6116 - val_accuracy: 0.7864\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 32s 119ms/step - loss: 0.5703 - accuracy: 0.8039 - val_loss: 0.5305 - val_accuracy: 0.8141\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 32s 120ms/step - loss: 0.4891 - accuracy: 0.8307 - val_loss: 0.4689 - val_accuracy: 0.8391\n",
      "Trying hyperparameters: gru_units_1=512, gru_units_2=352, dense_units=416, dropout_rate=0.30000000000000004, learning_rate=0.0010797058474730794, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 69s 249ms/step - loss: 1.6236 - accuracy: 0.4219 - val_loss: 0.5185 - val_accuracy: 0.8200\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 66s 247ms/step - loss: 0.4797 - accuracy: 0.8324 - val_loss: 0.4503 - val_accuracy: 0.8447\n",
      "Trying hyperparameters: gru_units_1=384, gru_units_2=160, dense_units=224, dropout_rate=0.5, learning_rate=0.0027378860654990946, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 39s 137ms/step - loss: 1.5574 - accuracy: 0.4487 - val_loss: 0.4793 - val_accuracy: 0.8380\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 36s 135ms/step - loss: 0.4554 - accuracy: 0.8469 - val_loss: 0.4213 - val_accuracy: 0.8592\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 36s 135ms/step - loss: 0.3268 - accuracy: 0.8917 - val_loss: 0.4108 - val_accuracy: 0.8643\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 36s 135ms/step - loss: 0.2331 - accuracy: 0.9246 - val_loss: 0.4166 - val_accuracy: 0.8696\n",
      "Trying hyperparameters: gru_units_1=192, gru_units_2=512, dense_units=448, dropout_rate=0.30000000000000004, learning_rate=0.0008157529981870569, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 52s 186ms/step - loss: 1.7002 - accuracy: 0.3917 - val_loss: 0.6078 - val_accuracy: 0.7885\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 50s 185ms/step - loss: 0.5718 - accuracy: 0.8020 - val_loss: 0.5291 - val_accuracy: 0.8169\n",
      "Trying hyperparameters: gru_units_1=448, gru_units_2=352, dense_units=320, dropout_rate=0.2, learning_rate=0.00039420523864005846, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 63s 226ms/step - loss: 1.8071 - accuracy: 0.3515 - val_loss: 0.6707 - val_accuracy: 0.7624\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 60s 225ms/step - loss: 0.6154 - accuracy: 0.7818 - val_loss: 0.5279 - val_accuracy: 0.8162\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 60s 225ms/step - loss: 0.4994 - accuracy: 0.8219 - val_loss: 0.4938 - val_accuracy: 0.8271\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 60s 225ms/step - loss: 0.4357 - accuracy: 0.8468 - val_loss: 0.4455 - val_accuracy: 0.8454\n",
      "Trying hyperparameters: gru_units_1=128, gru_units_2=416, dense_units=384, dropout_rate=0.5, learning_rate=0.00029673516237245826, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 39s 129ms/step - loss: 2.0026 - accuracy: 0.2752 - val_loss: 1.6776 - val_accuracy: 0.3748\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 34s 127ms/step - loss: 1.4424 - accuracy: 0.4717 - val_loss: 1.0062 - val_accuracy: 0.6415\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 34s 127ms/step - loss: 0.9674 - accuracy: 0.6632 - val_loss: 0.7874 - val_accuracy: 0.7191\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 34s 127ms/step - loss: 0.7809 - accuracy: 0.7246 - val_loss: 0.6981 - val_accuracy: 0.7542\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 34s 127ms/step - loss: 0.6879 - accuracy: 0.7625 - val_loss: 0.6410 - val_accuracy: 0.7773\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 34s 128ms/step - loss: 0.6372 - accuracy: 0.7837 - val_loss: 0.5948 - val_accuracy: 0.7962\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 34s 127ms/step - loss: 0.5702 - accuracy: 0.8051 - val_loss: 0.5678 - val_accuracy: 0.8032\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 34s 127ms/step - loss: 0.5317 - accuracy: 0.8216 - val_loss: 0.5339 - val_accuracy: 0.8166\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 34s 127ms/step - loss: 0.4962 - accuracy: 0.8313 - val_loss: 0.5126 - val_accuracy: 0.8243\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 34s 128ms/step - loss: 0.4666 - accuracy: 0.8413 - val_loss: 0.4857 - val_accuracy: 0.8349\n",
      "Trying hyperparameters: gru_units_1=288, gru_units_2=320, dense_units=512, dropout_rate=0.30000000000000004, learning_rate=0.0009915081627235906, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 43s 154ms/step - loss: 1.6847 - accuracy: 0.4021 - val_loss: 0.5808 - val_accuracy: 0.7991\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 41s 153ms/step - loss: 0.5379 - accuracy: 0.8102 - val_loss: 0.4598 - val_accuracy: 0.8401\n",
      "Trying hyperparameters: gru_units_1=352, gru_units_2=448, dense_units=160, dropout_rate=0.5, learning_rate=0.0015711630429851944, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 61s 220ms/step - loss: 1.5976 - accuracy: 0.4335 - val_loss: 0.5282 - val_accuracy: 0.8181\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 59s 219ms/step - loss: 0.4710 - accuracy: 0.8380 - val_loss: 0.4336 - val_accuracy: 0.8523\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 59s 220ms/step - loss: 0.3579 - accuracy: 0.8758 - val_loss: 0.3943 - val_accuracy: 0.8668\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 59s 220ms/step - loss: 0.2701 - accuracy: 0.9082 - val_loss: 0.4064 - val_accuracy: 0.8692\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 59s 220ms/step - loss: 0.1988 - accuracy: 0.9337 - val_loss: 0.4287 - val_accuracy: 0.8707\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 59s 221ms/step - loss: 0.1356 - accuracy: 0.9565 - val_loss: 0.4917 - val_accuracy: 0.8672\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 59s 220ms/step - loss: 0.1008 - accuracy: 0.9678 - val_loss: 0.5240 - val_accuracy: 0.8645\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 59s 220ms/step - loss: 0.0796 - accuracy: 0.9752 - val_loss: 0.5467 - val_accuracy: 0.8732\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 59s 220ms/step - loss: 0.0552 - accuracy: 0.9825 - val_loss: 0.5991 - val_accuracy: 0.8664\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 59s 221ms/step - loss: 0.0477 - accuracy: 0.9845 - val_loss: 0.6399 - val_accuracy: 0.8667\n",
      "Trying hyperparameters: gru_units_1=352, gru_units_2=448, dense_units=160, dropout_rate=0.5, learning_rate=0.00155265175434905, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 61s 221ms/step - loss: 1.6786 - accuracy: 0.4094 - val_loss: 0.5476 - val_accuracy: 0.8081\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 59s 220ms/step - loss: 0.5093 - accuracy: 0.8273 - val_loss: 0.4309 - val_accuracy: 0.8514\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 59s 220ms/step - loss: 0.3904 - accuracy: 0.8640 - val_loss: 0.3984 - val_accuracy: 0.8636\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 59s 220ms/step - loss: 0.3136 - accuracy: 0.8958 - val_loss: 0.4161 - val_accuracy: 0.8614\n",
      "Trying hyperparameters: gru_units_1=320, gru_units_2=480, dense_units=224, dropout_rate=0.5, learning_rate=0.002319408627236559, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 62s 226ms/step - loss: 1.5452 - accuracy: 0.4582 - val_loss: 0.5101 - val_accuracy: 0.8208\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 60s 224ms/step - loss: 0.4869 - accuracy: 0.8328 - val_loss: 0.4368 - val_accuracy: 0.8517\n",
      "Trying hyperparameters: gru_units_1=448, gru_units_2=416, dense_units=128, dropout_rate=0.5, learning_rate=0.0010077187693562143, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 72s 256ms/step - loss: 1.6894 - accuracy: 0.3971 - val_loss: 0.5376 - val_accuracy: 0.8129\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 68s 254ms/step - loss: 0.5114 - accuracy: 0.8246 - val_loss: 0.4319 - val_accuracy: 0.8538\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 69s 256ms/step - loss: 0.4028 - accuracy: 0.8617 - val_loss: 0.4012 - val_accuracy: 0.8621\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 69s 256ms/step - loss: 0.3142 - accuracy: 0.8942 - val_loss: 0.4071 - val_accuracy: 0.8649\n",
      "Trying hyperparameters: gru_units_1=384, gru_units_2=160, dense_units=288, dropout_rate=0.4, learning_rate=0.0034543173121269087, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 39s 137ms/step - loss: 1.5777 - accuracy: 0.4455 - val_loss: 0.4721 - val_accuracy: 0.8396\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 36s 135ms/step - loss: 0.4243 - accuracy: 0.8557 - val_loss: 0.4139 - val_accuracy: 0.8625\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 36s 135ms/step - loss: 0.2925 - accuracy: 0.9025 - val_loss: 0.4215 - val_accuracy: 0.8655\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 36s 135ms/step - loss: 0.2122 - accuracy: 0.9307 - val_loss: 0.4286 - val_accuracy: 0.8683\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 36s 135ms/step - loss: 0.1645 - accuracy: 0.9467 - val_loss: 0.4787 - val_accuracy: 0.8701\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 36s 135ms/step - loss: 0.1294 - accuracy: 0.9583 - val_loss: 0.4895 - val_accuracy: 0.8639\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 36s 135ms/step - loss: 0.1261 - accuracy: 0.9593 - val_loss: 0.5200 - val_accuracy: 0.8604\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 36s 135ms/step - loss: 0.1175 - accuracy: 0.9627 - val_loss: 0.5201 - val_accuracy: 0.8623\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 36s 135ms/step - loss: 0.1057 - accuracy: 0.9654 - val_loss: 0.5320 - val_accuracy: 0.8593\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 36s 135ms/step - loss: 0.1140 - accuracy: 0.9629 - val_loss: 0.5509 - val_accuracy: 0.8591\n",
      "Trying hyperparameters: gru_units_1=256, gru_units_2=480, dense_units=192, dropout_rate=0.5, learning_rate=0.0006227973680513944, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 57s 205ms/step - loss: 1.9155 - accuracy: 0.3153 - val_loss: 0.7630 - val_accuracy: 0.7264\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 54s 202ms/step - loss: 0.7598 - accuracy: 0.7255 - val_loss: 0.5962 - val_accuracy: 0.7877\n",
      "Trying hyperparameters: gru_units_1=384, gru_units_2=384, dense_units=352, dropout_rate=0.4, learning_rate=0.0011846966151975208, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 56s 203ms/step - loss: 1.6479 - accuracy: 0.4158 - val_loss: 0.5497 - val_accuracy: 0.8092\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 54s 201ms/step - loss: 0.5290 - accuracy: 0.8166 - val_loss: 0.4499 - val_accuracy: 0.8426\n",
      "Trying hyperparameters: gru_units_1=320, gru_units_2=288, dense_units=256, dropout_rate=0.2, learning_rate=0.0018553216332058398, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 43s 154ms/step - loss: 1.4722 - accuracy: 0.4749 - val_loss: 0.4895 - val_accuracy: 0.8316\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 41s 153ms/step - loss: 0.4371 - accuracy: 0.8475 - val_loss: 0.4036 - val_accuracy: 0.8627\n",
      "Trying hyperparameters: gru_units_1=480, gru_units_2=480, dense_units=64, dropout_rate=0.5, learning_rate=0.0008637920189051893, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 84s 298ms/step - loss: 1.7851 - accuracy: 0.3711 - val_loss: 0.5786 - val_accuracy: 0.8009\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 80s 299ms/step - loss: 0.5336 - accuracy: 0.8186 - val_loss: 0.4607 - val_accuracy: 0.8411\n",
      "Trying hyperparameters: gru_units_1=288, gru_units_2=288, dense_units=288, dropout_rate=0.4, learning_rate=0.0013590615589008069, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 42s 148ms/step - loss: 1.6254 - accuracy: 0.4225 - val_loss: 0.5250 - val_accuracy: 0.8169\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 39s 146ms/step - loss: 0.5024 - accuracy: 0.8251 - val_loss: 0.4449 - val_accuracy: 0.8468\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 39s 146ms/step - loss: 0.3825 - accuracy: 0.8679 - val_loss: 0.4273 - val_accuracy: 0.8580\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 39s 146ms/step - loss: 0.3056 - accuracy: 0.8946 - val_loss: 0.3961 - val_accuracy: 0.8679\n",
      "Trying hyperparameters: gru_units_1=416, gru_units_2=64, dense_units=320, dropout_rate=0.30000000000000004, learning_rate=0.0020748512005887678, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 36s 128ms/step - loss: 1.5474 - accuracy: 0.4544 - val_loss: 0.5877 - val_accuracy: 0.7882\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 34s 127ms/step - loss: 0.5763 - accuracy: 0.8012 - val_loss: 0.4674 - val_accuracy: 0.8402\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 34s 127ms/step - loss: 0.4203 - accuracy: 0.8585 - val_loss: 0.4259 - val_accuracy: 0.8555\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 34s 127ms/step - loss: 0.3376 - accuracy: 0.8876 - val_loss: 0.4056 - val_accuracy: 0.8641\n",
      "Trying hyperparameters: gru_units_1=416, gru_units_2=416, dense_units=128, dropout_rate=0.4, learning_rate=0.0022987209842964445, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 66s 239ms/step - loss: 1.5934 - accuracy: 0.4359 - val_loss: 0.4776 - val_accuracy: 0.8330\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 64s 238ms/step - loss: 0.4328 - accuracy: 0.8510 - val_loss: 0.4117 - val_accuracy: 0.8614\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 64s 239ms/step - loss: 0.3114 - accuracy: 0.8938 - val_loss: 0.4081 - val_accuracy: 0.8650\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 64s 240ms/step - loss: 0.2126 - accuracy: 0.9292 - val_loss: 0.4171 - val_accuracy: 0.8677\n",
      "Trying hyperparameters: gru_units_1=384, gru_units_2=448, dense_units=160, dropout_rate=0.4, learning_rate=0.003076253566115606, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 64s 232ms/step - loss: 1.3651 - accuracy: 0.5223 - val_loss: 0.5233 - val_accuracy: 0.8210\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 62s 231ms/step - loss: 0.4446 - accuracy: 0.8484 - val_loss: 0.4096 - val_accuracy: 0.8618\n",
      "Trying hyperparameters: gru_units_1=320, gru_units_2=512, dense_units=192, dropout_rate=0.5, learning_rate=0.0046316427214685195, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 67s 242ms/step - loss: 1.3475 - accuracy: 0.5386 - val_loss: 0.4845 - val_accuracy: 0.8339\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 62s 232ms/step - loss: 0.4354 - accuracy: 0.8531 - val_loss: 0.4518 - val_accuracy: 0.8523\n",
      "Trying hyperparameters: gru_units_1=416, gru_units_2=384, dense_units=96, dropout_rate=0.5, learning_rate=0.0017615609588244965, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 62s 223ms/step - loss: 1.4403 - accuracy: 0.4970 - val_loss: 0.5349 - val_accuracy: 0.8161\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 59s 222ms/step - loss: 0.5089 - accuracy: 0.8254 - val_loss: 0.4446 - val_accuracy: 0.8510\n",
      "Trying hyperparameters: gru_units_1=480, gru_units_2=448, dense_units=256, dropout_rate=0.4, learning_rate=0.0012810442578175337, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 79s 286ms/step - loss: 1.6131 - accuracy: 0.4306 - val_loss: 0.5254 - val_accuracy: 0.8177\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 76s 285ms/step - loss: 0.4911 - accuracy: 0.8307 - val_loss: 0.4361 - val_accuracy: 0.8490\n",
      "Trying hyperparameters: gru_units_1=352, gru_units_2=384, dense_units=128, dropout_rate=0.4, learning_rate=0.0004908829714242922, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 54s 193ms/step - loss: 1.9383 - accuracy: 0.3077 - val_loss: 0.7727 - val_accuracy: 0.7314\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 51s 191ms/step - loss: 0.6743 - accuracy: 0.7657 - val_loss: 0.5258 - val_accuracy: 0.8193\n",
      "Trying hyperparameters: gru_units_1=416, gru_units_2=512, dense_units=96, dropout_rate=0.5, learning_rate=0.0007725100066824546, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 77s 279ms/step - loss: 1.9141 - accuracy: 0.3387 - val_loss: 0.6250 - val_accuracy: 0.7789\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 74s 278ms/step - loss: 0.7244 - accuracy: 0.7526 - val_loss: 0.5515 - val_accuracy: 0.8086\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 75s 279ms/step - loss: 0.5381 - accuracy: 0.8168 - val_loss: 0.4831 - val_accuracy: 0.8302\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 75s 279ms/step - loss: 0.4365 - accuracy: 0.8478 - val_loss: 0.4426 - val_accuracy: 0.8491\n",
      "Trying hyperparameters: gru_units_1=448, gru_units_2=192, dense_units=192, dropout_rate=0.30000000000000004, learning_rate=0.002495056288243475, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 49s 175ms/step - loss: 1.6569 - accuracy: 0.4186 - val_loss: 0.4845 - val_accuracy: 0.8330\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 46s 174ms/step - loss: 0.4242 - accuracy: 0.8540 - val_loss: 0.4166 - val_accuracy: 0.8613\n",
      "Trying hyperparameters: gru_units_1=256, gru_units_2=480, dense_units=352, dropout_rate=0.5, learning_rate=0.0019172506803797722, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 57s 204ms/step - loss: 1.6258 - accuracy: 0.4261 - val_loss: 0.4965 - val_accuracy: 0.8252\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 54s 203ms/step - loss: 0.4685 - accuracy: 0.8362 - val_loss: 0.4337 - val_accuracy: 0.8554\n",
      "Trying hyperparameters: gru_units_1=352, gru_units_2=256, dense_units=256, dropout_rate=0.2, learning_rate=0.003509332455518685, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 42s 151ms/step - loss: 1.4219 - accuracy: 0.4995 - val_loss: 0.4504 - val_accuracy: 0.8453\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 40s 150ms/step - loss: 0.4042 - accuracy: 0.8631 - val_loss: 0.3976 - val_accuracy: 0.8653\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 40s 151ms/step - loss: 0.2674 - accuracy: 0.9102 - val_loss: 0.4168 - val_accuracy: 0.8632\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 40s 150ms/step - loss: 0.1819 - accuracy: 0.9407 - val_loss: 0.4388 - val_accuracy: 0.8655\n",
      "Trying hyperparameters: gru_units_1=320, gru_units_2=96, dense_units=288, dropout_rate=0.4, learning_rate=0.00010781752095564963, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 31s 108ms/step - loss: 2.3421 - accuracy: 0.1729 - val_loss: 1.5494 - val_accuracy: 0.4238\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 28s 106ms/step - loss: 1.4379 - accuracy: 0.4694 - val_loss: 1.0945 - val_accuracy: 0.6128\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 28s 106ms/step - loss: 1.0663 - accuracy: 0.6431 - val_loss: 0.8668 - val_accuracy: 0.7024\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 28s 106ms/step - loss: 0.8658 - accuracy: 0.7076 - val_loss: 0.7658 - val_accuracy: 0.7250\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 28s 106ms/step - loss: 0.7634 - accuracy: 0.7354 - val_loss: 0.6714 - val_accuracy: 0.7628\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 28s 106ms/step - loss: 0.6816 - accuracy: 0.7624 - val_loss: 0.6248 - val_accuracy: 0.7784\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 28s 106ms/step - loss: 0.6252 - accuracy: 0.7839 - val_loss: 0.6020 - val_accuracy: 0.7894\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 28s 106ms/step - loss: 0.5924 - accuracy: 0.7933 - val_loss: 0.5653 - val_accuracy: 0.8043\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 28s 106ms/step - loss: 0.5662 - accuracy: 0.8056 - val_loss: 0.5513 - val_accuracy: 0.8096\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 28s 106ms/step - loss: 0.5391 - accuracy: 0.8162 - val_loss: 0.5368 - val_accuracy: 0.8144\n",
      "Trying hyperparameters: gru_units_1=224, gru_units_2=192, dense_units=320, dropout_rate=0.4, learning_rate=0.00015173131732159554, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 29s 100ms/step - loss: 2.2905 - accuracy: 0.1885 - val_loss: 1.6518 - val_accuracy: 0.3844\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 26s 98ms/step - loss: 1.5027 - accuracy: 0.4531 - val_loss: 1.1249 - val_accuracy: 0.6099\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 26s 98ms/step - loss: 1.0911 - accuracy: 0.6244 - val_loss: 0.8704 - val_accuracy: 0.7046\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 26s 98ms/step - loss: 0.8415 - accuracy: 0.7192 - val_loss: 0.7282 - val_accuracy: 0.7502\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 26s 98ms/step - loss: 0.7160 - accuracy: 0.7613 - val_loss: 0.6679 - val_accuracy: 0.7777\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 26s 98ms/step - loss: 0.6510 - accuracy: 0.7820 - val_loss: 0.6340 - val_accuracy: 0.7876\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 26s 98ms/step - loss: 0.6341 - accuracy: 0.7875 - val_loss: 0.5965 - val_accuracy: 0.8004\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 26s 98ms/step - loss: 0.5721 - accuracy: 0.8075 - val_loss: 0.5569 - val_accuracy: 0.8121\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 26s 98ms/step - loss: 0.5457 - accuracy: 0.8147 - val_loss: 0.5445 - val_accuracy: 0.8180\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 26s 98ms/step - loss: 0.5181 - accuracy: 0.8273 - val_loss: 0.5285 - val_accuracy: 0.8234\n",
      "Trying hyperparameters: gru_units_1=288, gru_units_2=320, dense_units=416, dropout_rate=0.4, learning_rate=0.00022428150563534992, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 43s 154ms/step - loss: 2.1742 - accuracy: 0.2243 - val_loss: 1.5617 - val_accuracy: 0.4084\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 41s 152ms/step - loss: 1.5142 - accuracy: 0.4361 - val_loss: 1.3498 - val_accuracy: 0.5056\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 41s 153ms/step - loss: 1.4806 - accuracy: 0.4705 - val_loss: 1.1526 - val_accuracy: 0.6140\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 41s 153ms/step - loss: 1.1569 - accuracy: 0.5988 - val_loss: 1.1873 - val_accuracy: 0.5671\n",
      "Trying hyperparameters: gru_units_1=384, gru_units_2=256, dense_units=384, dropout_rate=0.4, learning_rate=0.00018783239059800763, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 45s 159ms/step - loss: 2.1327 - accuracy: 0.2346 - val_loss: 1.1852 - val_accuracy: 0.5651\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 42s 157ms/step - loss: 1.0710 - accuracy: 0.6264 - val_loss: 0.7316 - val_accuracy: 0.7501\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 42s 157ms/step - loss: 0.7038 - accuracy: 0.7648 - val_loss: 0.6141 - val_accuracy: 0.7873\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 42s 157ms/step - loss: 0.5887 - accuracy: 0.7996 - val_loss: 0.5501 - val_accuracy: 0.8091\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 42s 157ms/step - loss: 0.5300 - accuracy: 0.8205 - val_loss: 0.5134 - val_accuracy: 0.8209\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 42s 157ms/step - loss: 0.4888 - accuracy: 0.8320 - val_loss: 0.5112 - val_accuracy: 0.8250\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 42s 157ms/step - loss: 0.4548 - accuracy: 0.8428 - val_loss: 0.4602 - val_accuracy: 0.8419\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 42s 157ms/step - loss: 0.4200 - accuracy: 0.8548 - val_loss: 0.4490 - val_accuracy: 0.8474\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 42s 157ms/step - loss: 0.3982 - accuracy: 0.8635 - val_loss: 0.4437 - val_accuracy: 0.8512\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 42s 157ms/step - loss: 0.3757 - accuracy: 0.8719 - val_loss: 0.4251 - val_accuracy: 0.8562\n",
      "Trying hyperparameters: gru_units_1=256, gru_units_2=448, dense_units=480, dropout_rate=0.30000000000000004, learning_rate=0.0005183664834653772, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 53s 190ms/step - loss: 1.8597 - accuracy: 0.3383 - val_loss: 0.8092 - val_accuracy: 0.7157\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 50s 188ms/step - loss: 0.8804 - accuracy: 0.6990 - val_loss: 0.7105 - val_accuracy: 0.7477\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 50s 188ms/step - loss: 0.6851 - accuracy: 0.7593 - val_loss: 0.5819 - val_accuracy: 0.7966\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 51s 189ms/step - loss: 0.5685 - accuracy: 0.7989 - val_loss: 0.6444 - val_accuracy: 0.7836\n",
      "Trying hyperparameters: gru_units_1=320, gru_units_2=320, dense_units=256, dropout_rate=0.30000000000000004, learning_rate=0.00010307942419766313, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 45s 159ms/step - loss: 2.2754 - accuracy: 0.2036 - val_loss: 1.5420 - val_accuracy: 0.4415\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 42s 158ms/step - loss: 1.3366 - accuracy: 0.5114 - val_loss: 0.9072 - val_accuracy: 0.6932\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 42s 158ms/step - loss: 0.9075 - accuracy: 0.6922 - val_loss: 0.7625 - val_accuracy: 0.7401\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 42s 158ms/step - loss: 0.7302 - accuracy: 0.7516 - val_loss: 0.6800 - val_accuracy: 0.7695\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 42s 159ms/step - loss: 0.6490 - accuracy: 0.7793 - val_loss: 0.6070 - val_accuracy: 0.7931\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 42s 159ms/step - loss: 0.5958 - accuracy: 0.7976 - val_loss: 0.5704 - val_accuracy: 0.8057\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 43s 159ms/step - loss: 0.5608 - accuracy: 0.8098 - val_loss: 0.5529 - val_accuracy: 0.8146\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 42s 158ms/step - loss: 0.5236 - accuracy: 0.8224 - val_loss: 0.5111 - val_accuracy: 0.8233\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 42s 158ms/step - loss: 0.4985 - accuracy: 0.8301 - val_loss: 0.4929 - val_accuracy: 0.8291\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 42s 158ms/step - loss: 0.4635 - accuracy: 0.8415 - val_loss: 0.4859 - val_accuracy: 0.8354\n",
      "Trying hyperparameters: gru_units_1=352, gru_units_2=416, dense_units=224, dropout_rate=0.4, learning_rate=0.0003903619462337016, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 58s 206ms/step - loss: 1.9524 - accuracy: 0.3017 - val_loss: 0.7494 - val_accuracy: 0.7437\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 55s 205ms/step - loss: 0.6797 - accuracy: 0.7723 - val_loss: 0.5461 - val_accuracy: 0.8109\n",
      "Trying hyperparameters: gru_units_1=480, gru_units_2=96, dense_units=288, dropout_rate=0.5, learning_rate=0.0015638276263213143, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 46s 164ms/step - loss: 1.8670 - accuracy: 0.3356 - val_loss: 0.5424 - val_accuracy: 0.8086\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 43s 162ms/step - loss: 0.5361 - accuracy: 0.8181 - val_loss: 0.4285 - val_accuracy: 0.8530\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 43s 162ms/step - loss: 0.4091 - accuracy: 0.8633 - val_loss: 0.4017 - val_accuracy: 0.8637\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 43s 162ms/step - loss: 0.3215 - accuracy: 0.8935 - val_loss: 0.3908 - val_accuracy: 0.8722\n",
      "Trying hyperparameters: gru_units_1=64, gru_units_2=128, dense_units=416, dropout_rate=0.2, learning_rate=0.0011359120373722583, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 19s 62ms/step - loss: 1.9199 - accuracy: 0.3157 - val_loss: 0.8575 - val_accuracy: 0.7027\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 0.9163 - accuracy: 0.6896 - val_loss: 0.7933 - val_accuracy: 0.7358\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 0.7633 - accuracy: 0.7384 - val_loss: 0.6865 - val_accuracy: 0.7685\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 0.6555 - accuracy: 0.7790 - val_loss: 0.8466 - val_accuracy: 0.7246\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 0.7032 - accuracy: 0.7715 - val_loss: 0.5950 - val_accuracy: 0.7989\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 0.5745 - accuracy: 0.8093 - val_loss: 0.6738 - val_accuracy: 0.7735\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 0.6086 - accuracy: 0.7926 - val_loss: 0.5958 - val_accuracy: 0.7951\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 16s 59ms/step - loss: 0.5372 - accuracy: 0.8129 - val_loss: 0.4996 - val_accuracy: 0.8275\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 0.4578 - accuracy: 0.8445 - val_loss: 0.4738 - val_accuracy: 0.8377\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 0.4110 - accuracy: 0.8594 - val_loss: 0.4733 - val_accuracy: 0.8377\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = embedding_matrix_word2vec\n",
    "study_gru_word2vec = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler(), pruner=optuna.pruners.HyperbandPruner())\n",
    "study_gru_word2vec.optimize(lambda trial: objective_gru(trial, embedding_matrix), n_trials=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### with Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = embedding_matrix_doc2vec\n",
    "maxlen=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_lstm_doc2vec = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler(), pruner=optuna.pruners.HyperbandPruner())\n",
    "study_lstm_doc2vec.optimize(lambda trial: objective_lstm(trial, embedding_matrix), n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying hyperparameters: lstm_units_1=288, lstm_units_2=240, dense_units=320, dropout_rate=0.2, learning_rate=0.003852952188934468, batch_size=256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-13 01:18:36.012470: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-12-13 01:18:36.014648: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2023-12-13 01:18:36.064084: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:88:00.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2023-12-13 01:18:36.064979: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:89:00.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2023-12-13 01:18:36.065820: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 2 with properties: \n",
      "pciBusID: 0000:b1:00.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2023-12-13 01:18:36.066639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 3 with properties: \n",
      "pciBusID: 0000:b2:00.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2023-12-13 01:18:36.066660: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-12-13 01:18:36.069473: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-12-13 01:18:36.069544: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-12-13 01:18:36.071865: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-12-13 01:18:36.072185: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-12-13 01:18:36.074800: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-12-13 01:18:36.076572: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-12-13 01:18:36.082213: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-12-13 01:18:36.088697: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1, 2, 3\n",
      "2023-12-13 01:18:36.089341: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-13 01:18:36.096008: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-12-13 01:18:36.492074: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:88:00.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2023-12-13 01:18:36.492879: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:89:00.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2023-12-13 01:18:36.493637: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 2 with properties: \n",
      "pciBusID: 0000:b1:00.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2023-12-13 01:18:36.494420: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 3 with properties: \n",
      "pciBusID: 0000:b2:00.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2023-12-13 01:18:36.494452: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-12-13 01:18:36.494495: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-12-13 01:18:36.494506: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-12-13 01:18:36.494517: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-12-13 01:18:36.494527: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-12-13 01:18:36.494538: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-12-13 01:18:36.494548: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-12-13 01:18:36.494559: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-12-13 01:18:36.500394: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1, 2, 3\n",
      "2023-12-13 01:18:36.500425: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-12-13 01:18:38.271031: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-12-13 01:18:38.271068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 2 3 \n",
      "2023-12-13 01:18:38.271073: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N Y Y Y \n",
      "2023-12-13 01:18:38.271076: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   Y N Y Y \n",
      "2023-12-13 01:18:38.271079: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 2:   Y Y N Y \n",
      "2023-12-13 01:18:38.271081: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 3:   Y Y Y N \n",
      "2023-12-13 01:18:38.280655: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13711 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:88:00.0, compute capability: 7.5)\n",
      "2023-12-13 01:18:38.282819: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 13739 MB memory) -> physical GPU (device: 1, name: Tesla T4, pci bus id: 0000:89:00.0, compute capability: 7.5)\n",
      "2023-12-13 01:18:38.284820: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 13739 MB memory) -> physical GPU (device: 2, name: Tesla T4, pci bus id: 0000:b1:00.0, compute capability: 7.5)\n",
      "2023-12-13 01:18:38.286789: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 13739 MB memory) -> physical GPU (device: 3, name: Tesla T4, pci bus id: 0000:b2:00.0, compute capability: 7.5)\n",
      "2023-12-13 01:18:39.408029: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2023-12-13 01:18:39.431681: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2100000000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-13 01:18:44.198213: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-12-13 01:18:44.508741: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 102s 357ms/step - loss: 0.9626 - accuracy: 0.6803 - val_loss: 0.6065 - val_accuracy: 0.8045\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 97s 363ms/step - loss: 0.5712 - accuracy: 0.8171 - val_loss: 0.5144 - val_accuracy: 0.8311\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 99s 369ms/step - loss: 0.4249 - accuracy: 0.8616 - val_loss: 0.4368 - val_accuracy: 0.8575\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 99s 371ms/step - loss: 0.3345 - accuracy: 0.8905 - val_loss: 0.4455 - val_accuracy: 0.8577\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 100s 373ms/step - loss: 0.2665 - accuracy: 0.9133 - val_loss: 0.4426 - val_accuracy: 0.8668\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 100s 373ms/step - loss: 0.2012 - accuracy: 0.9344 - val_loss: 0.4447 - val_accuracy: 0.8715\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 100s 373ms/step - loss: 0.1529 - accuracy: 0.9503 - val_loss: 0.4979 - val_accuracy: 0.8701\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 100s 373ms/step - loss: 0.1131 - accuracy: 0.9636 - val_loss: 0.5538 - val_accuracy: 0.8701\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 100s 373ms/step - loss: 0.0784 - accuracy: 0.9739 - val_loss: 0.5887 - val_accuracy: 0.8653\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 100s 373ms/step - loss: 0.0742 - accuracy: 0.9754 - val_loss: 0.6850 - val_accuracy: 0.8677\n",
      "Trying hyperparameters: lstm_units_1=448, lstm_units_2=352, dense_units=64, dropout_rate=0.2, learning_rate=0.00740776637449818, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 187s 685ms/step - loss: 1.3375 - accuracy: 0.5761 - val_loss: 0.6868 - val_accuracy: 0.7587\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 183s 683ms/step - loss: 0.7029 - accuracy: 0.7719 - val_loss: 0.6961 - val_accuracy: 0.7719\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 183s 683ms/step - loss: 0.6236 - accuracy: 0.7977 - val_loss: 0.5729 - val_accuracy: 0.8119\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 183s 683ms/step - loss: 0.5017 - accuracy: 0.8421 - val_loss: 0.5228 - val_accuracy: 0.8280\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 183s 683ms/step - loss: 0.4374 - accuracy: 0.8605 - val_loss: 0.5309 - val_accuracy: 0.8303\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 183s 682ms/step - loss: 0.3992 - accuracy: 0.8724 - val_loss: 0.4886 - val_accuracy: 0.8468\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 183s 683ms/step - loss: 0.3460 - accuracy: 0.8903 - val_loss: 0.5076 - val_accuracy: 0.8446\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 183s 682ms/step - loss: 0.3043 - accuracy: 0.9035 - val_loss: 0.5551 - val_accuracy: 0.8280\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 183s 683ms/step - loss: 0.3858 - accuracy: 0.8748 - val_loss: 0.5166 - val_accuracy: 0.8372\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 183s 682ms/step - loss: 0.3157 - accuracy: 0.8977 - val_loss: 0.5895 - val_accuracy: 0.8299\n",
      "Trying hyperparameters: lstm_units_1=384, lstm_units_2=352, dense_units=448, dropout_rate=0.30000000000000004, learning_rate=0.001539503012742086, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 162s 586ms/step - loss: 0.9268 - accuracy: 0.6947 - val_loss: 0.5696 - val_accuracy: 0.8099\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 157s 586ms/step - loss: 0.5518 - accuracy: 0.8151 - val_loss: 0.4920 - val_accuracy: 0.8338\n",
      "Trying hyperparameters: lstm_units_1=192, lstm_units_2=128, dense_units=320, dropout_rate=0.5, learning_rate=0.0024310117950201277, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 55s 194ms/step - loss: 1.0864 - accuracy: 0.6455 - val_loss: 0.6065 - val_accuracy: 0.7951\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 49s 185ms/step - loss: 0.6101 - accuracy: 0.8096 - val_loss: 0.4957 - val_accuracy: 0.8363\n",
      "Trying hyperparameters: lstm_units_1=224, lstm_units_2=176, dense_units=480, dropout_rate=0.2, learning_rate=0.00041756575082820306, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 72s 254ms/step - loss: 1.1419 - accuracy: 0.6323 - val_loss: 0.5538 - val_accuracy: 0.8101\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 67s 252ms/step - loss: 0.5343 - accuracy: 0.8173 - val_loss: 0.5047 - val_accuracy: 0.8286\n",
      "Trying hyperparameters: lstm_units_1=64, lstm_units_2=64, dense_units=192, dropout_rate=0.2, learning_rate=0.002446962188724995, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 30s 97ms/step - loss: 1.1163 - accuracy: 0.6310 - val_loss: 0.6090 - val_accuracy: 0.8000\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 23s 85ms/step - loss: 0.5687 - accuracy: 0.8136 - val_loss: 0.5063 - val_accuracy: 0.8373\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 23s 86ms/step - loss: 0.4480 - accuracy: 0.8546 - val_loss: 0.4481 - val_accuracy: 0.8549\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 23s 85ms/step - loss: 0.3629 - accuracy: 0.8843 - val_loss: 0.4261 - val_accuracy: 0.8618\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 23s 86ms/step - loss: 0.2902 - accuracy: 0.9077 - val_loss: 0.4234 - val_accuracy: 0.8698\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 23s 85ms/step - loss: 0.2310 - accuracy: 0.9269 - val_loss: 0.4334 - val_accuracy: 0.8701\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 23s 85ms/step - loss: 0.1874 - accuracy: 0.9409 - val_loss: 0.4467 - val_accuracy: 0.8712\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 23s 85ms/step - loss: 0.1497 - accuracy: 0.9539 - val_loss: 0.4898 - val_accuracy: 0.8721\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 23s 85ms/step - loss: 0.1225 - accuracy: 0.9622 - val_loss: 0.5201 - val_accuracy: 0.8723\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 23s 85ms/step - loss: 0.1033 - accuracy: 0.9677 - val_loss: 0.5641 - val_accuracy: 0.8713\n",
      "Trying hyperparameters: lstm_units_1=192, lstm_units_2=128, dense_units=192, dropout_rate=0.4, learning_rate=0.0010236945241794396, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 54s 187ms/step - loss: 1.1403 - accuracy: 0.6249 - val_loss: 0.5990 - val_accuracy: 0.8016\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 49s 184ms/step - loss: 0.5898 - accuracy: 0.8092 - val_loss: 0.5121 - val_accuracy: 0.8310\n",
      "Trying hyperparameters: lstm_units_1=96, lstm_units_2=80, dense_units=96, dropout_rate=0.4, learning_rate=0.003903139994002645, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 34s 109ms/step - loss: 1.1367 - accuracy: 0.6264 - val_loss: 0.7546 - val_accuracy: 0.7539\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 28s 105ms/step - loss: 0.7164 - accuracy: 0.7808 - val_loss: 0.5945 - val_accuracy: 0.8032\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 28s 105ms/step - loss: 0.5788 - accuracy: 0.8191 - val_loss: 0.4921 - val_accuracy: 0.8405\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 28s 106ms/step - loss: 0.4687 - accuracy: 0.8574 - val_loss: 0.4724 - val_accuracy: 0.8479\n",
      "Trying hyperparameters: lstm_units_1=256, lstm_units_2=256, dense_units=288, dropout_rate=0.2, learning_rate=0.001175780505736236, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 96s 344ms/step - loss: 0.9443 - accuracy: 0.6877 - val_loss: 0.5863 - val_accuracy: 0.8008\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 92s 344ms/step - loss: 0.5375 - accuracy: 0.8173 - val_loss: 0.4835 - val_accuracy: 0.8368\n",
      "Trying hyperparameters: lstm_units_1=160, lstm_units_2=112, dense_units=224, dropout_rate=0.5, learning_rate=0.0006577965424344387, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 49s 162ms/step - loss: 1.3384 - accuracy: 0.5612 - val_loss: 0.6312 - val_accuracy: 0.7914\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 42s 158ms/step - loss: 0.6545 - accuracy: 0.7940 - val_loss: 0.5491 - val_accuracy: 0.8213\n",
      "Trying hyperparameters: lstm_units_1=96, lstm_units_2=48, dense_units=160, dropout_rate=0.30000000000000004, learning_rate=0.00011991615074908274, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 30s 99ms/step - loss: 2.1798 - accuracy: 0.2976 - val_loss: 0.8770 - val_accuracy: 0.7082\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 25s 95ms/step - loss: 0.9205 - accuracy: 0.6927 - val_loss: 0.7586 - val_accuracy: 0.7433\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 26s 96ms/step - loss: 0.8095 - accuracy: 0.7285 - val_loss: 0.7140 - val_accuracy: 0.7628\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 26s 96ms/step - loss: 0.7533 - accuracy: 0.7514 - val_loss: 0.6773 - val_accuracy: 0.7750\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 26s 95ms/step - loss: 0.7235 - accuracy: 0.7669 - val_loss: 0.6588 - val_accuracy: 0.7811\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 25s 95ms/step - loss: 0.6817 - accuracy: 0.7816 - val_loss: 0.6260 - val_accuracy: 0.7937\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 26s 96ms/step - loss: 0.6514 - accuracy: 0.7943 - val_loss: 0.6142 - val_accuracy: 0.7993\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 26s 96ms/step - loss: 0.6263 - accuracy: 0.7993 - val_loss: 0.6010 - val_accuracy: 0.8038\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 26s 95ms/step - loss: 0.5948 - accuracy: 0.8079 - val_loss: 0.5917 - val_accuracy: 0.8078\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 25s 95ms/step - loss: 0.5758 - accuracy: 0.8171 - val_loss: 0.5731 - val_accuracy: 0.8140\n",
      "Trying hyperparameters: lstm_units_1=352, lstm_units_2=272, dense_units=352, dropout_rate=0.30000000000000004, learning_rate=0.009008440056982472, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 136s 487ms/step - loss: 1.7563 - accuracy: 0.4300 - val_loss: 0.7410 - val_accuracy: 0.7552\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 130s 487ms/step - loss: 0.6927 - accuracy: 0.7755 - val_loss: 0.5999 - val_accuracy: 0.8099\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 131s 489ms/step - loss: 0.5454 - accuracy: 0.8361 - val_loss: 0.5724 - val_accuracy: 0.8263\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 131s 489ms/step - loss: 0.4603 - accuracy: 0.8645 - val_loss: 0.5291 - val_accuracy: 0.8431\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 131s 489ms/step - loss: 0.3551 - accuracy: 0.8946 - val_loss: 0.5571 - val_accuracy: 0.8449\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 131s 489ms/step - loss: 0.3002 - accuracy: 0.9131 - val_loss: 0.5947 - val_accuracy: 0.8447\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 131s 489ms/step - loss: 0.2744 - accuracy: 0.9210 - val_loss: 0.6467 - val_accuracy: 0.8398\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 131s 489ms/step - loss: 0.2428 - accuracy: 0.9316 - val_loss: 0.6234 - val_accuracy: 0.8463\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 131s 489ms/step - loss: 0.2095 - accuracy: 0.9417 - val_loss: 0.6471 - val_accuracy: 0.8454\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 131s 489ms/step - loss: 0.1923 - accuracy: 0.9463 - val_loss: 0.6773 - val_accuracy: 0.8497\n",
      "Trying hyperparameters: lstm_units_1=512, lstm_units_2=512, dense_units=416, dropout_rate=0.2, learning_rate=0.003303551373320775, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 279s 1s/step - loss: 1.0690 - accuracy: 0.6609 - val_loss: 0.7062 - val_accuracy: 0.7742\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 276s 1s/step - loss: 0.6675 - accuracy: 0.7849 - val_loss: 0.5606 - val_accuracy: 0.8210\n",
      "Trying hyperparameters: lstm_units_1=320, lstm_units_2=224, dense_units=256, dropout_rate=0.2, learning_rate=0.005418578483193642, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 104s 373ms/step - loss: 1.2809 - accuracy: 0.5911 - val_loss: 0.6854 - val_accuracy: 0.7788\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 99s 371ms/step - loss: 0.6091 - accuracy: 0.8012 - val_loss: 0.5095 - val_accuracy: 0.8351\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 99s 371ms/step - loss: 0.4225 - accuracy: 0.8633 - val_loss: 0.4711 - val_accuracy: 0.8537\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 100s 372ms/step - loss: 0.3201 - accuracy: 0.8968 - val_loss: 0.4626 - val_accuracy: 0.8586\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 100s 372ms/step - loss: 0.2395 - accuracy: 0.9249 - val_loss: 0.4846 - val_accuracy: 0.8640\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 100s 372ms/step - loss: 0.1678 - accuracy: 0.9453 - val_loss: 0.5230 - val_accuracy: 0.8611\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 100s 372ms/step - loss: 0.1335 - accuracy: 0.9582 - val_loss: 0.5662 - val_accuracy: 0.8638\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 100s 372ms/step - loss: 0.1024 - accuracy: 0.9683 - val_loss: 0.6248 - val_accuracy: 0.8632\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 100s 372ms/step - loss: 0.0879 - accuracy: 0.9735 - val_loss: 0.6486 - val_accuracy: 0.8624\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 100s 372ms/step - loss: 0.0811 - accuracy: 0.9744 - val_loss: 0.7168 - val_accuracy: 0.8621\n",
      "Trying hyperparameters: lstm_units_1=64, lstm_units_2=32, dense_units=384, dropout_rate=0.30000000000000004, learning_rate=0.002179285252303789, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 29s 89ms/step - loss: 1.2293 - accuracy: 0.5897 - val_loss: 0.6138 - val_accuracy: 0.7967\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 23s 84ms/step - loss: 0.6250 - accuracy: 0.7996 - val_loss: 0.5134 - val_accuracy: 0.8317\n",
      "Trying hyperparameters: lstm_units_1=288, lstm_units_2=208, dense_units=128, dropout_rate=0.2, learning_rate=0.0044408288387875, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 97s 348ms/step - loss: 1.0042 - accuracy: 0.6725 - val_loss: 0.6084 - val_accuracy: 0.7978\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 93s 347ms/step - loss: 0.5695 - accuracy: 0.8145 - val_loss: 0.5141 - val_accuracy: 0.8305\n",
      "Trying hyperparameters: lstm_units_1=416, lstm_units_2=336, dense_units=224, dropout_rate=0.4, learning_rate=0.009208168906159643, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 172s 623ms/step - loss: 1.9689 - accuracy: 0.3481 - val_loss: 1.0581 - val_accuracy: 0.6159\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 167s 623ms/step - loss: 1.1515 - accuracy: 0.6017 - val_loss: 0.9516 - val_accuracy: 0.6638\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 167s 625ms/step - loss: 0.9704 - accuracy: 0.6705 - val_loss: 0.9035 - val_accuracy: 0.6818\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 167s 624ms/step - loss: 0.8570 - accuracy: 0.7123 - val_loss: 0.8186 - val_accuracy: 0.7342\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 167s 625ms/step - loss: 0.7605 - accuracy: 0.7529 - val_loss: 0.7736 - val_accuracy: 0.7566\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 167s 624ms/step - loss: 0.7119 - accuracy: 0.7772 - val_loss: 0.7487 - val_accuracy: 0.7677\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 167s 624ms/step - loss: 0.6607 - accuracy: 0.7994 - val_loss: 0.7251 - val_accuracy: 0.7806\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 167s 625ms/step - loss: 0.6471 - accuracy: 0.8073 - val_loss: 0.7524 - val_accuracy: 0.7727\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 167s 625ms/step - loss: 0.6167 - accuracy: 0.8144 - val_loss: 0.7000 - val_accuracy: 0.7860\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 167s 624ms/step - loss: 0.5541 - accuracy: 0.8343 - val_loss: 0.6934 - val_accuracy: 0.7940\n",
      "Trying hyperparameters: lstm_units_1=128, lstm_units_2=64, dense_units=512, dropout_rate=0.30000000000000004, learning_rate=0.0026964980908031717, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 35s 118ms/step - loss: 1.0541 - accuracy: 0.6450 - val_loss: 0.5714 - val_accuracy: 0.8081\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 30s 114ms/step - loss: 0.5538 - accuracy: 0.8221 - val_loss: 0.5005 - val_accuracy: 0.8347\n",
      "Trying hyperparameters: lstm_units_1=512, lstm_units_2=448, dense_units=288, dropout_rate=0.2, learning_rate=0.00536054877500289, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 257s 939ms/step - loss: 1.2588 - accuracy: 0.6045 - val_loss: 0.6710 - val_accuracy: 0.7813\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 254s 946ms/step - loss: 0.6561 - accuracy: 0.7849 - val_loss: 0.5799 - val_accuracy: 0.8202\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 253s 945ms/step - loss: 0.5151 - accuracy: 0.8417 - val_loss: 0.5257 - val_accuracy: 0.8378\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 253s 945ms/step - loss: 0.4037 - accuracy: 0.8748 - val_loss: 0.4785 - val_accuracy: 0.8545\n",
      "Trying hyperparameters: lstm_units_1=256, lstm_units_2=160, dense_units=352, dropout_rate=0.30000000000000004, learning_rate=0.0017919305991812347, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 75s 266ms/step - loss: 0.9975 - accuracy: 0.6698 - val_loss: 0.5669 - val_accuracy: 0.8105\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 71s 263ms/step - loss: 0.5478 - accuracy: 0.8184 - val_loss: 0.4809 - val_accuracy: 0.8403\n",
      "Trying hyperparameters: lstm_units_1=448, lstm_units_2=288, dense_units=160, dropout_rate=0.2, learning_rate=0.0036747936497929, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 168s 609ms/step - loss: 1.1888 - accuracy: 0.6093 - val_loss: 1.0548 - val_accuracy: 0.6550\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 163s 607ms/step - loss: 1.1471 - accuracy: 0.6200 - val_loss: 1.1343 - val_accuracy: 0.6162\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 163s 608ms/step - loss: 1.0426 - accuracy: 0.6543 - val_loss: 0.8700 - val_accuracy: 0.7074\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 163s 609ms/step - loss: 0.8226 - accuracy: 0.7242 - val_loss: 0.7937 - val_accuracy: 0.7318\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 163s 608ms/step - loss: 0.7208 - accuracy: 0.7581 - val_loss: 0.7139 - val_accuracy: 0.7587\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 163s 608ms/step - loss: 0.6115 - accuracy: 0.7956 - val_loss: 0.6277 - val_accuracy: 0.7846\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 163s 607ms/step - loss: 0.5192 - accuracy: 0.8292 - val_loss: 0.6164 - val_accuracy: 0.8004\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 163s 608ms/step - loss: 0.4687 - accuracy: 0.8476 - val_loss: 0.5835 - val_accuracy: 0.8132\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 163s 607ms/step - loss: 0.4143 - accuracy: 0.8648 - val_loss: 0.5597 - val_accuracy: 0.8215\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 163s 608ms/step - loss: 0.3574 - accuracy: 0.8848 - val_loss: 0.5719 - val_accuracy: 0.8233\n",
      "Trying hyperparameters: lstm_units_1=320, lstm_units_2=224, dense_units=256, dropout_rate=0.2, learning_rate=0.005620575113699961, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 104s 375ms/step - loss: 1.1213 - accuracy: 0.6308 - val_loss: 0.6097 - val_accuracy: 0.7997\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 100s 373ms/step - loss: 0.5813 - accuracy: 0.8138 - val_loss: 0.5077 - val_accuracy: 0.8334\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 100s 373ms/step - loss: 0.4651 - accuracy: 0.8524 - val_loss: 0.4811 - val_accuracy: 0.8451\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 100s 373ms/step - loss: 0.4049 - accuracy: 0.8740 - val_loss: 0.4613 - val_accuracy: 0.8512\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 100s 373ms/step - loss: 0.3076 - accuracy: 0.9032 - val_loss: 0.4574 - val_accuracy: 0.8558\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 100s 374ms/step - loss: 0.2807 - accuracy: 0.9123 - val_loss: 0.5098 - val_accuracy: 0.8469\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 100s 374ms/step - loss: 0.2521 - accuracy: 0.9240 - val_loss: 0.5011 - val_accuracy: 0.8614\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 100s 374ms/step - loss: 0.1936 - accuracy: 0.9390 - val_loss: 0.5296 - val_accuracy: 0.8630\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 100s 373ms/step - loss: 0.1613 - accuracy: 0.9492 - val_loss: 0.5681 - val_accuracy: 0.8607\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 100s 373ms/step - loss: 0.1251 - accuracy: 0.9606 - val_loss: 0.6076 - val_accuracy: 0.8624\n",
      "Trying hyperparameters: lstm_units_1=320, lstm_units_2=224, dense_units=256, dropout_rate=0.2, learning_rate=0.005982546775387727, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 104s 374ms/step - loss: 1.0352 - accuracy: 0.6637 - val_loss: 0.7010 - val_accuracy: 0.7690\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 99s 371ms/step - loss: 0.7370 - accuracy: 0.7628 - val_loss: 0.6027 - val_accuracy: 0.8129\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 100s 373ms/step - loss: 0.5495 - accuracy: 0.8290 - val_loss: 0.5087 - val_accuracy: 0.8368\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 100s 373ms/step - loss: 0.4335 - accuracy: 0.8625 - val_loss: 0.5098 - val_accuracy: 0.8364\n",
      "Trying hyperparameters: lstm_units_1=352, lstm_units_2=240, dense_units=192, dropout_rate=0.2, learning_rate=0.002958172115150171, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 122s 435ms/step - loss: 0.9570 - accuracy: 0.6846 - val_loss: 0.5591 - val_accuracy: 0.8110\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 116s 432ms/step - loss: 0.5331 - accuracy: 0.8269 - val_loss: 0.4846 - val_accuracy: 0.8343\n",
      "Trying hyperparameters: lstm_units_1=288, lstm_units_2=208, dense_units=320, dropout_rate=0.30000000000000004, learning_rate=0.004408906893745381, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 97s 349ms/step - loss: 1.0078 - accuracy: 0.6710 - val_loss: 0.6851 - val_accuracy: 0.7718\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 92s 345ms/step - loss: 0.6000 - accuracy: 0.8101 - val_loss: 0.4958 - val_accuracy: 0.8405\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 93s 346ms/step - loss: 0.4394 - accuracy: 0.8603 - val_loss: 0.4512 - val_accuracy: 0.8569\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 93s 345ms/step - loss: 0.3458 - accuracy: 0.8914 - val_loss: 0.4448 - val_accuracy: 0.8646\n",
      "Trying hyperparameters: lstm_units_1=160, lstm_units_2=112, dense_units=256, dropout_rate=0.2, learning_rate=0.006928454991961121, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 49s 162ms/step - loss: 0.9871 - accuracy: 0.6795 - val_loss: 0.5786 - val_accuracy: 0.8157\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 42s 158ms/step - loss: 0.5383 - accuracy: 0.8275 - val_loss: 0.5054 - val_accuracy: 0.8365\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 42s 158ms/step - loss: 0.4210 - accuracy: 0.8651 - val_loss: 0.4626 - val_accuracy: 0.8492\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 42s 158ms/step - loss: 0.3326 - accuracy: 0.8941 - val_loss: 0.4572 - val_accuracy: 0.8600\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 42s 158ms/step - loss: 0.2657 - accuracy: 0.9165 - val_loss: 0.4463 - val_accuracy: 0.8659\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 42s 158ms/step - loss: 0.2088 - accuracy: 0.9352 - val_loss: 0.4922 - val_accuracy: 0.8635\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 42s 158ms/step - loss: 0.1727 - accuracy: 0.9462 - val_loss: 0.5242 - val_accuracy: 0.8666\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 42s 158ms/step - loss: 0.1407 - accuracy: 0.9552 - val_loss: 0.5692 - val_accuracy: 0.8621\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 42s 159ms/step - loss: 0.1186 - accuracy: 0.9622 - val_loss: 0.6229 - val_accuracy: 0.8569\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 42s 158ms/step - loss: 0.1253 - accuracy: 0.9611 - val_loss: 0.5968 - val_accuracy: 0.8602\n",
      "Trying hyperparameters: lstm_units_1=64, lstm_units_2=32, dense_units=192, dropout_rate=0.30000000000000004, learning_rate=0.0019422931127186605, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 27s 88ms/step - loss: 1.3227 - accuracy: 0.5667 - val_loss: 0.6710 - val_accuracy: 0.7776\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 23s 85ms/step - loss: 0.6669 - accuracy: 0.7871 - val_loss: 0.5302 - val_accuracy: 0.8242\n",
      "Trying hyperparameters: lstm_units_1=256, lstm_units_2=192, dense_units=320, dropout_rate=0.2, learning_rate=0.0030743230699688557, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 83s 291ms/step - loss: 0.9343 - accuracy: 0.6922 - val_loss: 0.5516 - val_accuracy: 0.8174\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 78s 291ms/step - loss: 0.5257 - accuracy: 0.8271 - val_loss: 0.4792 - val_accuracy: 0.8410\n",
      "Trying hyperparameters: lstm_units_1=384, lstm_units_2=288, dense_units=384, dropout_rate=0.4, learning_rate=0.004776891302131905, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 142s 518ms/step - loss: 1.0844 - accuracy: 0.6567 - val_loss: 0.5780 - val_accuracy: 0.8142\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 138s 516ms/step - loss: 0.5984 - accuracy: 0.8131 - val_loss: 0.6885 - val_accuracy: 0.7893\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 138s 515ms/step - loss: 0.7122 - accuracy: 0.7939 - val_loss: 0.5645 - val_accuracy: 0.8273\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 138s 516ms/step - loss: 0.4743 - accuracy: 0.8584 - val_loss: 0.5043 - val_accuracy: 0.8489\n",
      "Trying hyperparameters: lstm_units_1=448, lstm_units_2=320, dense_units=64, dropout_rate=0.2, learning_rate=0.005862485273244202, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 172s 631ms/step - loss: 1.8933 - accuracy: 0.3703 - val_loss: 0.7040 - val_accuracy: 0.7370\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 169s 631ms/step - loss: 0.6845 - accuracy: 0.7658 - val_loss: 0.5784 - val_accuracy: 0.8093\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 169s 631ms/step - loss: 0.4855 - accuracy: 0.8499 - val_loss: 0.5080 - val_accuracy: 0.8433\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 169s 632ms/step - loss: 0.3646 - accuracy: 0.8890 - val_loss: 0.4973 - val_accuracy: 0.8489\n",
      "Trying hyperparameters: lstm_units_1=224, lstm_units_2=176, dense_units=128, dropout_rate=0.2, learning_rate=0.0076673136505112, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 73s 254ms/step - loss: 1.0897 - accuracy: 0.6403 - val_loss: 0.6065 - val_accuracy: 0.8074\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 67s 251ms/step - loss: 0.5725 - accuracy: 0.8202 - val_loss: 0.5318 - val_accuracy: 0.8279\n",
      "Trying hyperparameters: lstm_units_1=352, lstm_units_2=272, dense_units=352, dropout_rate=0.30000000000000004, learning_rate=0.00928635459352477, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 134s 487ms/step - loss: 2.2206 - accuracy: 0.2600 - val_loss: 0.8177 - val_accuracy: 0.7104\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 130s 485ms/step - loss: 0.8501 - accuracy: 0.7183 - val_loss: 1.1223 - val_accuracy: 0.5985\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 130s 486ms/step - loss: 1.0564 - accuracy: 0.6386 - val_loss: 0.7747 - val_accuracy: 0.7490\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 131s 488ms/step - loss: 0.7309 - accuracy: 0.7708 - val_loss: 0.6618 - val_accuracy: 0.7934\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 130s 487ms/step - loss: 0.6174 - accuracy: 0.8130 - val_loss: 0.6266 - val_accuracy: 0.8044\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 130s 487ms/step - loss: 0.5221 - accuracy: 0.8454 - val_loss: 0.5901 - val_accuracy: 0.8183\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 130s 487ms/step - loss: 0.4482 - accuracy: 0.8664 - val_loss: 0.6533 - val_accuracy: 0.8079\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 131s 488ms/step - loss: 0.5049 - accuracy: 0.8477 - val_loss: 0.6273 - val_accuracy: 0.8207\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 131s 487ms/step - loss: 0.4305 - accuracy: 0.8748 - val_loss: 0.5983 - val_accuracy: 0.8258\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 131s 487ms/step - loss: 0.3845 - accuracy: 0.8891 - val_loss: 0.6191 - val_accuracy: 0.8323\n",
      "Trying hyperparameters: lstm_units_1=352, lstm_units_2=272, dense_units=416, dropout_rate=0.30000000000000004, learning_rate=0.009657346388538934, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 136s 488ms/step - loss: 1.7382 - accuracy: 0.4758 - val_loss: 0.7264 - val_accuracy: 0.7605\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 130s 486ms/step - loss: 0.6880 - accuracy: 0.7824 - val_loss: 0.5945 - val_accuracy: 0.8175\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 130s 487ms/step - loss: 0.5290 - accuracy: 0.8362 - val_loss: 0.5547 - val_accuracy: 0.8269\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 131s 487ms/step - loss: 0.4344 - accuracy: 0.8696 - val_loss: 0.5255 - val_accuracy: 0.8423\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 131s 488ms/step - loss: 0.3516 - accuracy: 0.8942 - val_loss: 0.5264 - val_accuracy: 0.8505\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 131s 489ms/step - loss: 0.3097 - accuracy: 0.9086 - val_loss: 0.5129 - val_accuracy: 0.8507\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 132s 491ms/step - loss: 0.2525 - accuracy: 0.9241 - val_loss: 0.5422 - val_accuracy: 0.8554\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 132s 491ms/step - loss: 0.2295 - accuracy: 0.9311 - val_loss: 0.5757 - val_accuracy: 0.8451\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 132s 492ms/step - loss: 0.2253 - accuracy: 0.9330 - val_loss: 0.6084 - val_accuracy: 0.8472\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 131s 491ms/step - loss: 0.2161 - accuracy: 0.9367 - val_loss: 0.6104 - val_accuracy: 0.8468\n",
      "Trying hyperparameters: lstm_units_1=384, lstm_units_2=320, dense_units=352, dropout_rate=0.2, learning_rate=0.007239918521321639, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 149s 543ms/step - loss: 1.2255 - accuracy: 0.6207 - val_loss: 0.6722 - val_accuracy: 0.7896\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 145s 540ms/step - loss: 0.6207 - accuracy: 0.8085 - val_loss: 0.5744 - val_accuracy: 0.8230\n",
      "Trying hyperparameters: lstm_units_1=320, lstm_units_2=256, dense_units=288, dropout_rate=0.30000000000000004, learning_rate=0.0024530599314336343, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 116s 412ms/step - loss: 0.9601 - accuracy: 0.6862 - val_loss: 0.6423 - val_accuracy: 0.7762\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 110s 411ms/step - loss: 0.5707 - accuracy: 0.8139 - val_loss: 0.5014 - val_accuracy: 0.8325\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 110s 411ms/step - loss: 0.4552 - accuracy: 0.8520 - val_loss: 0.4422 - val_accuracy: 0.8554\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 110s 412ms/step - loss: 0.3687 - accuracy: 0.8807 - val_loss: 0.4176 - val_accuracy: 0.8640\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 110s 412ms/step - loss: 0.3023 - accuracy: 0.9023 - val_loss: 0.4224 - val_accuracy: 0.8662\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 111s 413ms/step - loss: 0.2562 - accuracy: 0.9177 - val_loss: 0.4240 - val_accuracy: 0.8706\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 111s 413ms/step - loss: 0.1902 - accuracy: 0.9376 - val_loss: 0.4434 - val_accuracy: 0.8752\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 111s 413ms/step - loss: 0.1453 - accuracy: 0.9526 - val_loss: 0.5044 - val_accuracy: 0.8746\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 111s 413ms/step - loss: 0.1186 - accuracy: 0.9611 - val_loss: 0.5323 - val_accuracy: 0.8726\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 111s 413ms/step - loss: 0.0948 - accuracy: 0.9685 - val_loss: 0.5759 - val_accuracy: 0.8729\n",
      "Trying hyperparameters: lstm_units_1=416, lstm_units_2=368, dense_units=224, dropout_rate=0.5, learning_rate=0.003813915170192316, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 183s 670ms/step - loss: 1.1146 - accuracy: 0.6414 - val_loss: 0.6255 - val_accuracy: 0.7935\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 179s 668ms/step - loss: 0.6711 - accuracy: 0.7961 - val_loss: 0.5445 - val_accuracy: 0.8228\n",
      "Trying hyperparameters: lstm_units_1=480, lstm_units_2=400, dense_units=320, dropout_rate=0.4, learning_rate=0.001499440265602765, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 224s 822ms/step - loss: 0.9780 - accuracy: 0.6837 - val_loss: 0.5761 - val_accuracy: 0.8122\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 221s 826ms/step - loss: 0.5958 - accuracy: 0.8066 - val_loss: 0.4956 - val_accuracy: 0.8313\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 222s 829ms/step - loss: 0.4666 - accuracy: 0.8471 - val_loss: 0.4690 - val_accuracy: 0.8410\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 222s 828ms/step - loss: 0.3900 - accuracy: 0.8727 - val_loss: 0.4288 - val_accuracy: 0.8579\n",
      "Trying hyperparameters: lstm_units_1=288, lstm_units_2=240, dense_units=448, dropout_rate=0.2, learning_rate=0.006969571593524271, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 105s 379ms/step - loss: 1.1626 - accuracy: 0.6416 - val_loss: 0.6223 - val_accuracy: 0.7998\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 99s 370ms/step - loss: 0.5592 - accuracy: 0.8214 - val_loss: 0.4914 - val_accuracy: 0.8422\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 99s 371ms/step - loss: 0.4451 - accuracy: 0.8594 - val_loss: 0.4839 - val_accuracy: 0.8537\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 99s 371ms/step - loss: 0.3548 - accuracy: 0.8888 - val_loss: 0.4810 - val_accuracy: 0.8522\n",
      "Trying hyperparameters: lstm_units_1=192, lstm_units_2=128, dense_units=256, dropout_rate=0.30000000000000004, learning_rate=0.004635773397402093, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 54s 187ms/step - loss: 0.9829 - accuracy: 0.6766 - val_loss: 0.6359 - val_accuracy: 0.7946\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 49s 184ms/step - loss: 0.5763 - accuracy: 0.8203 - val_loss: 0.4717 - val_accuracy: 0.8473\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 50s 185ms/step - loss: 0.4140 - accuracy: 0.8689 - val_loss: 0.4409 - val_accuracy: 0.8561\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 49s 184ms/step - loss: 0.3456 - accuracy: 0.8912 - val_loss: 0.4437 - val_accuracy: 0.8652\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 50s 185ms/step - loss: 0.2560 - accuracy: 0.9197 - val_loss: 0.4377 - val_accuracy: 0.8649\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 49s 185ms/step - loss: 0.2018 - accuracy: 0.9364 - val_loss: 0.4715 - val_accuracy: 0.8716\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 49s 185ms/step - loss: 0.1521 - accuracy: 0.9525 - val_loss: 0.5184 - val_accuracy: 0.8684\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 49s 185ms/step - loss: 0.1253 - accuracy: 0.9608 - val_loss: 0.5621 - val_accuracy: 0.8692\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 49s 184ms/step - loss: 0.1101 - accuracy: 0.9668 - val_loss: 0.5614 - val_accuracy: 0.8720\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 49s 184ms/step - loss: 0.0881 - accuracy: 0.9718 - val_loss: 0.6521 - val_accuracy: 0.8700\n",
      "Trying hyperparameters: lstm_units_1=224, lstm_units_2=176, dense_units=384, dropout_rate=0.2, learning_rate=0.0033850359098935756, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 73s 253ms/step - loss: 0.9710 - accuracy: 0.6755 - val_loss: 0.5602 - val_accuracy: 0.8127\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 67s 251ms/step - loss: 0.5361 - accuracy: 0.8245 - val_loss: 0.4747 - val_accuracy: 0.8437\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 67s 251ms/step - loss: 0.4135 - accuracy: 0.8652 - val_loss: 0.4342 - val_accuracy: 0.8572\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 67s 251ms/step - loss: 0.3251 - accuracy: 0.8937 - val_loss: 0.4595 - val_accuracy: 0.8508\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 67s 252ms/step - loss: 0.2657 - accuracy: 0.9133 - val_loss: 0.4331 - val_accuracy: 0.8702\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 67s 251ms/step - loss: 0.1952 - accuracy: 0.9356 - val_loss: 0.4566 - val_accuracy: 0.8716\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 67s 251ms/step - loss: 0.1455 - accuracy: 0.9518 - val_loss: 0.4872 - val_accuracy: 0.8736\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 67s 251ms/step - loss: 0.1071 - accuracy: 0.9641 - val_loss: 0.5448 - val_accuracy: 0.8694\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 67s 251ms/step - loss: 0.0847 - accuracy: 0.9720 - val_loss: 0.5881 - val_accuracy: 0.8716\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 67s 251ms/step - loss: 0.0733 - accuracy: 0.9761 - val_loss: 0.6279 - val_accuracy: 0.8670\n",
      "Trying hyperparameters: lstm_units_1=416, lstm_units_2=272, dense_units=224, dropout_rate=0.4, learning_rate=0.002556552587081027, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 153s 559ms/step - loss: 1.0086 - accuracy: 0.6718 - val_loss: 0.5847 - val_accuracy: 0.8051\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 150s 558ms/step - loss: 0.5702 - accuracy: 0.8194 - val_loss: 0.5208 - val_accuracy: 0.8308\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 150s 558ms/step - loss: 0.4689 - accuracy: 0.8489 - val_loss: 0.4495 - val_accuracy: 0.8502\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 149s 558ms/step - loss: 0.3887 - accuracy: 0.8747 - val_loss: 0.4188 - val_accuracy: 0.8633\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 150s 558ms/step - loss: 0.3231 - accuracy: 0.8971 - val_loss: 0.3952 - val_accuracy: 0.8711\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 150s 558ms/step - loss: 0.2636 - accuracy: 0.9142 - val_loss: 0.4253 - val_accuracy: 0.8704\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 149s 558ms/step - loss: 0.2151 - accuracy: 0.9307 - val_loss: 0.4347 - val_accuracy: 0.8774\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 149s 558ms/step - loss: 0.1666 - accuracy: 0.9468 - val_loss: 0.4957 - val_accuracy: 0.8737\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 149s 558ms/step - loss: 0.1283 - accuracy: 0.9601 - val_loss: 0.5047 - val_accuracy: 0.8755\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 150s 558ms/step - loss: 0.1062 - accuracy: 0.9655 - val_loss: 0.5244 - val_accuracy: 0.8750\n",
      "Trying hyperparameters: lstm_units_1=352, lstm_units_2=272, dense_units=352, dropout_rate=0.30000000000000004, learning_rate=0.008791665277103419, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 136s 488ms/step - loss: 1.7588 - accuracy: 0.4234 - val_loss: 0.6904 - val_accuracy: 0.7681\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 130s 487ms/step - loss: 0.6675 - accuracy: 0.7851 - val_loss: 0.6364 - val_accuracy: 0.7917\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 131s 488ms/step - loss: 0.5984 - accuracy: 0.8182 - val_loss: 0.5394 - val_accuracy: 0.8323\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 131s 488ms/step - loss: 0.6659 - accuracy: 0.7919 - val_loss: 0.6123 - val_accuracy: 0.8103\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 130s 485ms/step - loss: 0.6702 - accuracy: 0.7932 - val_loss: 0.6662 - val_accuracy: 0.7925\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 130s 484ms/step - loss: 0.5601 - accuracy: 0.8270 - val_loss: 0.6248 - val_accuracy: 0.8104\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 130s 485ms/step - loss: 0.4790 - accuracy: 0.8521 - val_loss: 0.5913 - val_accuracy: 0.8167\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 130s 484ms/step - loss: 0.4355 - accuracy: 0.8684 - val_loss: 0.5827 - val_accuracy: 0.8371\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 130s 484ms/step - loss: 0.3238 - accuracy: 0.9076 - val_loss: 0.5597 - val_accuracy: 0.8494\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 130s 484ms/step - loss: 0.2781 - accuracy: 0.9188 - val_loss: 0.6414 - val_accuracy: 0.8475\n",
      "Trying hyperparameters: lstm_units_1=352, lstm_units_2=240, dense_units=320, dropout_rate=0.30000000000000004, learning_rate=0.008289168717491776, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 119s 433ms/step - loss: 1.3298 - accuracy: 0.5744 - val_loss: 0.7136 - val_accuracy: 0.7657\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 116s 432ms/step - loss: 0.7057 - accuracy: 0.7761 - val_loss: 0.5861 - val_accuracy: 0.8153\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 116s 432ms/step - loss: 0.5486 - accuracy: 0.8305 - val_loss: 0.5052 - val_accuracy: 0.8398\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 116s 433ms/step - loss: 0.4175 - accuracy: 0.8719 - val_loss: 0.4779 - val_accuracy: 0.8545\n",
      "Trying hyperparameters: lstm_units_1=320, lstm_units_2=256, dense_units=416, dropout_rate=0.30000000000000004, learning_rate=0.006049723046489187, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 116s 411ms/step - loss: 1.0962 - accuracy: 0.6465 - val_loss: 0.5883 - val_accuracy: 0.8041\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 110s 410ms/step - loss: 0.5630 - accuracy: 0.8216 - val_loss: 0.5369 - val_accuracy: 0.8313\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 110s 411ms/step - loss: 0.4504 - accuracy: 0.8590 - val_loss: 0.4822 - val_accuracy: 0.8517\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 110s 411ms/step - loss: 0.3628 - accuracy: 0.8896 - val_loss: 0.4622 - val_accuracy: 0.8581\n",
      "Trying hyperparameters: lstm_units_1=384, lstm_units_2=288, dense_units=288, dropout_rate=0.2, learning_rate=0.009796391262231566, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 142s 516ms/step - loss: 2.2189 - accuracy: 0.2632 - val_loss: 0.8325 - val_accuracy: 0.6921\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 138s 515ms/step - loss: 0.8266 - accuracy: 0.7091 - val_loss: 0.6543 - val_accuracy: 0.7872\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 138s 515ms/step - loss: 0.5563 - accuracy: 0.8225 - val_loss: 0.5650 - val_accuracy: 0.8304\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 138s 516ms/step - loss: 0.4332 - accuracy: 0.8662 - val_loss: 0.5710 - val_accuracy: 0.8317\n",
      "Trying hyperparameters: lstm_units_1=288, lstm_units_2=208, dense_units=352, dropout_rate=0.2, learning_rate=0.0075553527638393975, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 97s 348ms/step - loss: 1.1034 - accuracy: 0.6475 - val_loss: 0.6291 - val_accuracy: 0.7929\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 93s 346ms/step - loss: 0.5974 - accuracy: 0.8115 - val_loss: 0.5455 - val_accuracy: 0.8246\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 93s 347ms/step - loss: 0.4846 - accuracy: 0.8485 - val_loss: 0.5053 - val_accuracy: 0.8408\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 93s 347ms/step - loss: 0.4025 - accuracy: 0.8737 - val_loss: 0.4849 - val_accuracy: 0.8485\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 93s 347ms/step - loss: 0.3234 - accuracy: 0.8986 - val_loss: 0.4888 - val_accuracy: 0.8514\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 93s 347ms/step - loss: 0.2655 - accuracy: 0.9162 - val_loss: 0.5102 - val_accuracy: 0.8562\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 93s 346ms/step - loss: 0.2254 - accuracy: 0.9288 - val_loss: 0.5155 - val_accuracy: 0.8564\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 93s 347ms/step - loss: 0.1997 - accuracy: 0.9381 - val_loss: 0.5429 - val_accuracy: 0.8577\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 93s 347ms/step - loss: 0.1814 - accuracy: 0.9438 - val_loss: 0.5501 - val_accuracy: 0.8577\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 93s 347ms/step - loss: 0.1579 - accuracy: 0.9518 - val_loss: 0.5514 - val_accuracy: 0.8593\n",
      "Trying hyperparameters: lstm_units_1=128, lstm_units_2=96, dense_units=160, dropout_rate=0.30000000000000004, learning_rate=0.004317770856386368, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 40s 131ms/step - loss: 1.0301 - accuracy: 0.6606 - val_loss: 0.6064 - val_accuracy: 0.8020\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 34s 127ms/step - loss: 0.5913 - accuracy: 0.8123 - val_loss: 0.5009 - val_accuracy: 0.8337\n",
      "Trying hyperparameters: lstm_units_1=256, lstm_units_2=224, dense_units=448, dropout_rate=0.5, learning_rate=0.005234288035878868, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 86s 310ms/step - loss: 1.0885 - accuracy: 0.6485 - val_loss: 0.6019 - val_accuracy: 0.8110\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 82s 308ms/step - loss: 0.6035 - accuracy: 0.8146 - val_loss: 0.5082 - val_accuracy: 0.8422\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 83s 308ms/step - loss: 0.4921 - accuracy: 0.8500 - val_loss: 0.4518 - val_accuracy: 0.8568\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 83s 308ms/step - loss: 0.3821 - accuracy: 0.8850 - val_loss: 0.4740 - val_accuracy: 0.8585\n",
      "Trying hyperparameters: lstm_units_1=384, lstm_units_2=288, dense_units=384, dropout_rate=0.30000000000000004, learning_rate=0.0038678815502108744, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 144s 517ms/step - loss: 1.1921 - accuracy: 0.6218 - val_loss: 0.6266 - val_accuracy: 0.7987\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 138s 516ms/step - loss: 0.5559 - accuracy: 0.8241 - val_loss: 0.4854 - val_accuracy: 0.8415\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 138s 517ms/step - loss: 0.4346 - accuracy: 0.8631 - val_loss: 0.4565 - val_accuracy: 0.8536\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 138s 516ms/step - loss: 0.3314 - accuracy: 0.8961 - val_loss: 0.4158 - val_accuracy: 0.8677\n",
      "Trying hyperparameters: lstm_units_1=416, lstm_units_2=304, dense_units=288, dropout_rate=0.2, learning_rate=0.0064889431313285735, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 160s 585ms/step - loss: 2.0569 - accuracy: 0.3229 - val_loss: 0.8130 - val_accuracy: 0.7152\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 157s 585ms/step - loss: 0.8003 - accuracy: 0.7243 - val_loss: 0.6538 - val_accuracy: 0.7835\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 157s 585ms/step - loss: 0.5348 - accuracy: 0.8322 - val_loss: 0.5352 - val_accuracy: 0.8356\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 157s 586ms/step - loss: 0.3917 - accuracy: 0.8786 - val_loss: 0.5002 - val_accuracy: 0.8417\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 157s 587ms/step - loss: 0.3047 - accuracy: 0.9065 - val_loss: 0.5411 - val_accuracy: 0.8415\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 157s 588ms/step - loss: 0.2884 - accuracy: 0.9129 - val_loss: 0.5768 - val_accuracy: 0.8401\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 157s 586ms/step - loss: 0.2251 - accuracy: 0.9321 - val_loss: 0.6365 - val_accuracy: 0.8420\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 157s 586ms/step - loss: 0.1819 - accuracy: 0.9466 - val_loss: 0.6418 - val_accuracy: 0.8419\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 157s 586ms/step - loss: 0.1498 - accuracy: 0.9563 - val_loss: 0.6855 - val_accuracy: 0.8425\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 157s 586ms/step - loss: 0.1262 - accuracy: 0.9623 - val_loss: 0.7586 - val_accuracy: 0.8338\n"
     ]
    }
   ],
   "source": [
    "study_bilstm_doc2vec = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler(), pruner=optuna.pruners.HyperbandPruner())\n",
    "study_bilstm_doc2vec.optimize(lambda trial: objective_bilstm(trial, embedding_matrix), n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying hyperparameters: gru_units_1=448, gru_units_2=128, dense_units=320, dropout_rate=0.2, learning_rate=0.0003678798568175657, batch_size=256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "268/268 [==============================] - 45s 160ms/step - loss: 1.9606 - accuracy: 0.2933 - val_loss: 1.2728 - val_accuracy: 0.5978\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 43s 159ms/step - loss: 1.0705 - accuracy: 0.6370 - val_loss: 0.6938 - val_accuracy: 0.7569\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 43s 161ms/step - loss: 0.6733 - accuracy: 0.7669 - val_loss: 0.6907 - val_accuracy: 0.7630\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 43s 160ms/step - loss: 0.6248 - accuracy: 0.7858 - val_loss: 0.5469 - val_accuracy: 0.8099\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 43s 162ms/step - loss: 0.5121 - accuracy: 0.8232 - val_loss: 0.4830 - val_accuracy: 0.8316\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 43s 162ms/step - loss: 0.4670 - accuracy: 0.8380 - val_loss: 0.4748 - val_accuracy: 0.8356\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 44s 163ms/step - loss: 0.4285 - accuracy: 0.8512 - val_loss: 0.4400 - val_accuracy: 0.8491\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 44s 164ms/step - loss: 0.4112 - accuracy: 0.8587 - val_loss: 0.4218 - val_accuracy: 0.8549\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 44s 164ms/step - loss: 0.3714 - accuracy: 0.8723 - val_loss: 0.4386 - val_accuracy: 0.8491\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 44s 164ms/step - loss: 0.3556 - accuracy: 0.8770 - val_loss: 0.4288 - val_accuracy: 0.8539\n",
      "Trying hyperparameters: gru_units_1=448, gru_units_2=416, dense_units=384, dropout_rate=0.5, learning_rate=0.003422675642270576, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 73s 262ms/step - loss: 1.7539 - accuracy: 0.3953 - val_loss: 0.5331 - val_accuracy: 0.8188\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 70s 261ms/step - loss: 0.5342 - accuracy: 0.8258 - val_loss: 0.4296 - val_accuracy: 0.8584\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 70s 261ms/step - loss: 0.3953 - accuracy: 0.8748 - val_loss: 0.4318 - val_accuracy: 0.8611\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 70s 262ms/step - loss: 0.3082 - accuracy: 0.9033 - val_loss: 0.4951 - val_accuracy: 0.8563\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 70s 263ms/step - loss: 0.2371 - accuracy: 0.9274 - val_loss: 0.4927 - val_accuracy: 0.8644\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 70s 263ms/step - loss: 0.2015 - accuracy: 0.9399 - val_loss: 0.5881 - val_accuracy: 0.8647\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 70s 262ms/step - loss: 0.1783 - accuracy: 0.9474 - val_loss: 0.5682 - val_accuracy: 0.8625\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 70s 262ms/step - loss: 0.1779 - accuracy: 0.9476 - val_loss: 0.6231 - val_accuracy: 0.8594\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 70s 262ms/step - loss: 0.1996 - accuracy: 0.9422 - val_loss: 0.6102 - val_accuracy: 0.8480\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 70s 262ms/step - loss: 0.2326 - accuracy: 0.9319 - val_loss: 0.6035 - val_accuracy: 0.8442\n",
      "Trying hyperparameters: gru_units_1=352, gru_units_2=352, dense_units=384, dropout_rate=0.2, learning_rate=0.00010139106821940818, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 54s 193ms/step - loss: 2.2933 - accuracy: 0.1836 - val_loss: 1.5754 - val_accuracy: 0.3821\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 51s 191ms/step - loss: 1.5349 - accuracy: 0.3921 - val_loss: 1.3031 - val_accuracy: 0.4872\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 51s 191ms/step - loss: 1.2824 - accuracy: 0.4925 - val_loss: 0.9708 - val_accuracy: 0.6684\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 51s 191ms/step - loss: 0.9194 - accuracy: 0.6758 - val_loss: 0.7316 - val_accuracy: 0.7428\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 51s 191ms/step - loss: 0.7335 - accuracy: 0.7413 - val_loss: 0.6600 - val_accuracy: 0.7700\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 51s 191ms/step - loss: 0.6661 - accuracy: 0.7709 - val_loss: 0.6119 - val_accuracy: 0.7901\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 51s 191ms/step - loss: 0.6064 - accuracy: 0.7949 - val_loss: 0.5848 - val_accuracy: 0.8017\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 51s 192ms/step - loss: 0.5637 - accuracy: 0.8089 - val_loss: 0.5355 - val_accuracy: 0.8188\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 51s 191ms/step - loss: 0.5335 - accuracy: 0.8199 - val_loss: 0.5178 - val_accuracy: 0.8234\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 51s 191ms/step - loss: 0.5070 - accuracy: 0.8279 - val_loss: 0.5051 - val_accuracy: 0.8284\n",
      "Trying hyperparameters: gru_units_1=320, gru_units_2=288, dense_units=480, dropout_rate=0.30000000000000004, learning_rate=0.00018724159135974865, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 45s 158ms/step - loss: 2.1774 - accuracy: 0.2184 - val_loss: 1.2581 - val_accuracy: 0.5525\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 42s 157ms/step - loss: 1.2632 - accuracy: 0.5452 - val_loss: 0.8515 - val_accuracy: 0.7017\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 42s 157ms/step - loss: 0.8498 - accuracy: 0.6983 - val_loss: 0.6799 - val_accuracy: 0.7552\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 42s 157ms/step - loss: 0.6967 - accuracy: 0.7508 - val_loss: 0.6123 - val_accuracy: 0.7831\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 42s 156ms/step - loss: 0.6109 - accuracy: 0.7867 - val_loss: 0.5495 - val_accuracy: 0.8090\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 42s 156ms/step - loss: 0.5578 - accuracy: 0.8080 - val_loss: 0.5592 - val_accuracy: 0.8082\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 42s 157ms/step - loss: 0.5565 - accuracy: 0.8146 - val_loss: 0.5202 - val_accuracy: 0.8213\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 42s 156ms/step - loss: 0.4920 - accuracy: 0.8340 - val_loss: 0.4768 - val_accuracy: 0.8380\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 42s 156ms/step - loss: 0.4673 - accuracy: 0.8415 - val_loss: 0.4715 - val_accuracy: 0.8410\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 42s 156ms/step - loss: 0.4435 - accuracy: 0.8501 - val_loss: 0.4659 - val_accuracy: 0.8436\n",
      "Trying hyperparameters: gru_units_1=128, gru_units_2=256, dense_units=512, dropout_rate=0.4, learning_rate=0.007048743304791128, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 27s 92ms/step - loss: 1.5202 - accuracy: 0.4871 - val_loss: 0.5012 - val_accuracy: 0.8387\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 24s 90ms/step - loss: 0.4450 - accuracy: 0.8593 - val_loss: 0.4536 - val_accuracy: 0.8585\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 24s 90ms/step - loss: 0.3436 - accuracy: 0.8946 - val_loss: 0.4768 - val_accuracy: 0.8576\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 24s 90ms/step - loss: 0.3150 - accuracy: 0.9050 - val_loss: 0.5469 - val_accuracy: 0.8436\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 24s 90ms/step - loss: 0.3459 - accuracy: 0.8971 - val_loss: 0.6053 - val_accuracy: 0.8316\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 24s 90ms/step - loss: 0.7271 - accuracy: 0.7762 - val_loss: 1.9470 - val_accuracy: 0.3822\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 23s 87ms/step - loss: 2.3658 - accuracy: 0.1740 - val_loss: 2.4828 - val_accuracy: 0.0949\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 23s 87ms/step - loss: 2.4838 - accuracy: 0.0945 - val_loss: 2.4833 - val_accuracy: 0.0842\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 23s 87ms/step - loss: 2.4835 - accuracy: 0.0927 - val_loss: 2.4829 - val_accuracy: 0.0949\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 23s 87ms/step - loss: 2.4835 - accuracy: 0.0908 - val_loss: 2.4831 - val_accuracy: 0.0949\n",
      "Trying hyperparameters: gru_units_1=512, gru_units_2=320, dense_units=352, dropout_rate=0.5, learning_rate=0.0037293328894960286, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 66s 240ms/step - loss: 1.6729 - accuracy: 0.4176 - val_loss: 0.4993 - val_accuracy: 0.8313\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 64s 239ms/step - loss: 0.4926 - accuracy: 0.8428 - val_loss: 0.4256 - val_accuracy: 0.8586\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 64s 241ms/step - loss: 0.3650 - accuracy: 0.8851 - val_loss: 0.4622 - val_accuracy: 0.8596\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 64s 241ms/step - loss: 0.6573 - accuracy: 0.7989 - val_loss: 0.7962 - val_accuracy: 0.7576\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 64s 240ms/step - loss: 0.7476 - accuracy: 0.7642 - val_loss: 0.6943 - val_accuracy: 0.7951\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 64s 240ms/step - loss: 0.5941 - accuracy: 0.8193 - val_loss: 0.5984 - val_accuracy: 0.8247\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 64s 241ms/step - loss: 0.4879 - accuracy: 0.8548 - val_loss: 0.9166 - val_accuracy: 0.7249\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 64s 238ms/step - loss: 0.9803 - accuracy: 0.6934 - val_loss: 0.7888 - val_accuracy: 0.7618\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 64s 240ms/step - loss: 0.7843 - accuracy: 0.7603 - val_loss: 0.7465 - val_accuracy: 0.7837\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 64s 240ms/step - loss: 0.7334 - accuracy: 0.7808 - val_loss: 0.8677 - val_accuracy: 0.7418\n",
      "Trying hyperparameters: gru_units_1=160, gru_units_2=448, dense_units=96, dropout_rate=0.30000000000000004, learning_rate=0.0018542591242407128, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 45s 160ms/step - loss: 1.9249 - accuracy: 0.3247 - val_loss: 0.5411 - val_accuracy: 0.8155\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 42s 157ms/step - loss: 0.5288 - accuracy: 0.8259 - val_loss: 0.4384 - val_accuracy: 0.8516\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 42s 156ms/step - loss: 0.3893 - accuracy: 0.8726 - val_loss: 0.4109 - val_accuracy: 0.8628\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 42s 157ms/step - loss: 0.3060 - accuracy: 0.9009 - val_loss: 0.4134 - val_accuracy: 0.8689\n",
      "Trying hyperparameters: gru_units_1=320, gru_units_2=160, dense_units=128, dropout_rate=0.2, learning_rate=0.00036643823928809505, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 35s 125ms/step - loss: 2.0379 - accuracy: 0.2636 - val_loss: 1.0055 - val_accuracy: 0.6528\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 33s 123ms/step - loss: 1.0723 - accuracy: 0.6415 - val_loss: 0.8068 - val_accuracy: 0.7137\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 33s 123ms/step - loss: 0.7793 - accuracy: 0.7265 - val_loss: 0.6465 - val_accuracy: 0.7647\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 33s 123ms/step - loss: 0.6419 - accuracy: 0.7761 - val_loss: 0.5893 - val_accuracy: 0.7928\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 33s 123ms/step - loss: 0.5678 - accuracy: 0.8039 - val_loss: 0.5289 - val_accuracy: 0.8157\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 33s 123ms/step - loss: 0.5168 - accuracy: 0.8230 - val_loss: 0.4909 - val_accuracy: 0.8324\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 33s 123ms/step - loss: 0.4749 - accuracy: 0.8393 - val_loss: 0.4939 - val_accuracy: 0.8289\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 33s 123ms/step - loss: 0.4438 - accuracy: 0.8500 - val_loss: 0.4562 - val_accuracy: 0.8472\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 33s 123ms/step - loss: 0.4080 - accuracy: 0.8627 - val_loss: 0.4569 - val_accuracy: 0.8481\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 33s 123ms/step - loss: 0.3824 - accuracy: 0.8717 - val_loss: 0.4259 - val_accuracy: 0.8561\n",
      "Trying hyperparameters: gru_units_1=64, gru_units_2=160, dense_units=512, dropout_rate=0.5, learning_rate=0.0002166423901637993, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 20s 66ms/step - loss: 2.3808 - accuracy: 0.1455 - val_loss: 1.5930 - val_accuracy: 0.4244\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 17s 63ms/step - loss: 1.5428 - accuracy: 0.4221 - val_loss: 1.1621 - val_accuracy: 0.5822\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 17s 64ms/step - loss: 1.2032 - accuracy: 0.5535 - val_loss: 1.0485 - val_accuracy: 0.6431\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 17s 64ms/step - loss: 1.0494 - accuracy: 0.6347 - val_loss: 0.9172 - val_accuracy: 0.6831\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 17s 63ms/step - loss: 0.9293 - accuracy: 0.6727 - val_loss: 0.8388 - val_accuracy: 0.7061\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 17s 64ms/step - loss: 0.8448 - accuracy: 0.6974 - val_loss: 0.7757 - val_accuracy: 0.7308\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 17s 64ms/step - loss: 0.7875 - accuracy: 0.7287 - val_loss: 0.7413 - val_accuracy: 0.7492\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 17s 64ms/step - loss: 0.7479 - accuracy: 0.7442 - val_loss: 0.7370 - val_accuracy: 0.7514\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 17s 64ms/step - loss: 0.7028 - accuracy: 0.7642 - val_loss: 0.6775 - val_accuracy: 0.7769\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 17s 64ms/step - loss: 0.6646 - accuracy: 0.7808 - val_loss: 0.6533 - val_accuracy: 0.7868\n",
      "Trying hyperparameters: gru_units_1=160, gru_units_2=192, dense_units=480, dropout_rate=0.2, learning_rate=0.00036099162638921926, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 25s 85ms/step - loss: 2.0935 - accuracy: 0.2452 - val_loss: 1.0752 - val_accuracy: 0.6297\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 22s 83ms/step - loss: 0.9970 - accuracy: 0.6573 - val_loss: 0.7507 - val_accuracy: 0.7403\n",
      "Trying hyperparameters: gru_units_1=416, gru_units_2=96, dense_units=224, dropout_rate=0.30000000000000004, learning_rate=0.001098784782738011, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 39s 140ms/step - loss: 1.9826 - accuracy: 0.3027 - val_loss: 0.9025 - val_accuracy: 0.6682\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 37s 138ms/step - loss: 0.8401 - accuracy: 0.6995 - val_loss: 0.6172 - val_accuracy: 0.7841\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 37s 139ms/step - loss: 0.6172 - accuracy: 0.7873 - val_loss: 0.5151 - val_accuracy: 0.8204\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 37s 138ms/step - loss: 0.5108 - accuracy: 0.8268 - val_loss: 0.5948 - val_accuracy: 0.7955\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 37s 138ms/step - loss: 0.5216 - accuracy: 0.8219 - val_loss: 0.4604 - val_accuracy: 0.8412\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 37s 139ms/step - loss: 0.4297 - accuracy: 0.8541 - val_loss: 0.4395 - val_accuracy: 0.8534\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 37s 139ms/step - loss: 0.3807 - accuracy: 0.8741 - val_loss: 0.4184 - val_accuracy: 0.8600\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 37s 139ms/step - loss: 0.3405 - accuracy: 0.8879 - val_loss: 0.4549 - val_accuracy: 0.8513\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 37s 139ms/step - loss: 0.3254 - accuracy: 0.8912 - val_loss: 0.4045 - val_accuracy: 0.8702\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 37s 139ms/step - loss: 0.2778 - accuracy: 0.9089 - val_loss: 0.4089 - val_accuracy: 0.8706\n",
      "Trying hyperparameters: gru_units_1=512, gru_units_2=512, dense_units=288, dropout_rate=0.4, learning_rate=0.0009332842625661362, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 88s 322ms/step - loss: 1.8810 - accuracy: 0.3343 - val_loss: 0.5461 - val_accuracy: 0.8104\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 86s 322ms/step - loss: 0.5410 - accuracy: 0.8186 - val_loss: 0.4584 - val_accuracy: 0.8437\n",
      "Trying hyperparameters: gru_units_1=416, gru_units_2=416, dense_units=384, dropout_rate=0.4, learning_rate=0.007774828021867788, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 68s 244ms/step - loss: 1.4156 - accuracy: 0.5307 - val_loss: 0.5370 - val_accuracy: 0.8271\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 65s 243ms/step - loss: 0.5892 - accuracy: 0.8195 - val_loss: 1.1167 - val_accuracy: 0.6231\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 64s 239ms/step - loss: 1.3305 - accuracy: 0.5617 - val_loss: 0.9045 - val_accuracy: 0.7001\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 64s 237ms/step - loss: 1.1077 - accuracy: 0.6405 - val_loss: 0.9189 - val_accuracy: 0.7044\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 63s 237ms/step - loss: 1.0883 - accuracy: 0.6466 - val_loss: 0.9160 - val_accuracy: 0.7033\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 63s 236ms/step - loss: 1.0960 - accuracy: 0.6467 - val_loss: 0.9213 - val_accuracy: 0.7054\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 63s 236ms/step - loss: 1.0837 - accuracy: 0.6526 - val_loss: 0.8862 - val_accuracy: 0.7148\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 63s 235ms/step - loss: 1.0801 - accuracy: 0.6534 - val_loss: 0.9283 - val_accuracy: 0.6975\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 63s 235ms/step - loss: 1.1516 - accuracy: 0.6334 - val_loss: 1.0457 - val_accuracy: 0.6686\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 63s 235ms/step - loss: 1.2106 - accuracy: 0.6175 - val_loss: 0.9278 - val_accuracy: 0.7037\n",
      "Trying hyperparameters: gru_units_1=416, gru_units_2=96, dense_units=256, dropout_rate=0.5, learning_rate=0.002788972131702578, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 40s 141ms/step - loss: 1.9852 - accuracy: 0.2996 - val_loss: 0.7073 - val_accuracy: 0.7408\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 37s 139ms/step - loss: 0.7154 - accuracy: 0.7527 - val_loss: 0.5136 - val_accuracy: 0.8247\n",
      "Trying hyperparameters: gru_units_1=256, gru_units_2=384, dense_units=192, dropout_rate=0.4, learning_rate=0.0007872131965393121, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 47s 167ms/step - loss: 2.0154 - accuracy: 0.2812 - val_loss: 0.7334 - val_accuracy: 0.7341\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 44s 165ms/step - loss: 0.7103 - accuracy: 0.7489 - val_loss: 0.5330 - val_accuracy: 0.8164\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 44s 165ms/step - loss: 0.5255 - accuracy: 0.8236 - val_loss: 0.4697 - val_accuracy: 0.8394\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 44s 165ms/step - loss: 0.4419 - accuracy: 0.8545 - val_loss: 0.4484 - val_accuracy: 0.8459\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 44s 166ms/step - loss: 0.3807 - accuracy: 0.8742 - val_loss: 0.4302 - val_accuracy: 0.8577\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 44s 165ms/step - loss: 0.3371 - accuracy: 0.8888 - val_loss: 0.4085 - val_accuracy: 0.8685\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 44s 165ms/step - loss: 0.2882 - accuracy: 0.9060 - val_loss: 0.4107 - val_accuracy: 0.8669\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 44s 166ms/step - loss: 0.2451 - accuracy: 0.9210 - val_loss: 0.4496 - val_accuracy: 0.8635\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 44s 165ms/step - loss: 0.2105 - accuracy: 0.9313 - val_loss: 0.4241 - val_accuracy: 0.8740\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 44s 165ms/step - loss: 0.1762 - accuracy: 0.9446 - val_loss: 0.4522 - val_accuracy: 0.8713\n",
      "Trying hyperparameters: gru_units_1=480, gru_units_2=224, dense_units=352, dropout_rate=0.30000000000000004, learning_rate=0.004541513776582277, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 57s 205ms/step - loss: 2.2762 - accuracy: 0.2306 - val_loss: 1.0837 - val_accuracy: 0.6112\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 54s 203ms/step - loss: 1.0988 - accuracy: 0.6065 - val_loss: 0.8362 - val_accuracy: 0.7023\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 54s 203ms/step - loss: 0.8642 - accuracy: 0.6956 - val_loss: 0.7403 - val_accuracy: 0.7442\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 54s 203ms/step - loss: 0.7639 - accuracy: 0.7391 - val_loss: 0.7037 - val_accuracy: 0.7578\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 54s 203ms/step - loss: 0.6944 - accuracy: 0.7696 - val_loss: 0.6810 - val_accuracy: 0.7721\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 54s 203ms/step - loss: 0.6512 - accuracy: 0.7855 - val_loss: 0.6325 - val_accuracy: 0.7881\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 54s 203ms/step - loss: 0.6073 - accuracy: 0.8018 - val_loss: 0.6346 - val_accuracy: 0.7935\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 54s 203ms/step - loss: 0.5678 - accuracy: 0.8158 - val_loss: 0.6624 - val_accuracy: 0.7805\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 54s 202ms/step - loss: 0.5304 - accuracy: 0.8279 - val_loss: 0.6720 - val_accuracy: 0.7889\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 54s 202ms/step - loss: 0.5263 - accuracy: 0.8309 - val_loss: 0.6534 - val_accuracy: 0.7914\n",
      "Trying hyperparameters: gru_units_1=256, gru_units_2=512, dense_units=320, dropout_rate=0.2, learning_rate=0.001815004694311725, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 60s 216ms/step - loss: 1.6608 - accuracy: 0.4120 - val_loss: 0.4894 - val_accuracy: 0.8289\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 57s 214ms/step - loss: 0.4379 - accuracy: 0.8506 - val_loss: 0.4213 - val_accuracy: 0.8555\n",
      "Trying hyperparameters: gru_units_1=448, gru_units_2=448, dense_units=416, dropout_rate=0.5, learning_rate=0.009228375617420603, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 76s 273ms/step - loss: 1.7891 - accuracy: 0.4397 - val_loss: 0.7238 - val_accuracy: 0.7524\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 73s 271ms/step - loss: 0.8486 - accuracy: 0.7268 - val_loss: 0.7369 - val_accuracy: 0.7573\n",
      "Trying hyperparameters: gru_units_1=384, gru_units_2=64, dense_units=160, dropout_rate=0.4, learning_rate=0.0005573904363462236, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 34s 120ms/step - loss: 2.2116 - accuracy: 0.2114 - val_loss: 1.6089 - val_accuracy: 0.4142\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 32s 118ms/step - loss: 1.4629 - accuracy: 0.4579 - val_loss: 0.6943 - val_accuracy: 0.7442\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 32s 118ms/step - loss: 0.7327 - accuracy: 0.7359 - val_loss: 0.5571 - val_accuracy: 0.8063\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 32s 118ms/step - loss: 0.5933 - accuracy: 0.8024 - val_loss: 0.5015 - val_accuracy: 0.8297\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 32s 118ms/step - loss: 0.5180 - accuracy: 0.8306 - val_loss: 0.4686 - val_accuracy: 0.8430\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 32s 118ms/step - loss: 0.4562 - accuracy: 0.8529 - val_loss: 0.4356 - val_accuracy: 0.8580\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 32s 118ms/step - loss: 0.4080 - accuracy: 0.8690 - val_loss: 0.4456 - val_accuracy: 0.8562\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 32s 118ms/step - loss: 0.3771 - accuracy: 0.8809 - val_loss: 0.4192 - val_accuracy: 0.8659\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 32s 118ms/step - loss: 0.3334 - accuracy: 0.8957 - val_loss: 0.4480 - val_accuracy: 0.8617\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 32s 118ms/step - loss: 0.3215 - accuracy: 0.9009 - val_loss: 0.4262 - val_accuracy: 0.8700\n",
      "Trying hyperparameters: gru_units_1=448, gru_units_2=320, dense_units=416, dropout_rate=0.30000000000000004, learning_rate=0.00162977626555077, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 62s 223ms/step - loss: 1.7506 - accuracy: 0.3865 - val_loss: 0.4962 - val_accuracy: 0.8289\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 59s 220ms/step - loss: 0.4735 - accuracy: 0.8376 - val_loss: 0.4288 - val_accuracy: 0.8545\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 59s 221ms/step - loss: 0.3628 - accuracy: 0.8767 - val_loss: 0.4133 - val_accuracy: 0.8602\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 59s 221ms/step - loss: 0.2789 - accuracy: 0.9053 - val_loss: 0.3798 - val_accuracy: 0.8766\n",
      "Trying hyperparameters: gru_units_1=256, gru_units_2=256, dense_units=288, dropout_rate=0.5, learning_rate=0.004817143916501337, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 35s 123ms/step - loss: 1.9110 - accuracy: 0.3326 - val_loss: 0.6675 - val_accuracy: 0.7548\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 33s 122ms/step - loss: 0.6954 - accuracy: 0.7614 - val_loss: 0.5316 - val_accuracy: 0.8227\n",
      "Trying hyperparameters: gru_units_1=352, gru_units_2=352, dense_units=416, dropout_rate=0.2, learning_rate=0.00012245823094967763, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 53s 191ms/step - loss: 2.2484 - accuracy: 0.1997 - val_loss: 1.4433 - val_accuracy: 0.4701\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 51s 190ms/step - loss: 1.3301 - accuracy: 0.5195 - val_loss: 1.0455 - val_accuracy: 0.6515\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 51s 190ms/step - loss: 1.0317 - accuracy: 0.6476 - val_loss: 0.9787 - val_accuracy: 0.6630\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 51s 190ms/step - loss: 0.9922 - accuracy: 0.6626 - val_loss: 0.8885 - val_accuracy: 0.6915\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 51s 190ms/step - loss: 0.8941 - accuracy: 0.6900 - val_loss: 0.7645 - val_accuracy: 0.7372\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 51s 191ms/step - loss: 0.9530 - accuracy: 0.6749 - val_loss: 0.7528 - val_accuracy: 0.7435\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 51s 191ms/step - loss: 0.7699 - accuracy: 0.7311 - val_loss: 0.7107 - val_accuracy: 0.7558\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 51s 190ms/step - loss: 0.7518 - accuracy: 0.7373 - val_loss: 0.6688 - val_accuracy: 0.7664\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 51s 190ms/step - loss: 0.6862 - accuracy: 0.7604 - val_loss: 0.6248 - val_accuracy: 0.7827\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 51s 191ms/step - loss: 0.6348 - accuracy: 0.7772 - val_loss: 0.5879 - val_accuracy: 0.7949\n",
      "Trying hyperparameters: gru_units_1=352, gru_units_2=416, dense_units=352, dropout_rate=0.2, learning_rate=0.00012549970804098532, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 59s 211ms/step - loss: 2.2216 - accuracy: 0.2112 - val_loss: 1.1830 - val_accuracy: 0.5766\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 56s 210ms/step - loss: 1.1603 - accuracy: 0.5867 - val_loss: 0.8729 - val_accuracy: 0.7065\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 56s 210ms/step - loss: 0.8570 - accuracy: 0.7121 - val_loss: 0.7497 - val_accuracy: 0.7404\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 56s 210ms/step - loss: 0.7269 - accuracy: 0.7551 - val_loss: 0.7852 - val_accuracy: 0.7425\n",
      "Trying hyperparameters: gru_units_1=480, gru_units_2=352, dense_units=448, dropout_rate=0.2, learning_rate=0.00010339271587933356, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 68s 247ms/step - loss: 2.2353 - accuracy: 0.2056 - val_loss: 1.2234 - val_accuracy: 0.5539\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 66s 245ms/step - loss: 1.1254 - accuracy: 0.6006 - val_loss: 0.8362 - val_accuracy: 0.7115\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 66s 246ms/step - loss: 0.8224 - accuracy: 0.7226 - val_loss: 0.7144 - val_accuracy: 0.7548\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 66s 246ms/step - loss: 0.7106 - accuracy: 0.7592 - val_loss: 0.6624 - val_accuracy: 0.7748\n",
      "Trying hyperparameters: gru_units_1=384, gru_units_2=448, dense_units=320, dropout_rate=0.2, learning_rate=0.00020482638381448125, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 65s 237ms/step - loss: 2.0805 - accuracy: 0.2556 - val_loss: 1.1127 - val_accuracy: 0.6073\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 63s 235ms/step - loss: 1.0582 - accuracy: 0.6295 - val_loss: 0.6953 - val_accuracy: 0.7455\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 63s 236ms/step - loss: 0.6866 - accuracy: 0.7528 - val_loss: 0.5831 - val_accuracy: 0.7955\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 63s 236ms/step - loss: 0.5745 - accuracy: 0.8000 - val_loss: 0.5260 - val_accuracy: 0.8176\n",
      "Trying hyperparameters: gru_units_1=448, gru_units_2=384, dense_units=384, dropout_rate=0.30000000000000004, learning_rate=0.000411890443287977, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 68s 243ms/step - loss: 2.0124 - accuracy: 0.2789 - val_loss: 0.7506 - val_accuracy: 0.7315\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 65s 242ms/step - loss: 0.7216 - accuracy: 0.7475 - val_loss: 0.5639 - val_accuracy: 0.8073\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 65s 243ms/step - loss: 0.5433 - accuracy: 0.8161 - val_loss: 0.4875 - val_accuracy: 0.8329\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 65s 243ms/step - loss: 0.4639 - accuracy: 0.8420 - val_loss: 0.4452 - val_accuracy: 0.8474\n",
      "Trying hyperparameters: gru_units_1=320, gru_units_2=288, dense_units=256, dropout_rate=0.2, learning_rate=0.00028851893249007786, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 44s 158ms/step - loss: 2.1010 - accuracy: 0.2525 - val_loss: 0.8849 - val_accuracy: 0.6807\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 42s 156ms/step - loss: 0.8560 - accuracy: 0.7018 - val_loss: 0.7258 - val_accuracy: 0.7440\n",
      "Trying hyperparameters: gru_units_1=384, gru_units_2=352, dense_units=320, dropout_rate=0.30000000000000004, learning_rate=0.0005641120638808218, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 56s 201ms/step - loss: 1.9070 - accuracy: 0.3200 - val_loss: 0.6814 - val_accuracy: 0.7673\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 53s 198ms/step - loss: 0.6753 - accuracy: 0.7648 - val_loss: 0.5119 - val_accuracy: 0.8206\n",
      "Trying hyperparameters: gru_units_1=480, gru_units_2=480, dense_units=384, dropout_rate=0.2, learning_rate=0.00016612164747120212, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 83s 304ms/step - loss: 2.0923 - accuracy: 0.2554 - val_loss: 0.9524 - val_accuracy: 0.6664\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 81s 304ms/step - loss: 0.8574 - accuracy: 0.6952 - val_loss: 0.6744 - val_accuracy: 0.7590\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 81s 304ms/step - loss: 0.6526 - accuracy: 0.7662 - val_loss: 0.5984 - val_accuracy: 0.7912\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 82s 305ms/step - loss: 0.5882 - accuracy: 0.7956 - val_loss: 0.5257 - val_accuracy: 0.8195\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 82s 304ms/step - loss: 0.5206 - accuracy: 0.8210 - val_loss: 0.4929 - val_accuracy: 0.8307\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 82s 305ms/step - loss: 0.4825 - accuracy: 0.8353 - val_loss: 0.4794 - val_accuracy: 0.8362\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 82s 305ms/step - loss: 0.4477 - accuracy: 0.8491 - val_loss: 0.4604 - val_accuracy: 0.8413\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 82s 304ms/step - loss: 0.4233 - accuracy: 0.8543 - val_loss: 0.4534 - val_accuracy: 0.8453\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 82s 305ms/step - loss: 0.4067 - accuracy: 0.8598 - val_loss: 0.4323 - val_accuracy: 0.8516\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 82s 305ms/step - loss: 0.3756 - accuracy: 0.8705 - val_loss: 0.4292 - val_accuracy: 0.8531\n",
      "Trying hyperparameters: gru_units_1=288, gru_units_2=256, dense_units=480, dropout_rate=0.30000000000000004, learning_rate=0.0002712826212515278, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 39s 138ms/step - loss: 2.1137 - accuracy: 0.2420 - val_loss: 1.0578 - val_accuracy: 0.6366\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 36s 136ms/step - loss: 0.9720 - accuracy: 0.6715 - val_loss: 0.7505 - val_accuracy: 0.7416\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 36s 136ms/step - loss: 0.7480 - accuracy: 0.7411 - val_loss: 0.6444 - val_accuracy: 0.7780\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 36s 136ms/step - loss: 0.6380 - accuracy: 0.7809 - val_loss: 0.5497 - val_accuracy: 0.8109\n",
      "Trying hyperparameters: gru_units_1=352, gru_units_2=320, dense_units=448, dropout_rate=0.4, learning_rate=0.00016063089692592672, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 50s 177ms/step - loss: 2.2600 - accuracy: 0.1910 - val_loss: 1.4795 - val_accuracy: 0.4301\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 47s 175ms/step - loss: 1.3126 - accuracy: 0.5186 - val_loss: 1.0626 - val_accuracy: 0.6381\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 47s 176ms/step - loss: 0.9798 - accuracy: 0.6702 - val_loss: 0.8002 - val_accuracy: 0.7259\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 47s 176ms/step - loss: 0.8167 - accuracy: 0.7227 - val_loss: 0.7166 - val_accuracy: 0.7623\n",
      "Trying hyperparameters: gru_units_1=96, gru_units_2=160, dense_units=448, dropout_rate=0.5, learning_rate=0.00022049788711881138, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 21s 70ms/step - loss: 2.3799 - accuracy: 0.1407 - val_loss: 1.6039 - val_accuracy: 0.3716\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 18s 68ms/step - loss: 1.5344 - accuracy: 0.4018 - val_loss: 1.1362 - val_accuracy: 0.5699\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 18s 68ms/step - loss: 1.1635 - accuracy: 0.5543 - val_loss: 1.0134 - val_accuracy: 0.6419\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 18s 68ms/step - loss: 1.0129 - accuracy: 0.6343 - val_loss: 0.8790 - val_accuracy: 0.6882\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 18s 68ms/step - loss: 0.8739 - accuracy: 0.6910 - val_loss: 0.7771 - val_accuracy: 0.7307\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 18s 68ms/step - loss: 0.7773 - accuracy: 0.7276 - val_loss: 0.7134 - val_accuracy: 0.7466\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 18s 69ms/step - loss: 0.7169 - accuracy: 0.7463 - val_loss: 0.6842 - val_accuracy: 0.7590\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 18s 69ms/step - loss: 0.6701 - accuracy: 0.7627 - val_loss: 0.6477 - val_accuracy: 0.7747\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 18s 69ms/step - loss: 0.6465 - accuracy: 0.7750 - val_loss: 0.6289 - val_accuracy: 0.7863\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 18s 68ms/step - loss: 0.6142 - accuracy: 0.7876 - val_loss: 0.6178 - val_accuracy: 0.7944\n",
      "Trying hyperparameters: gru_units_1=192, gru_units_2=128, dense_units=512, dropout_rate=0.5, learning_rate=0.00010211046861168984, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 23s 80ms/step - loss: 2.4481 - accuracy: 0.1207 - val_loss: 2.2009 - val_accuracy: 0.2075\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 21s 78ms/step - loss: 2.0364 - accuracy: 0.2578 - val_loss: 1.3326 - val_accuracy: 0.4977\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 21s 78ms/step - loss: 1.3795 - accuracy: 0.4705 - val_loss: 1.1874 - val_accuracy: 0.5564\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 21s 78ms/step - loss: 1.2315 - accuracy: 0.5341 - val_loss: 1.0555 - val_accuracy: 0.6226\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 21s 78ms/step - loss: 1.0644 - accuracy: 0.6195 - val_loss: 0.9360 - val_accuracy: 0.6696\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 21s 78ms/step - loss: 0.9515 - accuracy: 0.6700 - val_loss: 0.8537 - val_accuracy: 0.7061\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 21s 78ms/step - loss: 0.8491 - accuracy: 0.7027 - val_loss: 0.7706 - val_accuracy: 0.7267\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 21s 78ms/step - loss: 0.7785 - accuracy: 0.7286 - val_loss: 0.7505 - val_accuracy: 0.7401\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 21s 78ms/step - loss: 0.7461 - accuracy: 0.7407 - val_loss: 0.7245 - val_accuracy: 0.7494\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 21s 78ms/step - loss: 0.7124 - accuracy: 0.7540 - val_loss: 0.6875 - val_accuracy: 0.7640\n",
      "Trying hyperparameters: gru_units_1=64, gru_units_2=192, dense_units=352, dropout_rate=0.5, learning_rate=0.00016007054502442558, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 22s 71ms/step - loss: 2.4237 - accuracy: 0.1337 - val_loss: 1.9777 - val_accuracy: 0.2662\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 18s 68ms/step - loss: 1.8315 - accuracy: 0.2984 - val_loss: 1.3269 - val_accuracy: 0.4520\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 18s 68ms/step - loss: 1.3531 - accuracy: 0.4549 - val_loss: 1.1665 - val_accuracy: 0.5369\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 18s 68ms/step - loss: 1.2030 - accuracy: 0.5176 - val_loss: 1.0800 - val_accuracy: 0.5728\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 18s 68ms/step - loss: 1.1064 - accuracy: 0.5646 - val_loss: 0.9868 - val_accuracy: 0.6360\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 18s 68ms/step - loss: 1.0119 - accuracy: 0.6292 - val_loss: 0.8866 - val_accuracy: 0.6875\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 18s 68ms/step - loss: 0.9016 - accuracy: 0.6816 - val_loss: 0.7956 - val_accuracy: 0.7218\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 18s 68ms/step - loss: 0.8197 - accuracy: 0.7094 - val_loss: 0.7600 - val_accuracy: 0.7351\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 18s 68ms/step - loss: 0.7582 - accuracy: 0.7335 - val_loss: 0.7107 - val_accuracy: 0.7576\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 18s 68ms/step - loss: 0.7241 - accuracy: 0.7514 - val_loss: 0.6847 - val_accuracy: 0.7656\n",
      "Trying hyperparameters: gru_units_1=224, gru_units_2=64, dense_units=512, dropout_rate=0.5, learning_rate=0.00024394726630167432, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 23s 79ms/step - loss: 2.3463 - accuracy: 0.1524 - val_loss: 1.5642 - val_accuracy: 0.4241\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 20s 76ms/step - loss: 1.5324 - accuracy: 0.4345 - val_loss: 1.1104 - val_accuracy: 0.6088\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 21s 77ms/step - loss: 1.1869 - accuracy: 0.5897 - val_loss: 0.9879 - val_accuracy: 0.6705\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 20s 76ms/step - loss: 1.0845 - accuracy: 0.6332 - val_loss: 0.9146 - val_accuracy: 0.6954\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 21s 77ms/step - loss: 0.9694 - accuracy: 0.6774 - val_loss: 0.8822 - val_accuracy: 0.6949\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 20s 76ms/step - loss: 0.9428 - accuracy: 0.6815 - val_loss: 0.8235 - val_accuracy: 0.7202\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 20s 76ms/step - loss: 0.9273 - accuracy: 0.6924 - val_loss: 0.8458 - val_accuracy: 0.7147\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 21s 80ms/step - loss: 0.8418 - accuracy: 0.7161 - val_loss: 0.7711 - val_accuracy: 0.7398\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 21s 78ms/step - loss: 0.8002 - accuracy: 0.7308 - val_loss: 0.6939 - val_accuracy: 0.7667\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 20s 76ms/step - loss: 0.7165 - accuracy: 0.7575 - val_loss: 0.6753 - val_accuracy: 0.7766\n",
      "Trying hyperparameters: gru_units_1=512, gru_units_2=128, dense_units=288, dropout_rate=0.4, learning_rate=0.00018988956108988823, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 52s 184ms/step - loss: 2.2125 - accuracy: 0.2021 - val_loss: 1.3301 - val_accuracy: 0.4622\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 49s 182ms/step - loss: 1.3410 - accuracy: 0.4900 - val_loss: 1.1130 - val_accuracy: 0.6124\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 49s 182ms/step - loss: 1.0583 - accuracy: 0.6426 - val_loss: 0.8018 - val_accuracy: 0.7244\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 49s 185ms/step - loss: 0.8639 - accuracy: 0.7069 - val_loss: 1.0625 - val_accuracy: 0.6405\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 49s 182ms/step - loss: 1.0372 - accuracy: 0.6485 - val_loss: 0.8904 - val_accuracy: 0.6925\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 49s 184ms/step - loss: 0.8846 - accuracy: 0.7006 - val_loss: 0.7140 - val_accuracy: 0.7491\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 50s 185ms/step - loss: 0.7207 - accuracy: 0.7527 - val_loss: 0.5971 - val_accuracy: 0.7918\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 49s 184ms/step - loss: 0.6115 - accuracy: 0.7919 - val_loss: 0.5468 - val_accuracy: 0.8108\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 49s 185ms/step - loss: 0.5724 - accuracy: 0.8055 - val_loss: 0.5503 - val_accuracy: 0.8097\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 50s 185ms/step - loss: 0.5418 - accuracy: 0.8167 - val_loss: 0.5185 - val_accuracy: 0.8227\n",
      "Trying hyperparameters: gru_units_1=288, gru_units_2=224, dense_units=480, dropout_rate=0.5, learning_rate=0.00014618017402730774, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 38s 134ms/step - loss: 2.3699 - accuracy: 0.1523 - val_loss: 1.5200 - val_accuracy: 0.3971\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 36s 133ms/step - loss: 1.5310 - accuracy: 0.4227 - val_loss: 1.1672 - val_accuracy: 0.5890\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 36s 133ms/step - loss: 1.1771 - accuracy: 0.5864 - val_loss: 0.9777 - val_accuracy: 0.6735\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 36s 133ms/step - loss: 0.9595 - accuracy: 0.6773 - val_loss: 0.8875 - val_accuracy: 0.7104\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 36s 133ms/step - loss: 0.8525 - accuracy: 0.7113 - val_loss: 0.7884 - val_accuracy: 0.7307\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 36s 133ms/step - loss: 0.7802 - accuracy: 0.7298 - val_loss: 0.7343 - val_accuracy: 0.7496\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 36s 133ms/step - loss: 0.7233 - accuracy: 0.7446 - val_loss: 0.6901 - val_accuracy: 0.7510\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 36s 133ms/step - loss: 0.6830 - accuracy: 0.7574 - val_loss: 0.6658 - val_accuracy: 0.7634\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 36s 133ms/step - loss: 0.6552 - accuracy: 0.7628 - val_loss: 0.6286 - val_accuracy: 0.7680\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 36s 133ms/step - loss: 0.6185 - accuracy: 0.7765 - val_loss: 0.6193 - val_accuracy: 0.7836\n",
      "Trying hyperparameters: gru_units_1=128, gru_units_2=160, dense_units=64, dropout_rate=0.4, learning_rate=0.000294001114935416, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 22s 74ms/step - loss: 2.3538 - accuracy: 0.1567 - val_loss: 1.4868 - val_accuracy: 0.4258\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 19s 71ms/step - loss: 1.5928 - accuracy: 0.4031 - val_loss: 1.2737 - val_accuracy: 0.5435\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 19s 71ms/step - loss: 1.3283 - accuracy: 0.5105 - val_loss: 1.0046 - val_accuracy: 0.6396\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 19s 71ms/step - loss: 1.0580 - accuracy: 0.6278 - val_loss: 0.7897 - val_accuracy: 0.7148\n",
      "Trying hyperparameters: gru_units_1=320, gru_units_2=288, dense_units=384, dropout_rate=0.2, learning_rate=0.00021300634109985473, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 45s 158ms/step - loss: 2.1643 - accuracy: 0.2238 - val_loss: 1.1945 - val_accuracy: 0.5651\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 42s 156ms/step - loss: 1.1031 - accuracy: 0.6054 - val_loss: 0.7798 - val_accuracy: 0.7319\n",
      "Trying hyperparameters: gru_units_1=416, gru_units_2=384, dense_units=224, dropout_rate=0.30000000000000004, learning_rate=0.00012892097683179428, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 63s 226ms/step - loss: 2.2609 - accuracy: 0.1968 - val_loss: 1.3323 - val_accuracy: 0.4800\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 60s 224ms/step - loss: 1.2924 - accuracy: 0.5152 - val_loss: 0.9741 - val_accuracy: 0.6677\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 60s 225ms/step - loss: 0.8918 - accuracy: 0.6908 - val_loss: 0.7004 - val_accuracy: 0.7580\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 60s 225ms/step - loss: 0.7037 - accuracy: 0.7599 - val_loss: 0.6252 - val_accuracy: 0.7888\n",
      "Trying hyperparameters: gru_units_1=160, gru_units_2=96, dense_units=256, dropout_rate=0.5, learning_rate=0.0003335729839302301, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 22s 73ms/step - loss: 2.3520 - accuracy: 0.1487 - val_loss: 1.3410 - val_accuracy: 0.4921\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 19s 71ms/step - loss: 1.3973 - accuracy: 0.4720 - val_loss: 1.0432 - val_accuracy: 0.6189\n",
      "Trying hyperparameters: gru_units_1=192, gru_units_2=128, dense_units=512, dropout_rate=0.5, learning_rate=0.00012395392280150017, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 23s 80ms/step - loss: 2.4327 - accuracy: 0.1310 - val_loss: 2.1452 - val_accuracy: 0.2267\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 21s 78ms/step - loss: 1.8254 - accuracy: 0.3352 - val_loss: 1.2998 - val_accuracy: 0.5120\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 21s 78ms/step - loss: 1.3616 - accuracy: 0.4929 - val_loss: 1.1885 - val_accuracy: 0.5591\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 21s 78ms/step - loss: 1.2391 - accuracy: 0.5433 - val_loss: 1.3108 - val_accuracy: 0.5384\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 21s 78ms/step - loss: 1.1639 - accuracy: 0.5844 - val_loss: 0.9906 - val_accuracy: 0.6414\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 20s 76ms/step - loss: 0.9964 - accuracy: 0.6395 - val_loss: 0.9305 - val_accuracy: 0.6764\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 20s 74ms/step - loss: 0.9274 - accuracy: 0.6778 - val_loss: 0.8458 - val_accuracy: 0.7185\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 20s 74ms/step - loss: 0.8515 - accuracy: 0.7216 - val_loss: 0.8077 - val_accuracy: 0.7349\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 20s 75ms/step - loss: 0.8075 - accuracy: 0.7336 - val_loss: 0.7743 - val_accuracy: 0.7473\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 21s 79ms/step - loss: 0.7671 - accuracy: 0.7512 - val_loss: 0.7285 - val_accuracy: 0.7599\n",
      "Trying hyperparameters: gru_units_1=64, gru_units_2=128, dense_units=512, dropout_rate=0.5, learning_rate=0.0001508678545286896, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 17s 55ms/step - loss: 2.4464 - accuracy: 0.1215 - val_loss: 2.0397 - val_accuracy: 0.2437\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 14s 53ms/step - loss: 1.9684 - accuracy: 0.2417 - val_loss: 1.4995 - val_accuracy: 0.4345\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 14s 52ms/step - loss: 1.4795 - accuracy: 0.4245 - val_loss: 1.2159 - val_accuracy: 0.5293\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 14s 53ms/step - loss: 1.2299 - accuracy: 0.5097 - val_loss: 1.1062 - val_accuracy: 0.5859\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 14s 53ms/step - loss: 1.1260 - accuracy: 0.5723 - val_loss: 0.9808 - val_accuracy: 0.6459\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 14s 53ms/step - loss: 1.0090 - accuracy: 0.6376 - val_loss: 0.9089 - val_accuracy: 0.6745\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 14s 53ms/step - loss: 0.9213 - accuracy: 0.6697 - val_loss: 0.8516 - val_accuracy: 0.7035\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 14s 53ms/step - loss: 0.8676 - accuracy: 0.6953 - val_loss: 0.8108 - val_accuracy: 0.7128\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 14s 53ms/step - loss: 0.8146 - accuracy: 0.7097 - val_loss: 0.7642 - val_accuracy: 0.7235\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 16s 59ms/step - loss: 0.7867 - accuracy: 0.7181 - val_loss: 0.7570 - val_accuracy: 0.7346\n",
      "Trying hyperparameters: gru_units_1=128, gru_units_2=192, dense_units=448, dropout_rate=0.5, learning_rate=0.00019249383325211576, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 24s 78ms/step - loss: 2.3705 - accuracy: 0.1463 - val_loss: 1.6621 - val_accuracy: 0.3378\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 20s 76ms/step - loss: 1.6157 - accuracy: 0.3835 - val_loss: 1.2545 - val_accuracy: 0.5275\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 20s 76ms/step - loss: 1.3004 - accuracy: 0.5118 - val_loss: 1.0706 - val_accuracy: 0.6376\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 20s 76ms/step - loss: 1.0879 - accuracy: 0.6117 - val_loss: 0.9037 - val_accuracy: 0.6834\n",
      "Trying hyperparameters: gru_units_1=192, gru_units_2=96, dense_units=480, dropout_rate=0.5, learning_rate=0.00010743836998772893, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 23s 78ms/step - loss: 2.4454 - accuracy: 0.1205 - val_loss: 2.1855 - val_accuracy: 0.2146\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 20s 76ms/step - loss: 1.9378 - accuracy: 0.2755 - val_loss: 1.4992 - val_accuracy: 0.4542\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 20s 76ms/step - loss: 1.5651 - accuracy: 0.4119 - val_loss: 1.4430 - val_accuracy: 0.4880\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 20s 76ms/step - loss: 1.4121 - accuracy: 0.4785 - val_loss: 1.1664 - val_accuracy: 0.5974\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 20s 76ms/step - loss: 1.2342 - accuracy: 0.5624 - val_loss: 1.0918 - val_accuracy: 0.6163\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 20s 76ms/step - loss: 1.1330 - accuracy: 0.5971 - val_loss: 1.0204 - val_accuracy: 0.6391\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 20s 76ms/step - loss: 1.0642 - accuracy: 0.6267 - val_loss: 0.9683 - val_accuracy: 0.6606\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 20s 76ms/step - loss: 0.9749 - accuracy: 0.6651 - val_loss: 0.9063 - val_accuracy: 0.6827\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 20s 76ms/step - loss: 0.9135 - accuracy: 0.6889 - val_loss: 0.8564 - val_accuracy: 0.6992\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 20s 74ms/step - loss: 0.8768 - accuracy: 0.7048 - val_loss: 0.8729 - val_accuracy: 0.7105\n",
      "Trying hyperparameters: gru_units_1=96, gru_units_2=416, dense_units=416, dropout_rate=0.4, learning_rate=0.00010193595119877372, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 35s 121ms/step - loss: 2.3617 - accuracy: 0.1559 - val_loss: 1.4117 - val_accuracy: 0.4765\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 32s 119ms/step - loss: 1.3809 - accuracy: 0.4672 - val_loss: 1.1160 - val_accuracy: 0.5965\n",
      "Trying hyperparameters: gru_units_1=224, gru_units_2=128, dense_units=512, dropout_rate=0.5, learning_rate=0.0002550422180593209, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 26s 87ms/step - loss: 2.2720 - accuracy: 0.1867 - val_loss: 1.3763 - val_accuracy: 0.4819\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 23s 85ms/step - loss: 1.3311 - accuracy: 0.5055 - val_loss: 0.9906 - val_accuracy: 0.6567\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 24s 88ms/step - loss: 0.9688 - accuracy: 0.6751 - val_loss: 0.8272 - val_accuracy: 0.7171\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 24s 88ms/step - loss: 0.8133 - accuracy: 0.7248 - val_loss: 0.7312 - val_accuracy: 0.7497\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 24s 88ms/step - loss: 0.7290 - accuracy: 0.7517 - val_loss: 0.6683 - val_accuracy: 0.7789\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 24s 88ms/step - loss: 0.6672 - accuracy: 0.7779 - val_loss: 0.6233 - val_accuracy: 0.7936\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 24s 88ms/step - loss: 0.6155 - accuracy: 0.7955 - val_loss: 0.5830 - val_accuracy: 0.8073\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 24s 88ms/step - loss: 0.5547 - accuracy: 0.8172 - val_loss: 0.5528 - val_accuracy: 0.8194\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 23s 87ms/step - loss: 0.5221 - accuracy: 0.8320 - val_loss: 0.5515 - val_accuracy: 0.8264\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 23s 84ms/step - loss: 0.4883 - accuracy: 0.8420 - val_loss: 0.5095 - val_accuracy: 0.8377\n",
      "Trying hyperparameters: gru_units_1=512, gru_units_2=160, dense_units=320, dropout_rate=0.4, learning_rate=0.000244924636229298, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 54s 193ms/step - loss: 2.1499 - accuracy: 0.2197 - val_loss: 1.3790 - val_accuracy: 0.4688\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 52s 194ms/step - loss: 1.2177 - accuracy: 0.5541 - val_loss: 1.2374 - val_accuracy: 0.5861\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 52s 193ms/step - loss: 1.1870 - accuracy: 0.5897 - val_loss: 0.8475 - val_accuracy: 0.6997\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 52s 193ms/step - loss: 0.8436 - accuracy: 0.7016 - val_loss: 0.8293 - val_accuracy: 0.7168\n",
      "Trying hyperparameters: gru_units_1=448, gru_units_2=96, dense_units=352, dropout_rate=0.5, learning_rate=0.00042060470709428475, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 45s 156ms/step - loss: 2.2356 - accuracy: 0.2041 - val_loss: 1.4946 - val_accuracy: 0.4883\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 42s 155ms/step - loss: 1.4966 - accuracy: 0.4785 - val_loss: 1.5179 - val_accuracy: 0.4783\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 41s 153ms/step - loss: 1.3198 - accuracy: 0.5442 - val_loss: 0.8428 - val_accuracy: 0.7154\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 41s 153ms/step - loss: 0.8050 - accuracy: 0.7256 - val_loss: 0.6247 - val_accuracy: 0.7853\n",
      "Trying hyperparameters: gru_units_1=416, gru_units_2=224, dense_units=480, dropout_rate=0.2, learning_rate=0.00032250501119978145, batch_size=256\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 49s 174ms/step - loss: 1.9964 - accuracy: 0.2828 - val_loss: 0.9145 - val_accuracy: 0.6834\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 46s 172ms/step - loss: 0.9551 - accuracy: 0.6662 - val_loss: 0.7158 - val_accuracy: 0.7497\n"
     ]
    }
   ],
   "source": [
    "study_gru_doc2vec = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler(), pruner=optuna.pruners.HyperbandPruner())\n",
    "study_gru_doc2vec.optimize(lambda trial: objective_gru(trial, embedding_matrix), n_trials=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get best parameters "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec\n",
    "complete_lstm_word2vec_trials = study_lstm_word2vec.trials_dataframe()[study_lstm_word2vec.trials_dataframe()['state'] == 'COMPLETE']\n",
    "complete_lstm_word2vec_trials.to_csv(\"./trials_result/study_lstm_word2vec_trials.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_bilstm_word2vec_trials = study_bilstm_word2vec.trials_dataframe()[study_bilstm_word2vec.trials_dataframe()['state'] == 'COMPLETE']\n",
    "complete_bilstm_word2vec_trials.to_csv(\"./trials_result/study_bilstm_word2vec_trials.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_trials_word2vec_gru = study_gru_word2vec.trials_dataframe()[study_gru_word2vec.trials_dataframe()['state'] == 'COMPLETE']\n",
    "complete_trials_word2vec_gru.to_csv(\"./trials_result/study_gru_word2vec_trials.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec\n",
    "best_hyperparameters_lstm_word2vec = {\n",
    "    'lstm_units_1': study_lstm_word2vec.best_trial.params['lstm_units_1'],\n",
    "    'lstm_units_2': study_lstm_word2vec.best_trial.params['lstm_units_2'],\n",
    "    'dense_units': study_lstm_word2vec.best_trial.params['dense_units'],\n",
    "    'dropout_rate': study_lstm_word2vec.best_trial.params['dropout_rate'],\n",
    "    'learning_rate': study_lstm_word2vec.best_trial.params['learning_rate']\n",
    "    \n",
    "}\n",
    "# Save the best hyperparameters to a JSON file\n",
    "with open('./hyperparameters/LSTM_Word2Vec.json', 'w') as file:\n",
    "    json.dump(best_hyperparameters_lstm_word2vec, file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyperparameters_bilstm_word2vec = {\n",
    "    'lstm_units_1': study_bilstm_word2vec.best_trial.params['lstm_units_1'],\n",
    "    'lstm_units_2': study_bilstm_word2vec.best_trial.params['lstm_units_2'],\n",
    "    'dense_units': study_bilstm_word2vec.best_trial.params['dense_units'],\n",
    "    'dropout_rate': study_bilstm_word2vec.best_trial.params['dropout_rate'],\n",
    "    'learning_rate': study_bilstm_word2vec.best_trial.params['learning_rate']\n",
    "    \n",
    "}\n",
    "# Save the best hyperparameters to a JSON file\n",
    "with open('./hyperparameters/BiLSTM_Word2Vec.json', 'w') as file:\n",
    "    json.dump(best_hyperparameters_bilstm_word2vec, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyperparameters_gru_word2vec = {\n",
    "    'gru_units_1': study_gru_word2vec.best_trial.params['gru_units_1'],\n",
    "    'gru_units_2': study_gru_word2vec.best_trial.params['gru_units_2'],\n",
    "    'dense_units': study_gru_word2vec.best_trial.params['dense_units'],\n",
    "    'dropout_rate': study_gru_word2vec.best_trial.params['dropout_rate'],\n",
    "    'learning_rate': study_gru_word2vec.best_trial.params['learning_rate']\n",
    "    \n",
    "}\n",
    "# Save the best hyperparameters to a JSON file\n",
    "with open('./hyperparameters/GRU_Word2Vec.json', 'w') as file:\n",
    "    json.dump(best_hyperparameters_gru_word2vec, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doc2Vec\n",
    "complete_trials_doc2vec_lstm = study_lstm_doc2vec.trials_dataframe()[study_lstm_doc2vec.trials_dataframe()['state'] == 'COMPLETE']\n",
    "complete_trials_doc2vec_lstm.to_csv(\"./trials_result/study_lstm_doc2vec.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_trials_doc2vec_bilstm = study_bilstm_doc2vec.trials_dataframe()[study_bilstm_doc2vec.trials_dataframe()['state'] == 'COMPLETE']\n",
    "complete_trials_doc2vec_bilstm.to_csv(\"./trials_result/study_bilstm_doc2vec.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_trials_doc2vec_gru = study_gru_doc2vec.trials_dataframe()[study_gru_doc2vec.trials_dataframe()['state'] == 'COMPLETE']\n",
    "complete_trials_doc2vec_gru.to_csv(\"./trials_result/study_gru_doc2vec.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doc2Vec\n",
    "best_hyperparameters_lstm_doc2vec = {\n",
    "    'lstm_units_1': study_lstm_doc2vec.best_trial.params['lstm_units_1'],\n",
    "    'lstm_units_2': study_lstm_doc2vec.best_trial.params['lstm_units_2'],\n",
    "    'dense_units': study_lstm_doc2vec.best_trial.params['dense_units'],\n",
    "    'dropout_rate': study_lstm_doc2vec.best_trial.params['dropout_rate'],\n",
    "    'learning_rate': study_lstm_doc2vec.best_trial.params['learning_rate']\n",
    "    \n",
    "}\n",
    "# Save the best hyperparameters to a JSON file\n",
    "with open('./hyperparameters/LSTM_Doc2Vec.json', 'w') as file:\n",
    "    json.dump(best_hyperparameters_lstm_doc2vec, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyperparameters_bilstm_doc2vec = {\n",
    "    'lstm_units_1': study_bilstm_doc2vec.best_trial.params['lstm_units_1'],\n",
    "    'lstm_units_2': study_bilstm_doc2vec.best_trial.params['lstm_units_2'],\n",
    "    'dense_units': study_bilstm_doc2vec.best_trial.params['dense_units'],\n",
    "    'dropout_rate': study_bilstm_doc2vec.best_trial.params['dropout_rate'],\n",
    "    'learning_rate': study_bilstm_doc2vec.best_trial.params['learning_rate']\n",
    "    \n",
    "}\n",
    "# Save the best hyperparameters to a JSON file\n",
    "with open('./hyperparameters/BiLSTM_Doc2Vec.json', 'w') as file:\n",
    "    json.dump(best_hyperparameters_bilstm_doc2vec, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyperparameters_gru_doc2vec = {\n",
    "    'gru_units_1': study_gru_doc2vec.best_trial.params['gru_units_1'],\n",
    "    'gru_units_2': study_gru_doc2vec.best_trial.params['gru_units_2'],\n",
    "    'dense_units': study_gru_doc2vec.best_trial.params['dense_units'],\n",
    "    'dropout_rate': study_gru_doc2vec.best_trial.params['dropout_rate'],\n",
    "    'learning_rate': study_gru_doc2vec.best_trial.params['learning_rate']\n",
    "    \n",
    "}\n",
    "# Save the best hyperparameters to a JSON file\n",
    "with open('./hyperparameters/GRU_Doc2Vec.json', 'w') as file:\n",
    "    json.dump(best_hyperparameters_gru_doc2vec, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with best hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 35s 116ms/step - loss: 1.8528 - accuracy: 0.3367 - val_loss: 1.3665 - val_accuracy: 0.4916\n",
      "Epoch 2/15\n",
      "268/268 [==============================] - 31s 116ms/step - loss: 1.3931 - accuracy: 0.5112 - val_loss: 1.1729 - val_accuracy: 0.5823\n",
      "Epoch 3/15\n",
      "268/268 [==============================] - 31s 116ms/step - loss: 1.1659 - accuracy: 0.5921 - val_loss: 0.9759 - val_accuracy: 0.6402\n",
      "Epoch 4/15\n",
      "268/268 [==============================] - 31s 117ms/step - loss: 0.9734 - accuracy: 0.6586 - val_loss: 0.7353 - val_accuracy: 0.7332\n",
      "Epoch 5/15\n",
      "268/268 [==============================] - 32s 118ms/step - loss: 0.7395 - accuracy: 0.7348 - val_loss: 0.6450 - val_accuracy: 0.7705\n",
      "Epoch 6/15\n",
      "268/268 [==============================] - 32s 119ms/step - loss: 0.6243 - accuracy: 0.7841 - val_loss: 0.5662 - val_accuracy: 0.8072\n",
      "Epoch 7/15\n",
      "268/268 [==============================] - 32s 119ms/step - loss: 0.5439 - accuracy: 0.8170 - val_loss: 0.5378 - val_accuracy: 0.8187\n",
      "Epoch 8/15\n",
      "268/268 [==============================] - 32s 120ms/step - loss: 0.4770 - accuracy: 0.8414 - val_loss: 0.5161 - val_accuracy: 0.8291\n",
      "Epoch 9/15\n",
      "268/268 [==============================] - 32s 119ms/step - loss: 0.4220 - accuracy: 0.8607 - val_loss: 0.4793 - val_accuracy: 0.8456\n",
      "Epoch 10/15\n",
      "268/268 [==============================] - 32s 119ms/step - loss: 0.3702 - accuracy: 0.8798 - val_loss: 0.4634 - val_accuracy: 0.8489\n",
      "Epoch 11/15\n",
      "268/268 [==============================] - 32s 119ms/step - loss: 0.3307 - accuracy: 0.8944 - val_loss: 0.4465 - val_accuracy: 0.8577\n",
      "Epoch 12/15\n",
      "268/268 [==============================] - 32s 120ms/step - loss: 0.2850 - accuracy: 0.9107 - val_loss: 0.4663 - val_accuracy: 0.8595\n",
      "Epoch 13/15\n",
      "268/268 [==============================] - 32s 120ms/step - loss: 0.2445 - accuracy: 0.9244 - val_loss: 0.4639 - val_accuracy: 0.8611\n",
      "Epoch 14/15\n",
      "268/268 [==============================] - 32s 119ms/step - loss: 0.2109 - accuracy: 0.9356 - val_loss: 0.4745 - val_accuracy: 0.8661\n",
      "Epoch 15/15\n",
      "268/268 [==============================] - 32s 120ms/step - loss: 0.1808 - accuracy: 0.9440 - val_loss: 0.4777 - val_accuracy: 0.8662\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd4d4082550>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Word2Vec\n",
    "best_params_lstm_word2vec = study_lstm_word2vec.best_params\n",
    "\n",
    "# Create a new dictionary excluding 'epochs' and 'batch_size'\n",
    "filtered_params = {key: value for key, value in best_params_lstm_word2vec.items()}\n",
    "filtered_params['embedding_matrix'] = embedding_matrix_word2vec\n",
    "# Now, filtered_params contains all parameters from best_params_bilstm_word2vec except 'epochs' and 'batch_size'\n",
    "best_model_lstm_word2vec = build_lstm_model(**filtered_params)\n",
    "best_model_lstm_word2vec.fit(X_train, y_train, epochs=15, batch_size=256, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "268/268 [==============================] - 154s 561ms/step - loss: 0.9042 - accuracy: 0.7025 - val_loss: 0.5830 - val_accuracy: 0.8033\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 149s 558ms/step - loss: 0.5390 - accuracy: 0.8189 - val_loss: 0.4865 - val_accuracy: 0.8354\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 150s 560ms/step - loss: 0.4496 - accuracy: 0.8479 - val_loss: 0.4549 - val_accuracy: 0.8471\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 150s 559ms/step - loss: 0.3815 - accuracy: 0.8706 - val_loss: 0.4189 - val_accuracy: 0.8579\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 150s 559ms/step - loss: 0.3232 - accuracy: 0.8907 - val_loss: 0.4225 - val_accuracy: 0.8559\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 150s 560ms/step - loss: 0.2853 - accuracy: 0.9026 - val_loss: 0.3992 - val_accuracy: 0.8702\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 150s 560ms/step - loss: 0.2225 - accuracy: 0.9253 - val_loss: 0.4123 - val_accuracy: 0.8673\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 150s 559ms/step - loss: 0.1810 - accuracy: 0.9377 - val_loss: 0.4411 - val_accuracy: 0.8725\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 150s 559ms/step - loss: 0.1425 - accuracy: 0.9516 - val_loss: 0.4677 - val_accuracy: 0.8715\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 150s 559ms/step - loss: 0.1096 - accuracy: 0.9632 - val_loss: 0.5019 - val_accuracy: 0.8702\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd3cc648040>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params_bilstm_word2vec = study_bilstm_word2vec.best_params\n",
    "\n",
    "# Create a new dictionary excluding 'epochs' and 'batch_size'\n",
    "filtered_params = {key: value for key, value in best_params_bilstm_word2vec.items()}\n",
    "filtered_params['embedding_matrix'] = embedding_matrix_word2vec\n",
    "# Now, filtered_params contains all parameters from best_params_bilstm_word2vec except 'epochs' and 'batch_size'\n",
    "best_model_bilstm_word2vec = build_bilstm_model(**filtered_params)\n",
    "best_model_bilstm_word2vec.fit(X_train, y_train, epochs=10, batch_size=256, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "268/268 [==============================] - 62s 223ms/step - loss: 1.7862 - accuracy: 0.3629 - val_loss: 0.6811 - val_accuracy: 0.7640\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 60s 225ms/step - loss: 0.6470 - accuracy: 0.7802 - val_loss: 0.5466 - val_accuracy: 0.8136\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 61s 228ms/step - loss: 0.5508 - accuracy: 0.8135 - val_loss: 0.4892 - val_accuracy: 0.8338\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 62s 231ms/step - loss: 0.4454 - accuracy: 0.8471 - val_loss: 0.4368 - val_accuracy: 0.8524\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 62s 232ms/step - loss: 0.3781 - accuracy: 0.8715 - val_loss: 0.4362 - val_accuracy: 0.8539\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 62s 233ms/step - loss: 0.3351 - accuracy: 0.8861 - val_loss: 0.4264 - val_accuracy: 0.8585\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 63s 234ms/step - loss: 0.2880 - accuracy: 0.9041 - val_loss: 0.4017 - val_accuracy: 0.8682\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 63s 234ms/step - loss: 0.2462 - accuracy: 0.9167 - val_loss: 0.4152 - val_accuracy: 0.8673\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 62s 233ms/step - loss: 0.2047 - accuracy: 0.9303 - val_loss: 0.4132 - val_accuracy: 0.8716\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 62s 233ms/step - loss: 0.1642 - accuracy: 0.9453 - val_loss: 0.4461 - val_accuracy: 0.8715\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd4a458ac10>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params_gru_word2vec = study_gru_word2vec.best_params\n",
    "\n",
    "# Create a new dictionary excluding 'epochs' and 'batch_size'\n",
    "filtered_params = {key: value for key, value in best_params_gru_word2vec.items()}\n",
    "filtered_params['embedding_matrix'] = embedding_matrix_word2vec\n",
    "# Now, filtered_params contains all parameters from best_params_bilstm_word2vec except 'epochs' and 'batch_size'\n",
    "best_model_gru_word2vec = build_gru_model(**filtered_params)\n",
    "best_model_gru_word2vec.fit(X_train, y_train, epochs=10, batch_size=256, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "268/268 [==============================] - 37s 131ms/step - loss: 2.0326 - accuracy: 0.2895 - val_loss: 1.0692 - val_accuracy: 0.6364\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 35s 130ms/step - loss: 0.9910 - accuracy: 0.6520 - val_loss: 0.6715 - val_accuracy: 0.7569\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 35s 131ms/step - loss: 0.6717 - accuracy: 0.7703 - val_loss: 0.5346 - val_accuracy: 0.8208\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 35s 131ms/step - loss: 0.5085 - accuracy: 0.8331 - val_loss: 0.4830 - val_accuracy: 0.8396\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 35s 132ms/step - loss: 0.4171 - accuracy: 0.8651 - val_loss: 0.4441 - val_accuracy: 0.8524\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 36s 133ms/step - loss: 0.3409 - accuracy: 0.8925 - val_loss: 0.4362 - val_accuracy: 0.8625\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 35s 132ms/step - loss: 0.2659 - accuracy: 0.9168 - val_loss: 0.4289 - val_accuracy: 0.8686\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 36s 133ms/step - loss: 0.2112 - accuracy: 0.9349 - val_loss: 0.4430 - val_accuracy: 0.8699\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 36s 133ms/step - loss: 0.1678 - accuracy: 0.9479 - val_loss: 0.4866 - val_accuracy: 0.8719\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 36s 134ms/step - loss: 0.1264 - accuracy: 0.9618 - val_loss: 0.5301 - val_accuracy: 0.8744\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6bd45b9490>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Doc2Vec\n",
    "# After optimization is complete, get the best params\n",
    "best_params_lstm_doc2vec = study_lstm_doc2vec.best_params\n",
    "\n",
    "# Create a new dictionary excluding 'epochs' and 'batch_size'\n",
    "filtered_params = {key: value for key, value in best_params_lstm_doc2vec.items()}\n",
    "filtered_params['embedding_matrix'] = embedding_matrix_doc2vec\n",
    "\n",
    "# Now, filtered_params contains all parameters from best_params_lstm_doc2vec except 'epochs' and 'batch_size'\n",
    "best_model_lstm_doc2vec = build_lstm_model(**filtered_params)\n",
    "\n",
    "# Fit the model with the EarlyStopping callback\n",
    "best_model_lstm_doc2vec.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=10,\n",
    "    batch_size=256,\n",
    "    validation_data=(X_val, y_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "268/268 [==============================] - 28s 90ms/step - loss: 1.0989 - accuracy: 0.6381 - val_loss: 0.6039 - val_accuracy: 0.7979\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 23s 86ms/step - loss: 0.5725 - accuracy: 0.8123 - val_loss: 0.5060 - val_accuracy: 0.8342\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 23s 86ms/step - loss: 0.4621 - accuracy: 0.8514 - val_loss: 0.4696 - val_accuracy: 0.8498\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 23s 87ms/step - loss: 0.3797 - accuracy: 0.8790 - val_loss: 0.4548 - val_accuracy: 0.8519\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 23s 87ms/step - loss: 0.3093 - accuracy: 0.9009 - val_loss: 0.4312 - val_accuracy: 0.8666\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 23s 86ms/step - loss: 0.2503 - accuracy: 0.9197 - val_loss: 0.4335 - val_accuracy: 0.8694\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 23s 86ms/step - loss: 0.2022 - accuracy: 0.9360 - val_loss: 0.4389 - val_accuracy: 0.8725\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 23s 86ms/step - loss: 0.1517 - accuracy: 0.9528 - val_loss: 0.4648 - val_accuracy: 0.8737\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 23s 86ms/step - loss: 0.1251 - accuracy: 0.9604 - val_loss: 0.5140 - val_accuracy: 0.8694\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 23s 87ms/step - loss: 0.0999 - accuracy: 0.9686 - val_loss: 0.5657 - val_accuracy: 0.8709\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3a4c0ca580>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params_bilstm_doc2vec = study_bilstm_doc2vec.best_params\n",
    "\n",
    "# Create a new dictionary excluding 'epochs' and 'batch_size'\n",
    "filtered_params = {key: value for key, value in best_params_bilstm_doc2vec.items()}\n",
    "filtered_params['embedding_matrix'] = embedding_matrix_doc2vec\n",
    "\n",
    "# Now, filtered_params contains all parameters from best_params_lstm_doc2vec except 'epochs' and 'batch_size'\n",
    "best_model_bilstm_doc2vec = build_bilstm_model(**filtered_params)\n",
    "\n",
    "# Fit the model with the EarlyStopping callback\n",
    "best_model_bilstm_doc2vec.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=10,\n",
    "    batch_size=256,\n",
    "    validation_data=(X_val, y_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-14 04:30:12.554070: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-12-14 04:30:12.555435: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2023-12-14 04:30:15.403404: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:88:00.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2023-12-14 04:30:15.404217: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:89:00.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2023-12-14 04:30:15.404971: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 2 with properties: \n",
      "pciBusID: 0000:b1:00.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2023-12-14 04:30:15.405710: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 3 with properties: \n",
      "pciBusID: 0000:b2:00.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2023-12-14 04:30:15.405729: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-12-14 04:30:15.407404: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-12-14 04:30:15.407486: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-12-14 04:30:15.408938: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-12-14 04:30:15.409218: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-12-14 04:30:15.410476: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-12-14 04:30:15.411136: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-12-14 04:30:15.414019: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-12-14 04:30:15.420062: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1, 2, 3\n",
      "2023-12-14 04:30:15.421791: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-14 04:30:15.429839: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-12-14 04:30:15.821174: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:88:00.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2023-12-14 04:30:15.823575: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:89:00.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2023-12-14 04:30:15.825825: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 2 with properties: \n",
      "pciBusID: 0000:b1:00.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2023-12-14 04:30:15.828043: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 3 with properties: \n",
      "pciBusID: 0000:b2:00.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2023-12-14 04:30:15.828106: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-12-14 04:30:15.828176: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-12-14 04:30:15.828214: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-12-14 04:30:15.828251: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-12-14 04:30:15.828287: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-12-14 04:30:15.828323: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-12-14 04:30:15.828360: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-12-14 04:30:15.828397: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-12-14 04:30:15.836774: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1, 2, 3\n",
      "2023-12-14 04:30:15.836814: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-12-14 04:30:17.565555: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-12-14 04:30:17.565587: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 2 3 \n",
      "2023-12-14 04:30:17.565592: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N Y Y Y \n",
      "2023-12-14 04:30:17.565595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   Y N Y Y \n",
      "2023-12-14 04:30:17.565598: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 2:   Y Y N Y \n",
      "2023-12-14 04:30:17.565600: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 3:   Y Y Y N \n",
      "2023-12-14 04:30:17.570984: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13970 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:88:00.0, compute capability: 7.5)\n",
      "2023-12-14 04:30:17.573382: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 13970 MB memory) -> physical GPU (device: 1, name: Tesla T4, pci bus id: 0000:89:00.0, compute capability: 7.5)\n",
      "2023-12-14 04:30:17.575312: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 13970 MB memory) -> physical GPU (device: 2, name: Tesla T4, pci bus id: 0000:b1:00.0, compute capability: 7.5)\n",
      "2023-12-14 04:30:17.577284: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 13970 MB memory) -> physical GPU (device: 3, name: Tesla T4, pci bus id: 0000:b2:00.0, compute capability: 7.5)\n",
      "2023-12-14 04:30:18.281161: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2023-12-14 04:30:18.303755: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2100000000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-14 04:30:20.172773: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-12-14 04:30:20.482010: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 46s 159ms/step - loss: 2.0284 - accuracy: 0.2663 - val_loss: 0.9289 - val_accuracy: 0.6844\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 42s 158ms/step - loss: 0.8661 - accuracy: 0.6961 - val_loss: 0.7168 - val_accuracy: 0.7466\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 43s 159ms/step - loss: 0.7019 - accuracy: 0.7513 - val_loss: 0.6182 - val_accuracy: 0.7805\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 43s 159ms/step - loss: 0.5688 - accuracy: 0.8011 - val_loss: 0.5225 - val_accuracy: 0.8182\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 43s 160ms/step - loss: 0.4947 - accuracy: 0.8277 - val_loss: 0.4863 - val_accuracy: 0.8314\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 43s 161ms/step - loss: 0.4680 - accuracy: 0.8377 - val_loss: 0.4617 - val_accuracy: 0.8375\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 43s 162ms/step - loss: 0.4231 - accuracy: 0.8514 - val_loss: 0.4433 - val_accuracy: 0.8450\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 44s 163ms/step - loss: 0.3967 - accuracy: 0.8640 - val_loss: 0.4293 - val_accuracy: 0.8531\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 44s 164ms/step - loss: 0.3723 - accuracy: 0.8730 - val_loss: 0.4145 - val_accuracy: 0.8600\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 44s 164ms/step - loss: 0.3373 - accuracy: 0.8862 - val_loss: 0.4147 - val_accuracy: 0.8612\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5558212700>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params_gru_doc2vec = study_gru_doc2vec.best_params\n",
    "\n",
    "# Create a new dictionary excluding 'epochs' and 'batch_size'\n",
    "filtered_params = {key: value for key, value in best_params_gru_doc2vec.items()}\n",
    "filtered_params['embedding_matrix'] = embedding_matrix_doc2vec\n",
    "\n",
    "# Now, filtered_params contains all parameters from best_params_lstm_doc2vec except 'epochs' and 'batch_size'\n",
    "best_model_gru_doc2vec = build_gru_model(**filtered_params)\n",
    "\n",
    "# Fit the model with the EarlyStopping callback\n",
    "best_model_gru_doc2vec.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=10,\n",
    "    batch_size=256,\n",
    "    validation_data=(X_val, y_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "715/715 [==============================] - 12s 16ms/step - loss: 0.4438 - accuracy: 0.8729\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4437906742095947, 0.8729443550109863]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_gru_word2vec.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "715/715 [==============================] - 24s 33ms/step - loss: 0.5025 - accuracy: 0.8704\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5025023818016052, 0.8704076409339905]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_bilstm_word2vec.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "715/715 [==============================] - 12s 17ms/step - loss: 0.4951 - accuracy: 0.8636\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.49508681893348694, 0.8636283874511719]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_lstm_word2vec.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  7/715 [..............................] - ETA: 14s - loss: 0.6645 - accuracy: 0.8348"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "715/715 [==============================] - 12s 17ms/step - loss: 0.5397 - accuracy: 0.8708\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5397418141365051, 0.870757520198822]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_lstm_doc2vec.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "715/715 [==============================] - 18s 25ms/step - loss: 0.5673 - accuracy: 0.8723\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.567282497882843, 0.8723320364952087]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_bilstm_doc2vec.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  7/715 [..............................] - ETA: 16s - loss: 0.5482 - accuracy: 0.8036"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "715/715 [==============================] - 12s 17ms/step - loss: 0.4222 - accuracy: 0.8593\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.422209769487381, 0.8592547178268433]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_gru_doc2vec.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec\n",
    "best_model_lstm_word2vec.save(MODEL_FOLDER + sep + 'lstm_word2vec.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_bilstm_word2vec.save(MODEL_FOLDER + sep + 'bilstm_word2vec.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_gru_word2vec.save(MODEL_FOLDER + sep + 'gru_word2vec.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_lstm_doc2vec.save(MODEL_FOLDER + sep + \"lstm_doc2vec.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_bilstm_doc2vec.save(MODEL_FOLDER + sep + \"bilstm_doc2vec.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_gru_doc2vec.save(MODEL_FOLDER + sep + 'gru_doc2vec.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers",
         "name": "Objective Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          10,
          22,
          26
         ],
         "y": [
          0.8119314312934875,
          0.6299422383308411,
          0.8666899800300598,
          0.7178096771240234,
          0.637508749961853,
          0.8660339117050171,
          0.8411914110183716,
          0.8074702620506287
         ]
        },
        {
         "mode": "lines",
         "name": "Best Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49
         ],
         "y": [
          0.8119314312934875,
          0.8119314312934875,
          0.8666899800300598,
          0.8666899800300598,
          0.8666899800300598,
          0.8666899800300598,
          0.8666899800300598,
          0.8666899800300598,
          0.8666899800300598,
          0.8666899800300598,
          0.8666899800300598,
          0.8666899800300598,
          0.8666899800300598,
          0.8666899800300598,
          0.8666899800300598,
          0.8666899800300598,
          0.8666899800300598,
          0.8666899800300598,
          0.8666899800300598,
          0.8666899800300598,
          0.8666899800300598,
          0.8666899800300598,
          0.8666899800300598,
          0.8666899800300598,
          0.8666899800300598,
          0.8666899800300598,
          0.8666899800300598,
          0.8666899800300598,
          0.8666899800300598,
          0.8666899800300598,
          0.8666899800300598,
          0.8666899800300598,
          0.8666899800300598,
          0.8666899800300598,
          0.8666899800300598,
          0.8666899800300598,
          0.8666899800300598,
          0.8666899800300598,
          0.8666899800300598,
          0.8666899800300598,
          0.8666899800300598,
          0.8666899800300598,
          0.8666899800300598,
          0.8666899800300598,
          0.8666899800300598,
          0.8666899800300598,
          0.8666899800300598,
          0.8666899800300598,
          0.8666899800300598,
          0.8666899800300598
         ]
        },
        {
         "marker": {
          "color": "#cccccc"
         },
         "mode": "markers",
         "name": "Infeasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [],
         "y": []
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Optimization History Plot"
        },
        "xaxis": {
         "title": {
          "text": "Trial"
         }
        },
        "yaxis": {
         "title": {
          "text": "Objective Value"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"d57e9ce1-bd42-4353-8dc3-20c09f9a0eac\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"d57e9ce1-bd42-4353-8dc3-20c09f9a0eac\")) {                    Plotly.newPlot(                        \"d57e9ce1-bd42-4353-8dc3-20c09f9a0eac\",                        [{\"mode\":\"markers\",\"name\":\"Objective Value\",\"x\":[0,1,2,3,4,10,22,26],\"y\":[0.8119314312934875,0.6299422383308411,0.8666899800300598,0.7178096771240234,0.637508749961853,0.8660339117050171,0.8411914110183716,0.8074702620506287],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Best Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49],\"y\":[0.8119314312934875,0.8119314312934875,0.8666899800300598,0.8666899800300598,0.8666899800300598,0.8666899800300598,0.8666899800300598,0.8666899800300598,0.8666899800300598,0.8666899800300598,0.8666899800300598,0.8666899800300598,0.8666899800300598,0.8666899800300598,0.8666899800300598,0.8666899800300598,0.8666899800300598,0.8666899800300598,0.8666899800300598,0.8666899800300598,0.8666899800300598,0.8666899800300598,0.8666899800300598,0.8666899800300598,0.8666899800300598,0.8666899800300598,0.8666899800300598,0.8666899800300598,0.8666899800300598,0.8666899800300598,0.8666899800300598,0.8666899800300598,0.8666899800300598,0.8666899800300598,0.8666899800300598,0.8666899800300598,0.8666899800300598,0.8666899800300598,0.8666899800300598,0.8666899800300598,0.8666899800300598,0.8666899800300598,0.8666899800300598,0.8666899800300598,0.8666899800300598,0.8666899800300598,0.8666899800300598,0.8666899800300598,0.8666899800300598,0.8666899800300598],\"type\":\"scatter\"},{\"marker\":{\"color\":\"#cccccc\"},\"mode\":\"markers\",\"name\":\"Infeasible Trial\",\"showlegend\":false,\"x\":[],\"y\":[],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Optimization History Plot\"},\"xaxis\":{\"title\":{\"text\":\"Trial\"}},\"yaxis\":{\"title\":{\"text\":\"Objective Value\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('d57e9ce1-bd42-4353-8dc3-20c09f9a0eac');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_optimization_history(study_lstm_word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers",
         "name": "Objective Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          5,
          7,
          11,
          14,
          20,
          22,
          25,
          30,
          34
         ],
         "y": [
          0.7603219151496887,
          0.8678708672523499,
          0.8664712905883789,
          0.8664712905883789,
          0.8670836091041565,
          0.8606980443000793,
          0.8645468950271606,
          0.6289362907409668,
          0.8449965119361877,
          0.7761983871459961,
          0.8388733267784119,
          0.7354356050491333
         ]
        },
        {
         "mode": "lines",
         "name": "Best Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49
         ],
         "y": [
          0.7603219151496887,
          0.8678708672523499,
          0.8678708672523499,
          0.8678708672523499,
          0.8678708672523499,
          0.8678708672523499,
          0.8678708672523499,
          0.8678708672523499,
          0.8678708672523499,
          0.8678708672523499,
          0.8678708672523499,
          0.8678708672523499,
          0.8678708672523499,
          0.8678708672523499,
          0.8678708672523499,
          0.8678708672523499,
          0.8678708672523499,
          0.8678708672523499,
          0.8678708672523499,
          0.8678708672523499,
          0.8678708672523499,
          0.8678708672523499,
          0.8678708672523499,
          0.8678708672523499,
          0.8678708672523499,
          0.8678708672523499,
          0.8678708672523499,
          0.8678708672523499,
          0.8678708672523499,
          0.8678708672523499,
          0.8678708672523499,
          0.8678708672523499,
          0.8678708672523499,
          0.8678708672523499,
          0.8678708672523499,
          0.8678708672523499,
          0.8678708672523499,
          0.8678708672523499,
          0.8678708672523499,
          0.8678708672523499,
          0.8678708672523499,
          0.8678708672523499,
          0.8678708672523499,
          0.8678708672523499,
          0.8678708672523499,
          0.8678708672523499,
          0.8678708672523499,
          0.8678708672523499,
          0.8678708672523499,
          0.8678708672523499
         ]
        },
        {
         "marker": {
          "color": "#cccccc"
         },
         "mode": "markers",
         "name": "Infeasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [],
         "y": []
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Optimization History Plot"
        },
        "xaxis": {
         "title": {
          "text": "Trial"
         }
        },
        "yaxis": {
         "title": {
          "text": "Objective Value"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"d3f14395-13ec-4563-b2a7-66d5d7302e95\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"d3f14395-13ec-4563-b2a7-66d5d7302e95\")) {                    Plotly.newPlot(                        \"d3f14395-13ec-4563-b2a7-66d5d7302e95\",                        [{\"mode\":\"markers\",\"name\":\"Objective Value\",\"x\":[0,1,2,5,7,11,14,20,22,25,30,34],\"y\":[0.7603219151496887,0.8678708672523499,0.8664712905883789,0.8664712905883789,0.8670836091041565,0.8606980443000793,0.8645468950271606,0.6289362907409668,0.8449965119361877,0.7761983871459961,0.8388733267784119,0.7354356050491333],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Best Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49],\"y\":[0.7603219151496887,0.8678708672523499,0.8678708672523499,0.8678708672523499,0.8678708672523499,0.8678708672523499,0.8678708672523499,0.8678708672523499,0.8678708672523499,0.8678708672523499,0.8678708672523499,0.8678708672523499,0.8678708672523499,0.8678708672523499,0.8678708672523499,0.8678708672523499,0.8678708672523499,0.8678708672523499,0.8678708672523499,0.8678708672523499,0.8678708672523499,0.8678708672523499,0.8678708672523499,0.8678708672523499,0.8678708672523499,0.8678708672523499,0.8678708672523499,0.8678708672523499,0.8678708672523499,0.8678708672523499,0.8678708672523499,0.8678708672523499,0.8678708672523499,0.8678708672523499,0.8678708672523499,0.8678708672523499,0.8678708672523499,0.8678708672523499,0.8678708672523499,0.8678708672523499,0.8678708672523499,0.8678708672523499,0.8678708672523499,0.8678708672523499,0.8678708672523499,0.8678708672523499,0.8678708672523499,0.8678708672523499,0.8678708672523499,0.8678708672523499],\"type\":\"scatter\"},{\"marker\":{\"color\":\"#cccccc\"},\"mode\":\"markers\",\"name\":\"Infeasible Trial\",\"showlegend\":false,\"x\":[],\"y\":[],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Optimization History Plot\"},\"xaxis\":{\"title\":{\"text\":\"Trial\"}},\"yaxis\":{\"title\":{\"text\":\"Objective Value\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('d3f14395-13ec-4563-b2a7-66d5d7302e95');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_optimization_history(study_bilstm_word2vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers",
         "name": "Objective Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          6,
          10,
          20
         ],
         "y": [
          0.8684394955635071,
          0.8437281250953674,
          0.8708012700080872,
          0.8229531049728394,
          0.8612228631973267,
          0.09412176162004471,
          0.866515040397644
         ]
        },
        {
         "mode": "lines",
         "name": "Best Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49
         ],
         "y": [
          0.8684394955635071,
          0.8684394955635071,
          0.8708012700080872,
          0.8708012700080872,
          0.8708012700080872,
          0.8708012700080872,
          0.8708012700080872,
          0.8708012700080872,
          0.8708012700080872,
          0.8708012700080872,
          0.8708012700080872,
          0.8708012700080872,
          0.8708012700080872,
          0.8708012700080872,
          0.8708012700080872,
          0.8708012700080872,
          0.8708012700080872,
          0.8708012700080872,
          0.8708012700080872,
          0.8708012700080872,
          0.8708012700080872,
          0.8708012700080872,
          0.8708012700080872,
          0.8708012700080872,
          0.8708012700080872,
          0.8708012700080872,
          0.8708012700080872,
          0.8708012700080872,
          0.8708012700080872,
          0.8708012700080872,
          0.8708012700080872,
          0.8708012700080872,
          0.8708012700080872,
          0.8708012700080872,
          0.8708012700080872,
          0.8708012700080872,
          0.8708012700080872,
          0.8708012700080872,
          0.8708012700080872,
          0.8708012700080872,
          0.8708012700080872,
          0.8708012700080872,
          0.8708012700080872,
          0.8708012700080872,
          0.8708012700080872,
          0.8708012700080872,
          0.8708012700080872,
          0.8708012700080872,
          0.8708012700080872,
          0.8708012700080872
         ]
        },
        {
         "marker": {
          "color": "#cccccc"
         },
         "mode": "markers",
         "name": "Infeasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [],
         "y": []
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Optimization History Plot"
        },
        "xaxis": {
         "title": {
          "text": "Trial"
         }
        },
        "yaxis": {
         "title": {
          "text": "Objective Value"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"3fa19292-86a8-4e8e-85b8-ad9a7b672b91\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"3fa19292-86a8-4e8e-85b8-ad9a7b672b91\")) {                    Plotly.newPlot(                        \"3fa19292-86a8-4e8e-85b8-ad9a7b672b91\",                        [{\"mode\":\"markers\",\"name\":\"Objective Value\",\"x\":[0,1,2,3,6,10,20],\"y\":[0.8684394955635071,0.8437281250953674,0.8708012700080872,0.8229531049728394,0.8612228631973267,0.09412176162004471,0.866515040397644],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Best Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49],\"y\":[0.8684394955635071,0.8684394955635071,0.8708012700080872,0.8708012700080872,0.8708012700080872,0.8708012700080872,0.8708012700080872,0.8708012700080872,0.8708012700080872,0.8708012700080872,0.8708012700080872,0.8708012700080872,0.8708012700080872,0.8708012700080872,0.8708012700080872,0.8708012700080872,0.8708012700080872,0.8708012700080872,0.8708012700080872,0.8708012700080872,0.8708012700080872,0.8708012700080872,0.8708012700080872,0.8708012700080872,0.8708012700080872,0.8708012700080872,0.8708012700080872,0.8708012700080872,0.8708012700080872,0.8708012700080872,0.8708012700080872,0.8708012700080872,0.8708012700080872,0.8708012700080872,0.8708012700080872,0.8708012700080872,0.8708012700080872,0.8708012700080872,0.8708012700080872,0.8708012700080872,0.8708012700080872,0.8708012700080872,0.8708012700080872,0.8708012700080872,0.8708012700080872,0.8708012700080872,0.8708012700080872,0.8708012700080872,0.8708012700080872,0.8708012700080872],\"type\":\"scatter\"},{\"marker\":{\"color\":\"#cccccc\"},\"mode\":\"markers\",\"name\":\"Infeasible Trial\",\"showlegend\":false,\"x\":[],\"y\":[],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Optimization History Plot\"},\"xaxis\":{\"title\":{\"text\":\"Trial\"}},\"yaxis\":{\"title\":{\"text\":\"Objective Value\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('3fa19292-86a8-4e8e-85b8-ad9a7b672b91');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_optimization_history(study_gru_word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers",
         "name": "Objective Value",
         "type": "scatter",
         "x": [
          0,
          1,
          3,
          4,
          5,
          7,
          9,
          11,
          17,
          30,
          34,
          35,
          44
         ],
         "y": [
          0.8588610887527466,
          0.6765657663345337,
          0.7042074799537659,
          0.8627099394798279,
          0.8472708463668823,
          0.5489853024482727,
          0.5220870971679688,
          0.09412176162004471,
          0.09412176162004471,
          0.5834062099456787,
          0.7465885281562805,
          0.4581000804901123,
          0.5196815729141235
         ]
        },
        {
         "mode": "lines",
         "name": "Best Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49
         ],
         "y": [
          0.8588610887527466,
          0.8588610887527466,
          0.8588610887527466,
          0.8588610887527466,
          0.8627099394798279,
          0.8627099394798279,
          0.8627099394798279,
          0.8627099394798279,
          0.8627099394798279,
          0.8627099394798279,
          0.8627099394798279,
          0.8627099394798279,
          0.8627099394798279,
          0.8627099394798279,
          0.8627099394798279,
          0.8627099394798279,
          0.8627099394798279,
          0.8627099394798279,
          0.8627099394798279,
          0.8627099394798279,
          0.8627099394798279,
          0.8627099394798279,
          0.8627099394798279,
          0.8627099394798279,
          0.8627099394798279,
          0.8627099394798279,
          0.8627099394798279,
          0.8627099394798279,
          0.8627099394798279,
          0.8627099394798279,
          0.8627099394798279,
          0.8627099394798279,
          0.8627099394798279,
          0.8627099394798279,
          0.8627099394798279,
          0.8627099394798279,
          0.8627099394798279,
          0.8627099394798279,
          0.8627099394798279,
          0.8627099394798279,
          0.8627099394798279,
          0.8627099394798279,
          0.8627099394798279,
          0.8627099394798279,
          0.8627099394798279,
          0.8627099394798279,
          0.8627099394798279,
          0.8627099394798279,
          0.8627099394798279,
          0.8627099394798279
         ]
        },
        {
         "marker": {
          "color": "#cccccc"
         },
         "mode": "markers",
         "name": "Infeasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [],
         "y": []
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Optimization History Plot"
        },
        "xaxis": {
         "title": {
          "text": "Trial"
         }
        },
        "yaxis": {
         "title": {
          "text": "Objective Value"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"886558b2-e968-4ae0-8ced-a462a273d3ee\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"886558b2-e968-4ae0-8ced-a462a273d3ee\")) {                    Plotly.newPlot(                        \"886558b2-e968-4ae0-8ced-a462a273d3ee\",                        [{\"mode\":\"markers\",\"name\":\"Objective Value\",\"x\":[0,1,3,4,5,7,9,11,17,30,34,35,44],\"y\":[0.8588610887527466,0.6765657663345337,0.7042074799537659,0.8627099394798279,0.8472708463668823,0.5489853024482727,0.5220870971679688,0.09412176162004471,0.09412176162004471,0.5834062099456787,0.7465885281562805,0.4581000804901123,0.5196815729141235],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Best Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49],\"y\":[0.8588610887527466,0.8588610887527466,0.8588610887527466,0.8588610887527466,0.8627099394798279,0.8627099394798279,0.8627099394798279,0.8627099394798279,0.8627099394798279,0.8627099394798279,0.8627099394798279,0.8627099394798279,0.8627099394798279,0.8627099394798279,0.8627099394798279,0.8627099394798279,0.8627099394798279,0.8627099394798279,0.8627099394798279,0.8627099394798279,0.8627099394798279,0.8627099394798279,0.8627099394798279,0.8627099394798279,0.8627099394798279,0.8627099394798279,0.8627099394798279,0.8627099394798279,0.8627099394798279,0.8627099394798279,0.8627099394798279,0.8627099394798279,0.8627099394798279,0.8627099394798279,0.8627099394798279,0.8627099394798279,0.8627099394798279,0.8627099394798279,0.8627099394798279,0.8627099394798279,0.8627099394798279,0.8627099394798279,0.8627099394798279,0.8627099394798279,0.8627099394798279,0.8627099394798279,0.8627099394798279,0.8627099394798279,0.8627099394798279,0.8627099394798279],\"type\":\"scatter\"},{\"marker\":{\"color\":\"#cccccc\"},\"mode\":\"markers\",\"name\":\"Infeasible Trial\",\"showlegend\":false,\"x\":[],\"y\":[],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Optimization History Plot\"},\"xaxis\":{\"title\":{\"text\":\"Trial\"}},\"yaxis\":{\"title\":{\"text\":\"Objective Value\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('886558b2-e968-4ae0-8ced-a462a273d3ee');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "html_file_path = \"./images/study_lstm_doc2vec_optimize_history.html\"\n",
    "# Plot and save the optimization history plot as an HTML file\n",
    "ov.plot_optimization_history(study_lstm_doc2vec).write_html(html_file_path)\n",
    "plot_optimization_history(study_lstm_doc2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers",
         "name": "Objective Value",
         "type": "scatter",
         "x": [
          0,
          1,
          5,
          11,
          13,
          16,
          31,
          41,
          49
         ],
         "y": [
          0.8674772381782532,
          0.8330563306808472,
          0.8727694153785706,
          0.8493701815605164,
          0.8612666130065918,
          0.7909814715385437,
          0.8356367945671082,
          0.8498513102531433,
          0.8383922576904297
         ]
        },
        {
         "mode": "lines",
         "name": "Best Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49
         ],
         "y": [
          0.8674772381782532,
          0.8674772381782532,
          0.8674772381782532,
          0.8674772381782532,
          0.8674772381782532,
          0.8727694153785706,
          0.8727694153785706,
          0.8727694153785706,
          0.8727694153785706,
          0.8727694153785706,
          0.8727694153785706,
          0.8727694153785706,
          0.8727694153785706,
          0.8727694153785706,
          0.8727694153785706,
          0.8727694153785706,
          0.8727694153785706,
          0.8727694153785706,
          0.8727694153785706,
          0.8727694153785706,
          0.8727694153785706,
          0.8727694153785706,
          0.8727694153785706,
          0.8727694153785706,
          0.8727694153785706,
          0.8727694153785706,
          0.8727694153785706,
          0.8727694153785706,
          0.8727694153785706,
          0.8727694153785706,
          0.8727694153785706,
          0.8727694153785706,
          0.8727694153785706,
          0.8727694153785706,
          0.8727694153785706,
          0.8727694153785706,
          0.8727694153785706,
          0.8727694153785706,
          0.8727694153785706,
          0.8727694153785706,
          0.8727694153785706,
          0.8727694153785706,
          0.8727694153785706,
          0.8727694153785706,
          0.8727694153785706,
          0.8727694153785706,
          0.8727694153785706,
          0.8727694153785706,
          0.8727694153785706,
          0.8727694153785706
         ]
        },
        {
         "marker": {
          "color": "#cccccc"
         },
         "mode": "markers",
         "name": "Infeasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [],
         "y": []
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Optimization History Plot"
        },
        "xaxis": {
         "title": {
          "text": "Trial"
         }
        },
        "yaxis": {
         "title": {
          "text": "Objective Value"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"8182e716-2efe-49e1-b63e-2261fa8b85b4\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"8182e716-2efe-49e1-b63e-2261fa8b85b4\")) {                    Plotly.newPlot(                        \"8182e716-2efe-49e1-b63e-2261fa8b85b4\",                        [{\"mode\":\"markers\",\"name\":\"Objective Value\",\"x\":[0,1,5,11,13,16,31,41,49],\"y\":[0.8674772381782532,0.8330563306808472,0.8727694153785706,0.8493701815605164,0.8612666130065918,0.7909814715385437,0.8356367945671082,0.8498513102531433,0.8383922576904297],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Best Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49],\"y\":[0.8674772381782532,0.8674772381782532,0.8674772381782532,0.8674772381782532,0.8674772381782532,0.8727694153785706,0.8727694153785706,0.8727694153785706,0.8727694153785706,0.8727694153785706,0.8727694153785706,0.8727694153785706,0.8727694153785706,0.8727694153785706,0.8727694153785706,0.8727694153785706,0.8727694153785706,0.8727694153785706,0.8727694153785706,0.8727694153785706,0.8727694153785706,0.8727694153785706,0.8727694153785706,0.8727694153785706,0.8727694153785706,0.8727694153785706,0.8727694153785706,0.8727694153785706,0.8727694153785706,0.8727694153785706,0.8727694153785706,0.8727694153785706,0.8727694153785706,0.8727694153785706,0.8727694153785706,0.8727694153785706,0.8727694153785706,0.8727694153785706,0.8727694153785706,0.8727694153785706,0.8727694153785706,0.8727694153785706,0.8727694153785706,0.8727694153785706,0.8727694153785706,0.8727694153785706,0.8727694153785706,0.8727694153785706,0.8727694153785706,0.8727694153785706],\"type\":\"scatter\"},{\"marker\":{\"color\":\"#cccccc\"},\"mode\":\"markers\",\"name\":\"Infeasible Trial\",\"showlegend\":false,\"x\":[],\"y\":[],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Optimization History Plot\"},\"xaxis\":{\"title\":{\"text\":\"Trial\"}},\"yaxis\":{\"title\":{\"text\":\"Objective Value\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('8182e716-2efe-49e1-b63e-2261fa8b85b4');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "html_file_path = \"./images/study_bilstm_doc2vec_optimize_history.html\"\n",
    "# Plot and save the optimization history plot as an HTML file\n",
    "ov.plot_optimization_history(study_bilstm_doc2vec).write_html(html_file_path)\n",
    "plot_optimization_history(study_bilstm_doc2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers",
         "name": "Objective Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          4,
          5,
          8,
          12,
          32,
          41,
          42,
          44,
          46
         ],
         "y": [
          0.8543124794960022,
          0.8433782458305359,
          0.8286389112472534,
          0.09412176162004471,
          0.7416025400161743,
          0.7884446978569031,
          0.7078813910484314,
          0.7671886086463928,
          0.7608029842376709,
          0.7378848791122437,
          0.7119926810264587,
          0.837517499923706
         ]
        },
        {
         "mode": "lines",
         "name": "Best Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49
         ],
         "y": [
          0.8543124794960022,
          0.8543124794960022,
          0.8543124794960022,
          0.8543124794960022,
          0.8543124794960022,
          0.8543124794960022,
          0.8543124794960022,
          0.8543124794960022,
          0.8543124794960022,
          0.8543124794960022,
          0.8543124794960022,
          0.8543124794960022,
          0.8543124794960022,
          0.8543124794960022,
          0.8543124794960022,
          0.8543124794960022,
          0.8543124794960022,
          0.8543124794960022,
          0.8543124794960022,
          0.8543124794960022,
          0.8543124794960022,
          0.8543124794960022,
          0.8543124794960022,
          0.8543124794960022,
          0.8543124794960022,
          0.8543124794960022,
          0.8543124794960022,
          0.8543124794960022,
          0.8543124794960022,
          0.8543124794960022,
          0.8543124794960022,
          0.8543124794960022,
          0.8543124794960022,
          0.8543124794960022,
          0.8543124794960022,
          0.8543124794960022,
          0.8543124794960022,
          0.8543124794960022,
          0.8543124794960022,
          0.8543124794960022,
          0.8543124794960022,
          0.8543124794960022,
          0.8543124794960022,
          0.8543124794960022,
          0.8543124794960022,
          0.8543124794960022,
          0.8543124794960022,
          0.8543124794960022,
          0.8543124794960022,
          0.8543124794960022
         ]
        },
        {
         "marker": {
          "color": "#cccccc"
         },
         "mode": "markers",
         "name": "Infeasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [],
         "y": []
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Optimization History Plot"
        },
        "xaxis": {
         "title": {
          "text": "Trial"
         }
        },
        "yaxis": {
         "title": {
          "text": "Objective Value"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"a2570a67-5467-44e7-ba7e-eea779cdfb18\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"a2570a67-5467-44e7-ba7e-eea779cdfb18\")) {                    Plotly.newPlot(                        \"a2570a67-5467-44e7-ba7e-eea779cdfb18\",                        [{\"mode\":\"markers\",\"name\":\"Objective Value\",\"x\":[0,1,2,4,5,8,12,32,41,42,44,46],\"y\":[0.8543124794960022,0.8433782458305359,0.8286389112472534,0.09412176162004471,0.7416025400161743,0.7884446978569031,0.7078813910484314,0.7671886086463928,0.7608029842376709,0.7378848791122437,0.7119926810264587,0.837517499923706],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Best Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49],\"y\":[0.8543124794960022,0.8543124794960022,0.8543124794960022,0.8543124794960022,0.8543124794960022,0.8543124794960022,0.8543124794960022,0.8543124794960022,0.8543124794960022,0.8543124794960022,0.8543124794960022,0.8543124794960022,0.8543124794960022,0.8543124794960022,0.8543124794960022,0.8543124794960022,0.8543124794960022,0.8543124794960022,0.8543124794960022,0.8543124794960022,0.8543124794960022,0.8543124794960022,0.8543124794960022,0.8543124794960022,0.8543124794960022,0.8543124794960022,0.8543124794960022,0.8543124794960022,0.8543124794960022,0.8543124794960022,0.8543124794960022,0.8543124794960022,0.8543124794960022,0.8543124794960022,0.8543124794960022,0.8543124794960022,0.8543124794960022,0.8543124794960022,0.8543124794960022,0.8543124794960022,0.8543124794960022,0.8543124794960022,0.8543124794960022,0.8543124794960022,0.8543124794960022,0.8543124794960022,0.8543124794960022,0.8543124794960022,0.8543124794960022,0.8543124794960022],\"type\":\"scatter\"},{\"marker\":{\"color\":\"#cccccc\"},\"mode\":\"markers\",\"name\":\"Infeasible Trial\",\"showlegend\":false,\"x\":[],\"y\":[],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Optimization History Plot\"},\"xaxis\":{\"title\":{\"text\":\"Trial\"}},\"yaxis\":{\"title\":{\"text\":\"Objective Value\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('a2570a67-5467-44e7-ba7e-eea779cdfb18');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "html_file_path = \"./images/study_gru_doc2vec_optimize_history.html\"\n",
    "# Plot and save the optimization history plot as an HTML file\n",
    "ov.plot_optimization_history(study_gru_doc2vec).write_html(html_file_path)\n",
    "plot_optimization_history(study_gru_doc2vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Chinh tri Xa hoi', 1: 'Cong nghe', 2: 'Doi song', 3: 'Giai tri', 4: 'Giao duc', 5: 'Khoa hoc', 6: 'Kinh doanh', 7: 'Phap luat', 8: 'Suc khoe', 9: 'The gioi', 10: 'The thao', 11: 'Van hoa'}\n"
     ]
    }
   ],
   "source": [
    "# Chỉ số từ Index\n",
    "index = pd.Index(y_train.columns)\n",
    "\n",
    "# Chuyển đổi Index thành danh sách\n",
    "labels_list = index.tolist()\n",
    "\n",
    "# Tạo từ điển ánh xạ\n",
    "label_mapping = dict(enumerate(labels_list))\n",
    "\n",
    "# In từ điển ánh xạ\n",
    "print(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nhập nội dung văn bản\n",
    "input_text = \"\"\"\n",
    "Uống nước nhớ nguồn, kính trọng những người đi trước vốn là những đạo lý tốt đẹp của dân tộc ta, là yếu tố quan trọng để tạo lập những giá trị bền vững cho tương lai. Từ những ý nghĩa sâu xa đó, sáng ngày 21/10/2023, Trường Dự bị Đại học TP. Hồ Chí Minh đã tổ chức họp mặt, chia tay đối với ông Nguyễn Minh Châu – nhân viên Phòng Công tác Học sinh – Sinh viên về nghỉ hưu theo chế độ. Tham dự buổi họp mặt có sự tham gia của Ban Giám hiệu; Trưởng,…\n",
    "\"\"\"\n",
    "processed_text = preprocess_text(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['uống_nước_nhớ_nguồn', 'kính_trọng', 'đi', 'vốn', 'đạo_lý', 'tốt_đẹp', 'dân_tộc', 'yếu_tố', 'tạo_lập', 'bền_vững', 'tương_lai', 'ý_nghĩa', 'sâu_xa', 'trường', 'dự_bị_đại_học', 'tổ_chức', 'họp_mặt', 'chia_tay', 'nhân_viên', 'phòng', 'công_tác', 'học_sinh', 'sinh_viên', 'nghỉ', 'hưu', 'chế_độ', 'tham_dự', 'họp_mặt', 'tham_gia', 'ban_giám_hiệu', 'trưởng']\n"
     ]
    }
   ],
   "source": [
    "print(processed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_token = tokenizer.texts_to_sequences([processed_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23745, 5501, 1, 144, 8727, 1517, 734, 430, 6909, 2122, 417, 770, 7330, 2, 6225, 10, 7856, 1019, 223, 32, 141, 14, 90, 389, 1997, 577, 455, 7856, 36, 3246, 181]]\n"
     ]
    }
   ],
   "source": [
    "print(text_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_padded = pad_sequences(text_token, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(MODEL_FOLDER + sep + \"bilstm_doc2vec.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Nhãn Phần trăm Độ tin cậy\n",
      "0   Chinh tri Xa hoi               92.47%\n",
      "1          Cong nghe                0.01%\n",
      "2           Doi song                0.02%\n",
      "3           Giai tri                0.00%\n",
      "4           Giao duc                5.54%\n",
      "5           Khoa hoc                0.00%\n",
      "6         Kinh doanh                1.54%\n",
      "7          Phap luat                0.17%\n",
      "8           Suc khoe                0.00%\n",
      "9           The gioi                0.06%\n",
      "10          The thao                0.19%\n",
      "11           Van hoa                0.01%\n",
      "Chinh tri Xa hoi\n"
     ]
    }
   ],
   "source": [
    "# Thực hiện dự đoán\n",
    "predictions = model.predict(new_padded)\n",
    "\n",
    "# Tạo DataFrame để lưu trữ kết quả\n",
    "result_df = pd.DataFrame(columns=['Nhãn', 'Phần trăm Độ tin cậy'])\n",
    "\n",
    "# In ra độ tin cậy của tất cả các nhãn và lưu vào DataFrame\n",
    "for i, prediction in enumerate(predictions):\n",
    "    \n",
    "    # In ra tên nhãn và độ tin cậy tương ứng\n",
    "    for index, label_name in label_mapping.items():\n",
    "        \n",
    "        confidence_percent = prediction[index] * 100\n",
    "        result_df = result_df.append({'Nhãn': label_name, 'Phần trăm Độ tin cậy': confidence_percent}, ignore_index=True)\n",
    "# Lấy chỉ số của dòng có giá trị lớn nhất trong cột 'Phần trăm Độ tin cậy'\n",
    "max_confidence_index = result_df['Phần trăm Độ tin cậy'].idxmax()\n",
    "\n",
    "# Lấy thông tin của dòng có độ tin cậy cao nhất\n",
    "max_confidence_row = result_df.loc[max_confidence_index]\n",
    "\n",
    "# In ra nhãn có độ tin cậy cao nhất và độ tin cậy tương ứng\n",
    "max_confidence_label = max_confidence_row['Nhãn']\n",
    "# Định dạng cột 'Phần trăm Độ tin cậy' để thêm đuôi %\n",
    "result_df['Phần trăm Độ tin cậy'] = result_df['Phần trăm Độ tin cậy'].apply(lambda x: f'{x:.2f}%')\n",
    "\n",
    "# In ra DataFrame\n",
    "print(result_df)\n",
    "print(max_confidence_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(MODEL_FOLDER + sep + \"lstm_doc2vec.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict_classes(X_test)\n",
    "y_pred_onehot = pd.get_dummies(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8708\n",
      "Precision: 0.8712\n",
      "Recall: 0.8708\n",
      "F1-score: 0.8706\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "y_pred_onehot = pd.get_dummies(y_pred)\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred_onehot)\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Precision, Recall, and F1-score (calculate for each class and then average)\n",
    "precision = precision_score(y_test, y_pred_onehot, average='weighted')\n",
    "recall = recall_score(y_test, y_pred_onehot, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred_onehot, average='weighted')\n",
    "\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1-score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Label  Precision    Recall  F1-score\n",
      "0   Chinh tri Xa hoi   0.774953  0.764870  0.769878\n",
      "1          Cong nghe   0.903834  0.854922  0.878698\n",
      "2           Doi song   0.814359  0.779195  0.796389\n",
      "3           Giai tri   0.879452  0.879452  0.879452\n",
      "4           Giao duc   0.884535  0.921611  0.902693\n",
      "5           Khoa hoc   0.846154  0.870342  0.858078\n",
      "6         Kinh doanh   0.850676  0.898846  0.874098\n",
      "7          Phap luat   0.928174  0.869135  0.897684\n",
      "8           Suc khoe   0.842046  0.884298  0.862655\n",
      "9           The gioi   0.921038  0.870005  0.894795\n",
      "10          The thao   0.962715  0.976722  0.969668\n",
      "11           Van hoa   0.856721  0.894142  0.875031\n"
     ]
    }
   ],
   "source": [
    "def evaluate_per_label(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Evaluate precision, recall, and f1-score for each label.\n",
    "\n",
    "    Parameters:\n",
    "    - y_true: DataFrame, true labels\n",
    "    - y_pred: Series or array, predicted labels (integer labels)\n",
    "\n",
    "    Returns:\n",
    "    - evaluation_df: DataFrame, containing precision, recall, and f1-score for each label\n",
    "    \"\"\"\n",
    "    # One-hot encode predicted labels\n",
    "    y_pred_onehot = pd.get_dummies(y_pred)\n",
    "\n",
    "    # Calculate precision, recall, and f1-score for each label\n",
    "    precision_per_label = precision_score(y_true, y_pred_onehot, average=None)\n",
    "    recall_per_label = recall_score(y_true, y_pred_onehot, average=None)\n",
    "    f1_per_label = f1_score(y_true, y_pred_onehot, average=None)\n",
    "\n",
    "    # Create a DataFrame to store the results\n",
    "    evaluation_df = pd.DataFrame({\n",
    "        'Label': y_true.columns,\n",
    "        'Precision': precision_per_label,\n",
    "        'Recall': recall_per_label,\n",
    "        'F1-score': f1_per_label\n",
    "    })\n",
    "\n",
    "    return evaluation_df\n",
    "\n",
    "# Example usage:\n",
    "# Assuming y_test is the true labels DataFrame and y_pred is the predicted labels Series or array\n",
    "evaluation_results = evaluate_per_label(y_test, y_pred)\n",
    "\n",
    "# Display the evaluation results\n",
    "print(evaluation_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
