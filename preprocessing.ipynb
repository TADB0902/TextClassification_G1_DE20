{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Vietnamese Text Normalizer version 1.9.5\n",
      "\tBùi Tấn Quang - langmaninternet@gmail.com\n"
     ]
    }
   ],
   "source": [
    "import regex as re\n",
    "import py_vncorenlp\n",
    "import pandas as pd\n",
    "from VietnameseTextNormalizer.ReleasePython3 import VietnameseTextNormalizer\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-11 18:36:02 INFO  WordSegmenter:24 - Loading Word Segmentation model\n",
      "2023-12-11 18:36:02 INFO  PosTagger:23 - Loading POS Tagging model\n",
      "2023-12-11 18:36:05 INFO  NerRecognizer:34 - Loading NER model\n",
      "2023-12-11 18:36:18 INFO  DependencyParser:32 - Loading Dependency Parsing model\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "annotate = py_vncorenlp.VnCoreNLP(annotators=[\"wseg\", \"pos\", \"ner\", \"parse\"], save_dir='./')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORD = \"./vietnamese-stopwords-dash.txt\"\n",
    "with open(STOPWORD, 'r', encoding='utf-8') as stop_word_file:\n",
    "    stop_words = stop_word_file.read().splitlines()\n",
    "    \n",
    "ORIGINAL_DATA =\"./original_data/\"\n",
    "PREPROCESSED_DATA = \"./preprocessed_data/preprocessed_data.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text= VietnameseTextNormalizer.Normalize(text)\n",
    "    text = re.sub(r'http\\S+', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\b(www\\.[^\\s]+|(?!https?://)[^\\s]+\\.[a-z]{2,})\\b', '', text)\n",
    "    # Remove phone numbers\n",
    "    text = re.sub(r'\\b\\d{10,}\\b', '', text)\n",
    "\n",
    "    # Remove emails\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    annotations = annotate.annotate_text(text)\n",
    "    all_tokens = []\n",
    "    for sentence_index, sentence_annotations in annotations.items():\n",
    "        all_tokens.extend(sentence_annotations)\n",
    "    word_list  = [\n",
    "        token['wordForm'] for token in all_tokens\n",
    "        if isinstance(token, dict) and 'wordForm' in token and isinstance(token['wordForm'], str)\n",
    "        and 'posTag' in token and isinstance(token['posTag'], str) and token['posTag'] in ['N', 'V', 'A']\n",
    "        and 'nerLabel' in token and token['nerLabel'] not in ['B-PER']\n",
    "    ]\n",
    "    clean_words = [word.strip(',').strip().lower() for word in word_list  if word not in stop_words]\n",
    "    clean_words = [re.sub(r'([^\\s\\w]|)+', '', sentence) for sentence in clean_words if sentence!='']\n",
    "    return clean_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text = \"\"\"\n",
    "Chủ tịch NVIDIA nhận định, Chip, AI là chiến lược vô cùng quan trọng, sống còn cho một quốc gia. Ông tin rằng, Việt Nam sẽ là quê hương và trung tâm lớn nhất của NVIDIA.\n",
    "Việt Nam sẵn sàng đón các nhà đầu tư \n",
    "\n",
    "Phát biểu tại tọa đàm xu hướng phát triển ngành công nghiệp bán dẫn, trí tuệ nhân tạo và cơ hội cho Việt Nam do Bộ Kế hoạch và Đầu tư (KH-ĐT) chủ trì, Trung tâm Đổi mới sáng tạo Quốc gia (NIC) và Tập đoàn NVIDIA (Hoa Kỳ) tổ chức, diễn ra Hòa Lạc ngày 11/12, Bộ trưởng Bộ KH-ĐT Nguyễn Chí Dũng cho biết, tuyên bố chung về nâng cấp quan hệ Việt Nam – Hoa Kỳ lên Đối tác Chiến lược Toàn diện đã nêu hợp tác đột phá giữa hai quốc gia trong giai đoạn tới sẽ là đổi mới sáng tạo, công nghệ cao, trong đó có công nghệ bán dẫn và trí tuệ nhân tạo (AI).\n",
    "\n",
    "Thời gian vừa qua, Việt Nam đã tích cực chuẩn bị các điều kiện để sẵn sàng đón nhận, hợp tác với các doanh nghiệp (DN), nhà đầu tư của Hoa Kỳ trong lĩnh vực đổi mới sáng tạo, công nghiệp bán dẫn và trí tuệ nhân tạo.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chủ_tịch', 'nhận_định', 'chiến_lược', 'sống_còn', 'quốc_gia', 'ông', 'quê_hương', 'trung_tâm', 'sẵn_sàng', 'đón', 'nhà_đầu_tư', 'phát_biểu', 'toạ_đàm', 'xu_hướng', 'phát_triển', 'ngành', 'công_nghiệp', 'bán_dẫn', 'trí_tuệ_nhân_tạo', 'kế_hoạch', 'đầu_tư', 'chủ_trì', 'trung_tâm', 'đổi_mới', 'sáng_tạo', 'tập_đoàn', 'tổ_chức', 'diễn', 'bộ_trưởng', 'bộ', 'kh-đt', 'tuyên_bố_chung', 'nâng_cấp', 'quan_hệ', 'đối_tác', 'chiến_lược', 'nêu', 'hợp_tác', 'đột_phá', 'quốc_gia', 'giai_đoạn', 'đổi_mới', 'sáng_tạo', 'công_nghệ_cao', 'công_nghệ', 'bán_dẫn', 'trí_tuệ_nhân_tạo', 'thời_gian', 'tích_cực', 'sẵn_sàng', 'đón_nhận', 'hợp_tác', 'doanh_nghiệp', 'nhà_đầu_tư', 'lĩnh_vực', 'đổi_mới', 'sáng_tạo', 'công_nghiệp', 'bán_dẫn', 'trí_tuệ_nhân_tạo']\n"
     ]
    }
   ],
   "source": [
    "preprocessed_text = preprocess_text(text)\n",
    "print(preprocessed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process and save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm để đọc nội dung của file dựa trên định dạng\n",
    "def read_file(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        # Đọc một số byte đầu tiên để xác định định dạng UTF\n",
    "        raw_data = file.read(4)\n",
    "\n",
    "        # Kiểm tra xem có phải là UTF-16 hay không\n",
    "        if raw_data.startswith(b'\\xff\\xfe') or raw_data.startswith(b'\\xfe\\xff'):\n",
    "            # Định dạng UTF-16\n",
    "            encoding = 'utf-16'\n",
    "        else:\n",
    "            # Định dạng mặc định là UTF-8\n",
    "            encoding = 'utf-8'\n",
    "\n",
    "    # Đọc toàn bộ nội dung của file với định dạng đã xác định\n",
    "    with open(file_path, 'r', encoding=encoding) as file:\n",
    "        content = file.read()\n",
    "\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo một danh sách để lưu trữ dữ liệu\n",
    "data_list = []\n",
    "\n",
    "# Lấy danh sách tất cả các tệp trong thư mục gốc\n",
    "file_names = os.listdir(ORIGINAL_DATA)\n",
    "\n",
    "# Đếm số lượng files để sử dụng trong thông báo tiến trình\n",
    "total_files = len(file_names)\n",
    "\n",
    "# Biến đếm để theo dõi số lượng file đã xử lý\n",
    "processed_files_count = 0\n",
    "\n",
    "# Xử lý từng file và thêm vào danh sách\n",
    "for file_name in file_names:\n",
    "    file_path = os.path.join(ORIGINAL_DATA, file_name)\n",
    "    print(file_path)\n",
    "    # Đọc nội dung file dựa trên định dạng\n",
    "    content = read_file(file_path)\n",
    "    # Tiền xử lý văn bản\n",
    "    processed_text = preprocess_text(content)\n",
    "\n",
    "    # Trích xuất danh mục từ đường dẫn của file\n",
    "    category = os.path.basename(ORIGINAL_DATA)\n",
    "\n",
    "    # Tạo đối tượng lưu trữ dữ liệu\n",
    "    data = {\n",
    "        \"Processed_Content\": processed_text,\n",
    "        \"Category\": category\n",
    "    }\n",
    "\n",
    "    # Thêm vào danh sách\n",
    "    data_list.append(data)\n",
    "    \n",
    "    \n",
    "\n",
    "    # Tăng biến đếm\n",
    "    processed_files_count += 1\n",
    "\n",
    "    # Hiển thị thông báo tiến trình\n",
    "    print(f\"Processed {processed_files_count}/{total_files} files.\", end='\\r')\n",
    "    # Ghi dữ liệu vào tệp JSON ngay sau khi xử lý xong mỗi file\n",
    "    with open(PREPROCESSED_DATA, 'w', encoding='utf-8') as json_file:\n",
    "        json.dump(data_list, json_file, ensure_ascii=False)\n",
    "print(\"\\nXử lý và lưu dữ liệu thành công.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        Processed_Content  Category\n",
      "114317  [hành_trình, giới_tính, bác_sĩ, trái, chỉnh_sử...  Suc khoe\n",
      "114318  [khi, nàng, ham_muốn, phụ_nữ, tự_động, giản_đơ...  Suc khoe\n",
      "114319  [khẳng_định, cúm_gà, thúc_giục, quốc_gia, thàn...  Suc khoe\n",
      "114320  [bệnh_nhân, nhiễm, chiều, viện, vệ_sinh, dịch_...  Suc khoe\n",
      "114321  [tập_thể_dục, tập, tối, đốt, calo, tập, trao_đ...  Suc khoe\n"
     ]
    }
   ],
   "source": [
    "# Đường dẫn đến file JSON\n",
    "json_file_path = PREPROCESSED_DATA\n",
    "\n",
    "# Load dữ liệu từ file JSON vào DataFrame\n",
    "df = pd.read_json(json_file_path, encoding='utf-8', lines=True)\n",
    "\n",
    "# Hiển thị DataFrame\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 114322 entries, 0 to 114321\n",
      "Data columns (total 2 columns):\n",
      " #   Column             Non-Null Count   Dtype \n",
      "---  ------             --------------   ----- \n",
      " 0   Processed_Content  114322 non-null  object\n",
      " 1   Category           114322 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
